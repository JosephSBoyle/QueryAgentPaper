
@inproceedings{gao_making_2021,
	address = {Online},
	title = {Making {Pre}-trained {Language} {Models} {Better} {Few}-shot {Learners}},
	url = {https://aclanthology.org/2021.acl-long.295},
	doi = {10.18653/v1/2021.acl-long.295},
	abstract = {The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot performance solely by leveraging a natural-language prompt and a few task demonstrations as input context. Inspired by their findings, we study few-shot learning in a more practical scenario, where we use smaller language models for which fine-tuning is computationally efficient. We present LM-BFF—better few-shot fine-tuning of language models—a suite of simple and complementary techniques for fine-tuning language models on a small number of annotated examples. Our approach includes (1) prompt-based fine-tuning together with a novel pipeline for automating prompt generation; and (2) a refined strategy for dynamically and selectively incorporating demonstrations into each context. Finally, we present a systematic evaluation for analyzing few-shot performance on a range of NLP tasks, including classification and regression. Our experiments demonstrate that our methods combine to dramatically outperform standard fine-tuning procedures in this low resource setting, achieving up to 30\% absolute improvement, and 11\% on average across all tasks. Our approach makes minimal assumptions on task resources and domain expertise, and hence constitutes a strong task-agnostic method for few-shot learning.},
	urldate = {2023-05-02},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Gao, Tianyu and Fisch, Adam and Chen, Danqi},
	month = aug,
	year = {2021},
	pages = {3816--3830},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/NH26S9PE/Gao et al. - 2021 - Making Pre-trained Language Models Better Few-shot.pdf:application/pdf},
}

@inproceedings{zou_lexicon-based_2018,
	address = {Santa Fe, New Mexico, USA},
	title = {A {Lexicon}-{Based} {Supervised} {Attention} {Model} for {Neural} {Sentiment} {Analysis}},
	url = {https://aclanthology.org/C18-1074},
	abstract = {Attention mechanisms have been leveraged for sentiment classification tasks because not all words have the same importance. However, most existing attention models did not take full advantage of sentiment lexicons, which provide rich sentiment information and play a critical role in sentiment analysis. To achieve the above target, in this work, we propose a novel lexicon-based supervised attention model (LBSA), which allows a recurrent neural network to focus on the sentiment content, thus generating sentiment-informative representations. Compared with general attention models, our model has better interpretability and less noise. Experimental results on three large-scale sentiment classification datasets showed that the proposed method outperforms previous methods.},
	urldate = {2023-04-24},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Zou, Yicheng and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
	month = aug,
	year = {2018},
	pages = {868--877},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PJRJBGAC/Zou et al. - 2018 - A Lexicon-Based Supervised Attention Model for Neu.pdf:application/pdf},
}

@article{trigueros_explainable_2022,
	title = {Explainable {ICD} multi-label classification of {EHRs} in {Spanish} with convolutional attention},
	volume = {157},
	issn = {1386-5056},
	url = {https://www.sciencedirect.com/science/article/pii/S1386505621002410},
	doi = {10.1016/j.ijmedinf.2021.104615},
	abstract = {Background
This work deals with Natural Language Processing applied to Electronic Health Records (EHRs). EHRs are coded following the International Classification of Diseases (ICD) leading to a multi-label classification problem. Previously proposed approaches act as black-boxes without giving further insights. Explainable Artificial Intelligence (XAI) helps to clarify what brought the model to make the predictions.
Goal
This work aims to obtain explainable predictions of the diseases and procedures contained in EHRs. As an application, we show visualizations of the attention stored and propose a prototype of a Decision Support System (DSS) that highlights the text that motivated the choice of each of the proposed ICD codes.
Methods
Convolutional Neural Networks (CNNs) with attention mechanisms were used. Attention mechanisms allow to detect which part of the input (EHRs) motivate the output (medical codes), producing explainable predictions.
Results
We successfully applied methods in a Spanish corpus getting challenging results. Finally, we presented the idea of extracting the chronological order of the ICDs in a given EHR by anchoring the codes to different stages of the clinical admission.
Conclusions
We found that explainable deep learning models applied to predict medical codes store helpful information that could be used to assist medical experts while reaching a solid performance. In particular, we show that the information stored in the attention mechanisms enables DSS and a shallow chronology of diagnoses.},
	language = {en},
	urldate = {2023-04-13},
	journal = {International Journal of Medical Informatics},
	author = {Trigueros, Owen and Blanco, Alberto and Lebeña, Nuria and Casillas, Arantza and Pérez, Alicia},
	month = jan,
	year = {2022},
	keywords = {Clinical Language Processing, Decision Support Systems, Deep Neural Understanding, Electronic Health Records, International Classification of Diseases},
	pages = {104615},
	file = {ScienceDirect Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/L6NHHZVG/Trigueros et al. - 2022 - Explainable ICD multi-label classification of EHRs.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/EHNHWWMX/S1386505621002410.html:text/html},
}

@article{johnson_mimic-iii_2016,
	title = {{MIMIC}-{III}, a freely accessible critical care database},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201635},
	doi = {10.1038/sdata.2016.35},
	abstract = {MIMIC-III (‘Medical Information Mart for Intensive Care’) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.},
	language = {en},
	number = {1},
	urldate = {2023-04-11},
	journal = {Scientific Data},
	author = {Johnson, Alistair E. W. and Pollard, Tom J. and Shen, Lu and Lehman, Li-wei H. and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Anthony Celi, Leo and Mark, Roger G.},
	month = may,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Diagnosis, Medical research, Outcomes research, Prognosis},
	pages = {160035},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/39HJLMVS/Johnson et al. - 2016 - MIMIC-III, a freely accessible critical care datab.pdf:application/pdf},
}

@article{bowman_eight_nodate,
	title = {Eight {Things} to {Know} about {Large} {Language} {Models}},
	language = {en},
	author = {Bowman, Samuel R},
	file = {Bowman - Eight Things to Know about Large Language Models.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/L7DV9DNY/Bowman - Eight Things to Know about Large Language Models.pdf:application/pdf},
}

@article{amann_explainability_2020,
	title = {Explainability for artificial intelligence in healthcare: a multidisciplinary perspective},
	volume = {20},
	issn = {1472-6947},
	shorttitle = {Explainability for artificial intelligence in healthcare},
	url = {https://doi.org/10.1186/s12911-020-01332-6},
	doi = {10.1186/s12911-020-01332-6},
	abstract = {Explainability is one of the most heavily debated topics when it comes to the application of artificial intelligence (AI) in healthcare. Even though AI-driven systems have been shown to outperform humans in certain analytical tasks, the lack of explainability continues to spark criticism. Yet, explainability is not a purely technological issue, instead it invokes a host of medical, legal, ethical, and societal questions that require thorough exploration. This paper provides a comprehensive assessment of the role of explainability in medical AI and makes an ethical evaluation of what explainability means for the adoption of AI-driven tools into clinical practice.},
	number = {1},
	urldate = {2023-03-28},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Amann, Julia and Blasimme, Alessandro and Vayena, Effy and Frey, Dietmar and Madai, Vince I. and {the Precise4Q consortium}},
	month = nov,
	year = {2020},
	keywords = {Machine learning, Artificial intelligence, Clinical decision support, Explainability, Interpretability},
	pages = {310},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2AUVJTLC/Amann et al. - 2020 - Explainability for artificial intelligence in heal.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/4WQN84JE/s12911-020-01332-6.html:text/html},
}

@article{braun_primer_2021,
	title = {Primer on an ethics of {AI}-based decision support systems in the clinic},
	volume = {47},
	copyright = {© Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {0306-6800, 1473-4257},
	url = {https://jme.bmj.com/content/47/12/e3},
	doi = {10.1136/medethics-2019-105860},
	abstract = {Making good decisions in extremely complex and difficult processes and situations has always been both a key task as well as a challenge in the clinic and has led to a large amount of clinical, legal and ethical routines, protocols and reflections in order to guarantee fair, participatory and up-to-date pathways for clinical decision-making. Nevertheless, the complexity of processes and physical phenomena, time as well as economic constraints and not least further endeavours as well as achievements in medicine and healthcare continuously raise the need to evaluate and to improve clinical decision-making. This article scrutinises if and how clinical decision-making processes are challenged by the rise of so-called artificial intelligence-driven decision support systems (AI-DSS). In a first step, this article analyses how the rise of AI-DSS will affect and transform the modes of interaction between different agents in the clinic. In a second step, we point out how these changing modes of interaction also imply shifts in the conditions of trustworthiness, epistemic challenges regarding transparency, the underlying normative concepts of agency and its embedding into concrete contexts of deployment and, finally, the consequences for (possible) ascriptions of responsibility. Third, we draw first conclusions for further steps regarding a ‘meaningful human control’ of clinical AI-DSS.},
	language = {en},
	number = {12},
	urldate = {2023-03-28},
	journal = {Journal of Medical Ethics},
	author = {Braun, Matthias and Hummel, Patrik and Beck, Susanne and Dabrock, Peter},
	month = dec,
	year = {2021},
	pmid = {32245804},
	note = {Publisher: Institute of Medical Ethics
Section: Original research},
	keywords = {decision-making, ethics},
	pages = {e3--e3},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2L6T6Z43/Braun et al. - 2021 - Primer on an ethics of AI-based decision support s.pdf:application/pdf},
}

@article{weiner_e-iatrogenesis_2007,
	title = {“e-{Iatrogenesis}”: {The} {Most} {Critical} {Unintended} {Consequence} of {CPOE} and other {HIT}},
	volume = {14},
	issn = {1067-5027},
	shorttitle = {“e-{Iatrogenesis}”},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2244888/},
	doi = {10.1197/jamia.M2338},
	number = {3},
	urldate = {2023-03-28},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Weiner, Jonathan P. and Kfuri, Toni and Chan, Kitty and Fowles, Jinnet B.},
	year = {2007},
	pmid = {17329719},
	pmcid = {PMC2244888},
	pages = {387--388},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/HLSHB953/Weiner et al. - 2007 - “e-Iatrogenesis” The Most Critical Unintended Con.pdf:application/pdf},
}

@article{parisi_continual_2019,
	title = {Continual lifelong learning with neural networks: {A} review},
	volume = {113},
	issn = {0893-6080},
	shorttitle = {Continual lifelong learning with neural networks},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608019300231},
	doi = {10.1016/j.neunet.2019.01.012},
	abstract = {Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for computational learning systems and autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. Although significant advances have been made in domain-specific learning with neural networks, extensive research efforts are required for the development of robust lifelong learning on autonomous agents and robots. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Neural Networks},
	author = {Parisi, German I. and Kemker, Ronald and Part, Jose L. and Kanan, Christopher and Wermter, Stefan},
	month = may,
	year = {2019},
	keywords = {Catastrophic forgetting, Continual learning, Developmental systems, Lifelong learning, Memory consolidation},
	pages = {54--71},
	file = {ScienceDirect Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/SUW7UDVN/Parisi et al. - 2019 - Continual lifelong learning with neural networks .pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/H9FB7YXY/S0893608019300231.html:text/html},
}

@article{beeler_clinical_2014,
	title = {Clinical decision support systems},
	issn = {1424-7860, 1424-3997},
	url = {https://smw.ch/index.php/smw/article/view/1954},
	doi = {10.4414/smw.2014.14073},
	abstract = {Clinical decision support (CDS) systems link patient data with an electronic knowledge base in order to improve decision-making and computerised physician order entry (CPOE) is a requirement to set up electronic CDS. The medical informatics literature suggests categorising CDS tools into medication dosing support, order facilitators, point-of-care alerts and reminders, relevant information display, expert systems and workflow support. To date, CDS has particularly been recognised for improving processes. CDS successfully fostered prevention of deep-vein thrombosis, improved adherence to guidelines, increased the use of vaccinations, and decreased the rate of serious medication errors. However, CDS may introduce errors, and therefore the term "e-iatrogenesis" has been proposed to address unintended consequences. At least two studies reported severe treatment delays due to CPOE and CDS. In addition, the phenomenon of "alert fatigue" - arising from a high number of CDS alerts of low clinical significance - may facilitate overriding of potentially critical notifications. The implementation of CDS needs to be carefully planned, CDS interventions should be thoroughly examined in pilot wards only, and then stepwise introduced. A crucial feature of CPOE in combination with CDS is speed, since time consumption has been found to be a major factor determining failure. In the near future, the specificity of alerts will be improved, notifications will be prioritised and offer detailed advice, customisation of CDS will play an increasing role, and finally, CDS is heading for patient-centred decision support. The most important research question remains whether CDS is able to improve patient outcomes beyond processes.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Swiss Medical Weekly},
	author = {Beeler, P and Bates, D and Hug, B},
	month = dec,
	year = {2014},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/9YHAY5YR/Beeler et al. - 2014 - Clinical decision support systems.pdf:application/pdf},
}

@inproceedings{schrempf_paying_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Paying {Per}-{Label} {Attention} for {Multi}-label {Extraction} from {Radiology} {Reports}},
	isbn = {978-3-030-61166-8},
	doi = {10.1007/978-3-030-61166-8_29},
	abstract = {Training medical image analysis models requires large amounts of expertly annotated data which is time-consuming and expensive to obtain. Images are often accompanied by free-text radiology reports which are a rich source of information. In this paper, we tackle the automated extraction of structured labels from head CT reports for imaging of suspected stroke patients, using deep learning. Firstly, we propose a set of 31 labels which correspond to radiographic findings (e.g. hyperdensity) and clinical impressions (e.g. haemorrhage) related to neurological abnormalities. Secondly, inspired by previous work, we extend existing state-of-the-art neural network models with a label-dependent attention mechanism. Using this mechanism and simple synthetic data augmentation, we are able to robustly extract many labels with a single model, classified according to the radiologist’s reporting (positive, uncertain, negative). This approach can be used in further research to effectively extract many labels from medical text.},
	language = {en},
	booktitle = {Interpretable and {Annotation}-{Efficient} {Learning} for {Medical} {Image} {Computing}},
	publisher = {Springer International Publishing},
	author = {Schrempf, Patrick and Watson, Hannah and Mikhael, Shadia and Pajak, Maciej and Falis, Matúš and Lisowska, Aneta and Muir, Keith W. and Harris-Birtill, David and O’Neil, Alison Q.},
	editor = {Cardoso, Jaime and Van Nguyen, Hien and Heller, Nicholas and Henriques Abreu, Pedro and Isgum, Ivana and Silva, Wilson and Cruz, Ricardo and Pereira Amorim, Jose and Patel, Vishal and Roysam, Badri and Zhou, Kevin and Jiang, Steve and Le, Ngan and Luu, Khoa and Sznitman, Raphael and Cheplygina, Veronika and Mateus, Diana and Trucco, Emanuele and Abbasi, Samaneh},
	year = {2020},
	keywords = {BERT, NLP, Radiology report labelling},
	pages = {277--289},
	file = {Accepted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/J88AWUA5/Schrempf et al. - 2020 - Paying Per-Label Attention for Multi-label Extract.pdf:application/pdf},
}

@inproceedings{mullenbach_explainable_2018,
	address = {New Orleans, Louisiana},
	title = {Explainable {Prediction} of {Medical} {Codes} from {Clinical} {Text}},
	url = {https://aclanthology.org/N18-1100},
	doi = {10.18653/v1/N18-1100},
	abstract = {Clinical notes are text documents that are created by clinicians for each patient encounter. They are typically accompanied by medical codes, which describe the diagnosis and treatment. Annotating these codes is labor intensive and error prone; furthermore, the connection between the codes and the text is not annotated, obscuring the reasons and details behind specific diagnoses and treatments. We present an attentional convolutional network that predicts medical codes from clinical text. Our method aggregates information across the document using a convolutional neural network, and uses an attention mechanism to select the most relevant segments for each of the thousands of possible codes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of 0.54, which are both better than the prior state of the art. Furthermore, through an interpretability evaluation by a physician, we show that the attention mechanism identifies meaningful explanations for each code assignment.},
	urldate = {2023-03-25},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Mullenbach, James and Wiegreffe, Sarah and Duke, Jon and Sun, Jimeng and Eisenstein, Jacob},
	month = jun,
	year = {2018},
	pages = {1101--1111},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/QYENJKYH/Mullenbach et al. - 2018 - Explainable Prediction of Medical Codes from Clini.pdf:application/pdf},
}

@article{venkatesh_automating_2023,
	title = {Automating the overburdened clinical coding system: challenges and next steps},
	volume = {6},
	issn = {2398-6352},
	shorttitle = {Automating the overburdened clinical coding system},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9898522/},
	doi = {10.1038/s41746-023-00768-0},
	abstract = {Artificial intelligence (AI) and natural language processing (NLP) have found a highly promising application in automated clinical coding (ACC), an innovation that will have profound impacts on the clinical coding industry, billing and revenue management, and potentially clinical care itself. Dong et al. recently analyzed the technical challenges of ACC and proposed future directions. Primary challenges for ACC exist at the technological and implementation levels; clinical documents are redundant and complex, code sets like the ICD-10 are rapidly evolving, training sets are not comprehensive of codes, and ACC models have yet to fully capture the logic and rules of coding decisions. Next steps include interdisciplinary collaboration with clinical coders, accessibility and transparency of datasets, and tailoring models to specific use cases.},
	urldate = {2023-03-24},
	journal = {NPJ Digital Medicine},
	author = {Venkatesh, Kaushik P. and Raza, Marium M. and Kvedar, Joseph C.},
	month = feb,
	year = {2023},
	pmid = {36737496},
	pmcid = {PMC9898522},
	pages = {16},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZC99XGUY/Venkatesh et al. - 2023 - Automating the overburdened clinical coding system.pdf:application/pdf},
}

@inproceedings{falis_ontological_2019,
	address = {Hong Kong},
	title = {Ontological attention ensembles for capturing semantic concepts in {ICD} code prediction from clinical text},
	url = {https://aclanthology.org/D19-6220},
	doi = {10.18653/v1/D19-6220},
	abstract = {We present a semantically interpretable system for automated ICD coding of clinical text documents. Our contribution is an ontological attention mechanism which matches the structure of the ICD ontology, in which shared attention vectors are learned at each level of the hierarchy, and combined into label-dependent ensembles. Analysis of the attention heads shows that shared concepts are learned by the lowest common denominator node. This allows child nodes to focus on the differentiating concepts, leading to efficient learning and memory usage. Visualisation of the multi-level attention on the original text allows explanation of the code predictions according to the semantics of the ICD ontology. On the MIMIC-III dataset we achieve a 2.7\% absolute (11\% relative) improvement from 0.218 to 0.245 macro-F1 score compared to the previous state of the art across 3,912 codes. Finally, we analyse the labelling inconsistencies arising from different coding practices which limit performance on this task.},
	urldate = {2023-03-23},
	booktitle = {Proceedings of the {Tenth} {International} {Workshop} on {Health} {Text} {Mining} and {Information} {Analysis} ({LOUHI} 2019)},
	publisher = {Association for Computational Linguistics},
	author = {Falis, Matus and Pajak, Maciej and Lisowska, Aneta and Schrempf, Patrick and Deckers, Lucas and Mikhael, Shadia and Tsaftaris, Sotirios and O'Neil, Alison},
	month = nov,
	year = {2019},
	pages = {168--177},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/Q6SPKPIN/Falis et al. - 2019 - Ontological attention ensembles for capturing sema.pdf:application/pdf},
}

@misc{wiegreffe_attention_2019,
	title = {Attention is not not {Explanation}},
	url = {http://arxiv.org/abs/1908.04626},
	doi = {10.48550/arXiv.1908.04626},
	abstract = {Attention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model's prediction, and consequently reach insights regarding the model's decision-making process. A recent paper claims that `Attention is not Explanation' (Jain and Wallace, 2019). We challenge many of the assumptions underlying this work, arguing that such a claim depends on one's definition of explanation, and that testing it needs to take into account all elements of the model, using a rigorous experimental design. We propose four alternative tests to determine when/whether attention can be used as explanation: a simple uniform-weights baseline; a variance calibration based on multiple random seed runs; a diagnostic framework using frozen weights from pretrained models; and an end-to-end adversarial attention training protocol. Each allows for meaningful interpretation of attention mechanisms in RNN models. We show that even when reliable adversarial distributions can be found, they don't perform well on the simple diagnostic, indicating that prior work does not disprove the usefulness of attention mechanisms for explainability.},
	urldate = {2023-03-23},
	publisher = {arXiv},
	author = {Wiegreffe, Sarah and Pinter, Yuval},
	month = sep,
	year = {2019},
	note = {arXiv:1908.04626 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/WZXD4R2N/Wiegreffe and Pinter - 2019 - Attention is not not Explanation.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ES47LMY6/1908.html:text/html},
}

@misc{jain_attention_2019,
	title = {Attention is not {Explanation}},
	url = {http://arxiv.org/abs/1902.10186},
	doi = {10.48550/arXiv.1902.10186},
	abstract = {Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work, we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful `explanations' for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code for all experiments is available at https://github.com/successar/AttentionExplanation.},
	urldate = {2023-03-21},
	publisher = {arXiv},
	author = {Jain, Sarthak and Wallace, Byron C.},
	month = may,
	year = {2019},
	note = {arXiv:1902.10186 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/7BWJ785T/Jain and Wallace - 2019 - Attention is not Explanation.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/PSKS3JJC/1902.html:text/html},
}

@misc{deyoung_entity_2022,
	title = {Entity {Anchored} {ICD} {Coding}},
	url = {http://arxiv.org/abs/2208.07444},
	doi = {10.48550/arXiv.2208.07444},
	abstract = {Medical coding is a complex task, requiring assignment of a subset of over 72,000 ICD codes to a patient's notes. Modern natural language processing approaches to these tasks have been challenged by the length of the input and size of the output space. We limit our model inputs to a small window around medical entities found in our documents. From those local contexts, we build contextualized representations of both ICD codes and entities, and aggregate over these representations to form document-level predictions. In contrast to existing methods which use a representation fixed either in size or by codes seen in training, we represent ICD codes by encoding the code description with local context. We discuss metrics appropriate to deploying coding systems in practice. We show that our approach is superior to existing methods in both standard and deployable measures, including performance on rare and unseen codes.},
	urldate = {2023-03-20},
	publisher = {arXiv},
	author = {DeYoung, Jay and Shing, Han-Chin and Kong, Luyang and Winestock, Christopher and Shivade, Chaitanya},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07444 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/DDDKH8LQ/DeYoung et al. - 2022 - Entity Anchored ICD Coding.pdf:application/pdf},
}

@article{de_lusignan_barriers_2005,
	title = {The barriers to clinical coding in general practice: {A} literature review},
	volume = {30},
	shorttitle = {The barriers to clinical coding in general practice},
	doi = {10.1080/14639230500298651},
	abstract = {Clinical coding is variable in UK general practice. The reasons for this remain undefined. This review explains why there are no readily available alternatives to recording structured clinical data and reviews the barriers to recording structured clinical data. Methods used included a literature review of bibliographic databases, university health informatics departments, and national and international medical informatics associations. The results show that the current state of development of computers and data processing means there is no practical alternative to coding data. The identified barriers to clinical coding are: the limitations of the coding systems and terminologies and the skill gap in their use; recording structured data in the consultation takes time and is distracting; the level of motivation of primary care professionals; and the priority within the organization. A taxonomy is proposed to describe the barriers to clinical coding. This can be used to identify barriers to coding and facilitate the development of strategies to overcome them.},
	journal = {Medical informatics and the Internet in medicine},
	author = {de Lusignan, Simon},
	month = jul,
	year = {2005},
	pages = {89--97},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2YI4FNFA/de Lusignan - 2005 - The barriers to clinical coding in general practic.pdf:application/pdf},
}

@misc{zhan_structuring_2021,
	title = {Structuring clinical text with {AI}: old vs. new natural language processing techniques evaluated on eight common cardiovascular diseases},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {Structuring clinical text with {AI}},
	url = {https://www.medrxiv.org/content/10.1101/2021.01.27.21250477v1},
	doi = {10.1101/2021.01.27.21250477},
	abstract = {Mining the structured data in electronic health records(EHRs) enables many clinical applications while the information in free-text clinical notes often remains untapped. Free-text notes are unstructured data harder to use in machine learning while structured diagnostic codes can be missing or even erroneous. To improve the quality of diagnostic codes, this work extracts structured diagnostic codes from the unstructured notes concerning cardiovascular diseases. Five old and new word embeddings were used to vectorize over 5 million progress notes from Stanford EHR and logistic regression was used to predict eight ICD-10 codes of common cardiovascular diseases. The models were interpreted by the important words in predictions and analyses of false positive cases. Trained on Stanford notes, the model transferability was tested in the prediction of corresponding ICD-9 codes of the MIMIC-III discharge summaries. The word embeddings and logistic regression showed good performance in the diagnostic code extraction with TF-IDF as the best word embedding model showing AU-ROC ranging from 0.9499 to 0.9915 and AUPRC ranging from 0.2956 to 0.8072. The models also showed transferability when tested on MIMIC-III data set with AUROC ranging from 0.7952 to 0.9790 and AUPRC ranging from 0.2353 to 0.8084. Model interpretability was showed by the important words with clinical meanings matching each disease. This study shows the feasibility to accurately extract structured diagnostic codes, impute missing codes and correct erroneous codes from free-text clinical notes with interpretable models for clinicians, which helps improve the data quality of diagnostic codes for information retrieval and downstream machine-learning applications.},
	language = {en},
	urldate = {2023-03-15},
	publisher = {medRxiv},
	author = {Zhan, Xianghao and Humbert-Droz, Marie and Mukherjee, Pritam and Gevaert, Olivier},
	month = jan,
	year = {2021},
	note = {Pages: 2021.01.27.21250477},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/YWZ8EPRJ/Zhan et al. - 2021 - Structuring clinical text with AI old vs. new nat.pdf:application/pdf},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2023-03-15},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GEJYXBWL/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/IFD7C5W6/1706.html:text/html},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2023-03-15},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/FJF62WEM/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/Y6GEFWN3/1810.html:text/html},
}

@article{s_detecting_2020,
	title = {Detecting {Miscoded} {Diabetes} {Diagnosis} {Codes} in {Electronic} {Health} {Records} for {Quality} {Improvement}: {Temporal} {Deep} {Learning} {Approach}},
	volume = {8},
	issn = {2291-9694},
	shorttitle = {Detecting {Miscoded} {Diabetes} {Diagnosis} {Codes} in {Electronic} {Health} {Records} for {Quality} {Improvement}},
	url = {https://pubmed.ncbi.nlm.nih.gov/33331828/},
	doi = {10.2196/22649},
	abstract = {This study demonstrates that deep learning methods can improve clinical phenotyping even when patient data are noisy, sparse, and heterogeneous.},
	language = {en},
	number = {12},
	urldate = {2023-03-15},
	journal = {JMIR medical informatics},
	author = {S, Rashidian and K, Abell-Hart and J, Hajagos and R, Moffitt and V, Lingam and V, Garcia and Cw, Tsai and F, Wang and X, Dong and S, Sun and J, Deng and R, Gupta and J, Miller and J, Saltz and M, Saltz},
	month = dec,
	year = {2020},
	pmid = {33331828},
	note = {Publisher: JMIR Med Inform},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/GDTAWMTG/S et al. - 2020 - Detecting Miscoded Diabetes Diagnosis Codes in Ele.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/XE3HY9JS/33331828.html:text/html},
}

@misc{szegedy_intriguing_2014,
	title = {Intriguing properties of neural networks},
	url = {http://arxiv.org/abs/1312.6199},
	doi = {10.48550/arXiv.1312.6199},
	abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.},
	urldate = {2023-03-15},
	publisher = {arXiv},
	author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	month = feb,
	year = {2014},
	note = {arXiv:1312.6199 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MYLN685Q/Szegedy et al. - 2014 - Intriguing properties of neural networks.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/8D2HM5ND/1312.html:text/html},
}

@inproceedings{vu_label_2020,
	title = {A {Label} {Attention} {Model} for {ICD} {Coding} from {Clinical} {Text}},
	url = {http://arxiv.org/abs/2007.06351},
	doi = {10.24963/ijcai.2020/461},
	abstract = {ICD coding is a process of assigning the International Classification of Disease diagnosis codes to clinical/medical notes documented by health professionals (e.g. clinicians). This process requires significant human resources, and thus is costly and prone to error. To handle the problem, machine learning has been utilized for automatic ICD coding. Previous state-of-the-art models were based on convolutional neural networks, using a single/several fixed window sizes. However, the lengths and interdependence between text fragments related to ICD codes in clinical text vary significantly, leading to the difficulty of deciding what the best window sizes are. In this paper, we propose a new label attention model for automatic ICD coding, which can handle both the various lengths and the interdependence of the ICD code related text fragments. Furthermore, as the majority of ICD codes are not frequently used, leading to the extremely imbalanced data issue, we additionally propose a hierarchical joint learning mechanism extending our label attention model to handle the issue, using the hierarchical relationships among the codes. Our label attention model achieves new state-of-the-art results on three benchmark MIMIC datasets, and the joint learning mechanism helps improve the performances for infrequent codes.},
	urldate = {2023-03-18},
	booktitle = {Proceedings of the {Twenty}-{Ninth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Vu, Thanh and Nguyen, Dat Quoc and Nguyen, Anthony},
	month = jul,
	year = {2020},
	note = {arXiv:2007.06351 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	pages = {3335--3341},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/322SMTY8/Vu et al. - 2020 - A Label Attention Model for ICD Coding from Clinic.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DMRV8IE6/2007.html:text/html},
}

@article{dong_automated_2022,
	title = {Automated clinical coding: what, why, and where we are?},
	volume = {5},
	copyright = {2022 The Author(s)},
	issn = {2398-6352},
	shorttitle = {Automated clinical coding},
	url = {https://www.nature.com/articles/s41746-022-00705-7},
	doi = {10.1038/s41746-022-00705-7},
	abstract = {Clinical coding is the task of transforming medical information in a patient’s health records into structured codes so that they can be used for statistical analysis. This is a cognitive and time-consuming task that follows a standard process in order to achieve a high level of consistency. Clinical coding could potentially be supported by an automated system to improve the efficiency and accuracy of the process. We introduce the idea of automated clinical coding and summarise its challenges from the perspective of Artificial Intelligence (AI) and Natural Language Processing (NLP), based on the literature, our project experience over the past two and half years (late 2019–early 2022), and discussions with clinical coding experts in Scotland and the UK. Our research reveals the gaps between the current deep learning-based approach applied to clinical coding and the need for explainability and consistency in real-world practice. Knowledge-based methods that represent and reason the standard, explainable process of a task may need to be incorporated into deep learning-based methods for clinical coding. Automated clinical coding is a promising task for AI, despite the technical and organisational challenges. Coders are needed to be involved in the development process. There is much to achieve to develop and deploy an AI-based automated system to support coding in the next five years and beyond.},
	language = {en},
	number = {1},
	urldate = {2023-03-16},
	journal = {npj Digital Medicine},
	author = {Dong, Hang and Falis, Matúš and Whiteley, William and Alex, Beatrice and Matterson, Joshua and Ji, Shaoxiong and Chen, Jiaoyan and Wu, Honghan},
	month = oct,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Health care, Information technology},
	pages = {1--8},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/RYAHBVQQ/Dong et al. - 2022 - Automated clinical coding what, why, and where we.pdf:application/pdf},
}

@article{sutton_overview_2020,
	title = {An overview of clinical decision support systems: benefits, risks, and strategies for success},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	shorttitle = {An overview of clinical decision support systems},
	url = {https://www.nature.com/articles/s41746-020-0221-y},
	doi = {10.1038/s41746-020-0221-y},
	abstract = {Computerized clinical decision support systems, or CDSS, represent a paradigm shift in healthcare today. CDSS are used to augment clinicians in their complex decision-making processes. Since their first use in the 1980s, CDSS have seen a rapid evolution. They are now commonly administered through electronic medical records and other computerized clinical workflows, which has been facilitated by increasing global adoption of electronic medical records with advanced capabilities. Despite these advances, there remain unknowns regarding the effect CDSS have on the providers who use them, patient outcomes, and costs. There have been numerous published examples in the past decade(s) of CDSS success stories, but notable setbacks have also shown us that CDSS are not without risks. In this paper, we provide a state-of-the-art overview on the use of clinical decision support systems in medicine, including the different types, current use cases with proven efficacy, common pitfalls, and potential harms. We conclude with evidence-based recommendations for minimizing risk in CDSS design, implementation, evaluation, and maintenance.},
	language = {en},
	number = {1},
	urldate = {2023-03-15},
	journal = {npj Digital Medicine},
	author = {Sutton, Reed T. and Pincock, David and Baumgart, Daniel C. and Sadowski, Daniel C. and Fedorak, Richard N. and Kroeker, Karen I.},
	month = feb,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Diagnosis, Drug regulation, Health services, Medical imaging},
	pages = {1--10},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MGKF9J7B/Sutton et al. - 2020 - An overview of clinical decision support systems .pdf:application/pdf},
}

@article{tarekegn_review_2021,
	title = {A review of methods for imbalanced multi-label classification},
	volume = {118},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320321001527},
	doi = {10.1016/j.patcog.2021.107965},
	abstract = {Multi-Label Classification (MLC) is an extension of the standard single-label classification where each data instance is associated with several labels simultaneously. MLC has gained much importance in recent years due to its wide range of application domains. However, the class imbalance problem has become an inherent characteristic of many multi-label datasets, where the samples and their corresponding labels are non-uniformly distributed over the data space. The imbalanced problem in MLC imposes challenges to multi-label data analytics which can be viewed from three perspectives: imbalance within labels, among labels, and label-sets. In this paper, we provide a review of the approaches for handling the imbalance problem in multi-label data by collecting the existing research work. As the first systematic study of approaches addressing an imbalanced problem in MLC, this paper provides a comprehensive survey of the state-of-the-art methods for imbalanced MLC, including the characteristics of imbalanced multi-label datasets, evaluation measures and comparative analysis of the proposed methods. The study also discusses important results reported so far in the literature and highlights some of their strengths and limitations to guide future research.},
	language = {en},
	urldate = {2023-03-15},
	journal = {Pattern Recognition},
	author = {Tarekegn, Adane Nega and Giacobini, Mario and Michalak, Krzysztof},
	month = oct,
	year = {2021},
	keywords = {Imbalanced Approaches, Imbalanced Classification, Imbalanced Data, Machine learning, Multi-label Classification, Review on Imbalanced Classification},
	pages = {107965},
	file = {ScienceDirect Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/RDDBL7IC/Tarekegn et al. - 2021 - A review of methods for imbalanced multi-label cla.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/778M7AIH/S0031320321001527.html:text/html},
}

@article{elmokhallalati_identification_2020,
	title = {Identification of patients with potential palliative care needs: {A} systematic review of screening tools in primary care},
	volume = {34},
	issn = {0269-2163},
	shorttitle = {Identification of patients with potential palliative care needs},
	url = {https://doi.org/10.1177/0269216320929552},
	doi = {10.1177/0269216320929552},
	abstract = {Background: Despite increasing evidence of the benefits of early access to palliative care, many patients do not receive palliative care in a timely manner. A systematic approach in primary care can facilitate earlier identification of patients with potential palliative care needs and prompt further assessment.
Aim: To identify existing screening tools for identification of patients with advanced progressive diseases who are likely to have palliative care needs in primary healthcare and evaluate their accuracy.
Design: Systematic review (PROSPERO registration number CRD42019111568).
Data sources: Cochrane, MEDLINE, Embase and CINAHL were searched from inception to March 2019
Results: From 4,127 unique articles screened, 25 reported the use or development of 10 screening tools. Most tools use prediction of death and/or deterioration as a proxy for the identification of people with potential palliative care needs. The tools are based on a wide range of general and disease-specific indicators. The accuracy of five tools was assessed in eight studies; these tools differed significantly in their ability to identify patients with potential palliative care needs with sensitivity ranging from 3\% to 94\% and specificity ranging from 26\% to 99\%.
Conclusion: The ability of current screening tools to identify patients with advanced progressive diseases who are likely to have palliative care needs in primary care is limited. Further research is needed to identify standardised screening processes that are based not only on predicting mortality and deterioration but also on anticipating the palliative care needs and predicting the rate and course of functional decline. This would prompt a comprehensive assessment to identify and meet their needs on time.},
	language = {en},
	number = {8},
	urldate = {2024-02-21},
	journal = {Palliative Medicine},
	author = {ElMokhallalati, Yousuf and Bradley, Stephen H and Chapman, Emma and Ziegler, Lucy and Murtagh, Fliss EM and Johnson, Miriam J and Bennett, Michael I},
	month = sep,
	year = {2020},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {989--1005},
	file = {SAGE PDF Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/I5UGDZHD/ElMokhallalati et al. - 2020 - Identification of patients with potential palliati.pdf:application/pdf},
}

@article{ocallaghan_can_2014,
	title = {Can we predict which hospitalised patients are in their last year of life? {A} prospective cross-sectional study of the {Gold} {Standards} {Framework} {Prognostic} {Indicator} {Guidance} as a screening tool in the acute hospital setting},
	volume = {28},
	issn = {0269-2163},
	shorttitle = {Can we predict which hospitalised patients are in their last year of life?},
	url = {https://doi.org/10.1177/0269216314536089},
	doi = {10.1177/0269216314536089},
	abstract = {Background: Screening to identify hospital inpatients with a short life expectancy may be a way to improve care towards the end of life. The Gold Standards Framework Prognostic Indicator Guidance is a screening tool that has recently been advocated for use in the hospital setting.
Aim: To assess the clinical utility of the Gold Standards Framework Prognostic Indicator Guidance as a screening tool in an acute hospital setting.
Main outcome measures: Mortality at 6 and 12 months and sensitivity, specificity and predictive value of the Gold Standards Framework Prognostic Indicator Guidance at 1 year.
Design, setting and participants: Prospective cross-sectional study of 501 adult inpatients in a tertiary New Zealand teaching hospital screened utilising the Gold Standards Framework Prognostic Indicator Guidance.
Results: A total of 99 patients were identified as meeting at least one of the Gold Standards Framework Prognostic Indicator Guidance triggers. In this group, 6-month mortality was 56.6\% and 12-month mortality was 67.7\% compared with 5.2\% and 10\%, respectively, for those not identified as meeting the criteria. The sensitivity and specificity of the Gold Standards Framework Prognostic Indicator Guidance at 1 year were 62.6\% and 91.9\%, respectively, with a positive predictive value of 67.7\% and a negative predictive value of 90.0\%.
Conclusion: The sensitivity, specificity and predictive values of the Gold Standards Framework Prognostic Indicator Guidance in this study are comparable to, or better than, results of studies identifying patients with a limited life expectancy in particular disease states (e.g. heart failure and renal failure). Screening utilising the Gold Standards Framework Prognostic Indicator Guidance in the acute setting could be the first step towards implementing a more systematic way of addressing patient need – both current unrecognised and future anticipated – thereby improving outcomes for this population.},
	language = {en},
	number = {8},
	urldate = {2024-02-21},
	journal = {Palliative Medicine},
	author = {O’Callaghan, Anne and Laking, George and Frey, Rosemary and Robinson, Jackie and Gott, Merryn},
	month = sep,
	year = {2014},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {1046--1052},
	file = {SAGE PDF Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/CT36RNKE/O’Callaghan et al. - 2014 - Can we predict which hospitalised patients are in .pdf:application/pdf},
}

@article{shaw_review_2010,
	title = {Review: {Improving} end-of-life care: a critical review of the {Gold} {Standards} {Framework} in primary care},
	volume = {24},
	issn = {0269-2163},
	shorttitle = {Review},
	url = {https://doi.org/10.1177/0269216310362005},
	doi = {10.1177/0269216310362005},
	abstract = {The Gold Standards Framework aims to optimize primary palliative care for patients nearing the end of their lives. This paper critically reviews the impact of the Gold Standards Framework since its introduction in 2001 and indicates direction for further research and development. Literature was accessed using specific databases and by contacting subject area specialists. The resultant literature was appraised using an established framework to evaluate healthcare interventions. Fifteen documents were reviewed. The quality of evidence is constrained by methodological limitations, but consistently demonstrates that the Gold Standards Framework improves general practice processes, co-working and the quality of palliative care. However, implementation of the Gold Standards Framework is variable and the direct impact on patients and carers is not known. We conclude that the Gold Standards Framework has considerable potential to improve end-of-life care, but further work is needed to support uptake and consistency of implementation. Additional evidence about patient and carer outcomes will add to existing insights.},
	language = {en},
	number = {3},
	urldate = {2024-02-12},
	journal = {Palliative Medicine},
	author = {Shaw, KL and Clifford, C. and Thomas, K. and Meehan, H.},
	month = apr,
	year = {2010},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {317--329},
	file = {SAGE PDF Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/RYTEKAM8/Shaw et al. - 2010 - Review Improving end-of-life care a critical rev.pdf:application/pdf},
}

@misc{mccurrie_predicting_2017,
	title = {Predicting {First} {Impressions} with {Deep} {Learning}},
	url = {http://arxiv.org/abs/1610.08119},
	doi = {10.48550/arXiv.1610.08119},
	abstract = {Describable visual facial attributes are now commonplace in human biometrics and affective computing, with existing algorithms even reaching a sufficient point of maturity for placement into commercial products. These algorithms model objective facets of facial appearance, such as hair and eye color, expression, and aspects of the geometry of the face. A natural extension, which has not been studied to any great extent thus far, is the ability to model subjective attributes that are assigned to a face based purely on visual judgements. For instance, with just a glance, our first impression of a face may lead us to believe that a person is smart, worthy of our trust, and perhaps even our admiration - regardless of the underlying truth behind such attributes. Psychologists believe that these judgements are based on a variety of factors such as emotional states, personality traits, and other physiognomic cues. But work in this direction leads to an interesting question: how do we create models for problems where there is no ground truth, only measurable behavior? In this paper, we introduce a new convolutional neural network-based regression framework that allows us to train predictive models of crowd behavior for social attribute assignment. Over images from the AFLW face database, these models demonstrate strong correlations with human crowd ratings.},
	urldate = {2024-02-09},
	publisher = {arXiv},
	author = {McCurrie, Mel and Beletti, Fernando and Parzianello, Lucas and Westendorp, Allen and Anthony, Samuel and Scheirer, Walter},
	month = may,
	year = {2017},
	note = {arXiv:1610.08119 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PKS3M366/McCurrie et al. - 2017 - Predicting First Impressions with Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/2RGFPETM/1610.html:text/html},
}

@misc{noauthor_clinical_nodate,
	title = {Clinical {Concept} {Embeddings} {Learned} from {Massive} {Sources} of {Multimodal} {Medical} {Data}},
	url = {https://www.worldscientific.com/doi/epdf/10.1142/9789811215636_0027},
	language = {en},
	urldate = {2024-02-09},
	doi = {10.1142/9789811215636_0027},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/PZ53G6CZ/9789811215636_0027.html:text/html;Submitted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/MPF85D7I/Clinical Concept Embeddings Learned from Massive S.pdf:application/pdf},
}

@article{luo_applying_2021,
	title = {Applying interpretable deep learning models to identify chronic cough patients using {EHR} data},
	volume = {210},
	issn = {0169-2607},
	url = {https://www.sciencedirect.com/science/article/pii/S0169260721004697},
	doi = {10.1016/j.cmpb.2021.106395},
	abstract = {Background and Objective
Chronic cough (CC) affects approximately 10\% of adults. Many disease states are associated with chronic cough, such as asthma, upper airway cough syndrome, bronchitis, and gastroesophageal reflux disease. The lack of an ICD code specific for chronic cough makes it challenging to identify such patients from electronic health records (EHRs). For clinical and research purposes, computational methods using EHR data are urgently needed to identify chronic cough cases. This research aims to investigate the data representations and deep learning algorithms for chronic cough prediction.
Methods
Utilizing real-world EHR data from a large academic healthcare system from October 2005 to September 2015, we investigated Natural Language Representation of the EHR data and systematically evaluated deep learning and traditional machine learning models to predict chronic cough patients. We built these machine learning models using structured data (medication and diagnosis) and unstructured data (clinical notes).
Results
The sensitivity and specificity of a transformer-based deep learning algorithm, specifically BERT with attention model, was 0.856 and 0.866, respectively, using structured data (medication and diagnosis). Sensitivity and specificity improved to 0.952 and 0.930 when we combined structured data with symptoms extracted from clinical notes. We further found that the attention mechanism of deep learning models can be used to extract important features that drive the prediction decisions. Compared with our previously published rule-based algorithm, the deep learning algorithm can identify more chronic cough patients with structured data.
Conclusions
By applying deep learning models, chronic cough patients can be reliably identified for prospective or retrospective research through medication and diagnosis data, widely available in EHR and electronic claims data, thus improving the generalizability of the patient identification algorithm. Deep learning models can identify chronic cough patients with even higher sensitivity and specificity when structured and unstructured EHR data are utilized. We anticipate language-based data representation and deep learning models developed in this research could also be productively used for other disease prediction and case identification.},
	urldate = {2024-02-09},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Luo, Xiao and Gandhi, Priyanka and Zhang, Zuoyi and Shao, Wei and Han, Zhi and Chandrasekaran, Vasu and Turzhitsky, Vladimir and Bali, Vishal and Roberts, Anna R. and Metzger, Megan and Baker, Jarod and La Rosa, Carmen and Weaver, Jessica and Dexter, Paul and Huang, Kun},
	month = oct,
	year = {2021},
	keywords = {Machine learning, Algorithms, Chronic cough, Deep learning, Electronic health records, Nlp},
	pages = {106395},
	file = {ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/5DHMLW95/S0169260721004697.html:text/html},
}

@article{meng_bidirectional_2021,
	title = {Bidirectional {Representation} {Learning} {From} {Transformers} {Using} {Multimodal} {Electronic} {Health} {Record} {Data} to {Predict} {Depression}},
	volume = {25},
	issn = {2168-2208},
	url = {https://ieeexplore.ieee.org/abstract/document/9369833?casa_token=uyerNODaKocAAAAA:d-lobJ36fvqaTYVrXJUvvUgzvpjsIChKk0o5bxf1Y2hdPcXti0AontDid5Qv7Re3c_838Q4xJQ},
	doi = {10.1109/JBHI.2021.3063721},
	abstract = {Advancements in machine learning algorithms have had a beneficial impact on representation learning, classification, and prediction models built using electronic health record (EHR) data. Effort has been put both on increasing models' overall performance as well as improving their interpretability, particularly regarding the decision-making process. In this study, we present a temporal deep learning model to perform bidirectional representation learning on EHR sequences with a transformer architecture to predict future diagnosis of depression. This model is able to aggregate five heterogenous and high-dimensional data sources from the EHR and process them in a temporal manner for chronic disease prediction at various prediction windows. We applied the current trend of pretraining and fine-tuning on EHR data to outperform the current state-of-the-art in chronic disease prediction, and to demonstrate the underlying relation between EHR codes in the sequence. The model generated the highest increases of precision-recall area under the curve (PRAUC) from 0.70 to 0.76 in depression prediction compared to the best baseline model. Furthermore, the self-attention weights in each sequence quantitatively demonstrated the inner relationship between various codes, which improved the model's interpretability. These results demonstrate the model's ability to utilize heterogeneous EHR data to predict depression while achieving high accuracy and interpretability, which may facilitate constructing clinical decision support systems in the future for chronic disease screening and early detection.},
	number = {8},
	urldate = {2024-02-09},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Meng, Yiwen and Speier, William and Ong, Michael K. and Arnold, Corey W.},
	month = aug,
	year = {2021},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	keywords = {Clinical decision support, Biological system modeling, Data models, depression, Depression, Diseases, electronic health record, Medical diagnostic imaging, natural language processing, Predictive models, temporal representation and reasoning, Vocabulary},
	pages = {3121--3129},
	file = {Accepted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/BPNGAUXT/Meng et al. - 2021 - Bidirectional Representation Learning From Transfo.pdf:application/pdf;IEEE Xplore Abstract Record:/home/extasia/snap/zotero-snap/common/Zotero/storage/9V75U85T/9369833.html:text/html},
}

@article{amirahmadi_deep_2023,
	title = {Deep learning prediction models based on {EHR} trajectories: {A} systematic review},
	volume = {144},
	issn = {15320464},
	shorttitle = {Deep learning prediction models based on {EHR} trajectories},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S153204642300151X},
	doi = {10.1016/j.jbi.2023.104430},
	abstract = {Background : Electronic health records (EHRs) are generated at an ever-increasing rate. EHR trajectories, the temporal aspect of health records, facilitate predicting patients’ future health-related risks. It enables healthcare systems to increase the quality of care through early identification and primary prevention. Deep learning techniques have shown great capacity for analyzing complex data and have been successful for prediction tasks using complex EHR trajectories. This systematic review aims to analyze recent studies to identify challenges, knowledge gaps, and ongoing research directions.
Methods: For this systematic review, we searched Scopus, PubMed, IEEE Xplore, and ACM databases from Jan 2016 to April 2022 using search terms centered around EHR, deep learning, and trajectories. Then the selected papers were analyzed according to publication characteristics, objectives, and their solutions regarding existing challenges, such as the model’s capacity to deal with intricate data dependencies, data insufficiency, and explainability.
Results : After removing duplicates and out-of-scope papers, 63 papers were selected, which showed rapid growth in the number of research in recent years. Predicting all diseases in the next visit and the onset of cardiovascular diseases were the most common targets. Different contextual and non-contextual representation learning methods are employed to retrieve important information from the sequence of EHR trajectories. Recurrent neural networks and the time-aware attention mechanism for modeling long-term dependencies, self-attentions, convolutional neural networks, graphs for representing inner visit relations, and attention scores for explainability were frequently used among the reviewed publications.
Conclusions: This systematic review demonstrated how recent breakthroughs in deep learning methods have facilitated the modeling of EHR trajectories. Research on improving the ability of graph neural networks, attention mechanisms, and cross-modal learning to analyze intricate dependencies among EHRs has shown good progress. There is a need to increase the number of publicly available EHR trajectory datasets to allow for easier comparison among different models. Also, very few developed models can handle all aspects of EHR trajectory data.},
	language = {en},
	urldate = {2024-02-09},
	journal = {Journal of Biomedical Informatics},
	author = {Amirahmadi, Ali and Ohlsson, Mattias and Etminani, Kobra},
	month = aug,
	year = {2023},
	pages = {104430},
	file = {Amirahmadi et al. - 2023 - Deep learning prediction models based on EHR traje.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/W4ZDT73P/Amirahmadi et al. - 2023 - Deep learning prediction models based on EHR traje.pdf:application/pdf},
}

@article{rajkomar_scalable_2018,
	title = {Scalable and accurate deep learning with electronic health records},
	volume = {1},
	copyright = {2018 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-018-0029-1},
	doi = {10.1038/s41746-018-0029-1},
	abstract = {Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient’s record. We propose a representation of patients’ entire raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two US academic medical centers with 216,221 adult patients hospitalized for at least 24 h. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting: in-hospital mortality (area under the receiver operator curve [AUROC] across sites 0.93–0.94), 30-day unplanned readmission (AUROC 0.75–0.76), prolonged length of stay (AUROC 0.85–0.86), and all of a patient’s final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed traditional, clinically-used predictive models in all cases. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios. In a case study of a particular prediction, we demonstrate that neural networks can be used to identify relevant information from the patient’s chart.},
	language = {en},
	number = {1},
	urldate = {2024-02-07},
	journal = {npj Digital Medicine},
	author = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Hardt, Michaela and Liu, Peter J. and Liu, Xiaobing and Marcus, Jake and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Zhang, Yi and Flores, Gerardo and Duggan, Gavin E. and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael D. and Cui, Claire and Corrado, Greg S. and Dean, Jeffrey},
	month = may,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Machine learning, Medical research},
	pages = {1--10},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/8ZM6APW3/Rajkomar et al. - 2018 - Scalable and accurate deep learning with electroni.pdf:application/pdf},
}

@misc{singh_prediction_2023,
	title = {A prediction algorithm to improve the accuracy of the {Gold} {Standard} {Framework} {Surprise} {Question} end-of-life prognostic categories in an acute hospital admission cohort-controlled study. {The} {Proactive} {Risk}-{Based} and {Data}-{Driven} {Assessment} of {Patients} at the {End} of {Life} ({PRADA})},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2023.09.07.23295196v1},
	doi = {10.1101/2023.09.07.23295196},
	abstract = {Objective To determine the accuracy of a clinical data algorithm allocated end-of-life prognosis amongst hospital inpatients.
Method The model allocated a predicted Gold Standard Framework end-of-life prognosis to all acute medical patients admitted over a 2-year period. Mortality was determined at 1 year.
Results Of 18,838 patients, end-of-life prognosis was unknown in 67.9\%. A binary logistic regression model calculated 1-year mortality probability (X2=6650.2, p{\textless}0.001, r2 = 0.43). Probability cut off points were used to triage those with unknown prognosis using the GSF Surprise Question “Yes” or “No” survival categories ({\textgreater} or {\textless} 1 year respectively), with subsidiary classification of “No” to Green (months), Amber (weeks) or Red (days). This digitally driven prognosis allocation (100\% vs baseline 32.1\%) yielded cohorts of GSFSQ-Yes 15,264 (81\%), GSFSQ-No Green 1,771 (9.4\%) and GSFSQ-No Amber or Red 1,803 (9.6\%).There were 5,043 (26.8\%) deaths at 1 year. In Cox’s survival, model allocated cohorts were discrete for mortality (GSFSQ-Yes 16.4\% v GSFSQ-No 71.0\% (p{\textless}0.001). For the GSFSQ-No classification, the mortality Odds Ratio was 12.4 (11.4 – 13.5) (p{\textless}0.001) vs GSFSQ-Yes (c-statistic of 0.71 (0.70 – 0.73), p{\textless}0.001; accuracy, positive and negative predictive values of 81.2\%, 83.6\%, 83.6\% respectively. If this tool had been utilised at the time of admission, the potential to reduce subsequent hospital admissions, death-in-hospital, and bed days was all p{\textless}0.001.
Conclusions The defined model successfully allocated end-of-life prognosis in cohorts of hospitalised patients with strong performance metrics for prospective 1 year mortality, yielding the potential to provide anticipatory care and improve outcomes.
What is already known about this topic?End-of-life care is fragmented with excessive hospital admission and death in hospital. Current processes to determine end-of-life prognosis and promote anticipatory care for better outcomes are of limited utility.
What this paper adds?A patient centric data integration model permitted the development of a digital health care system (PRADA) which allows the use of advanced analytics to accurately determine end-of-life prognosis among those where it was otherwise unknown. This paper demonstrates the potential benefit of integrating this prediction tool into routine care, at scale, in large population-level cohorts.
Implications for practice, theory, or policy In an era of advancing opportunity from informatics driven heath care, NHS policy, through commissioning to direct care, must now actively deploy such evidence-based digital systems into direct care, most specifically in data sharing across provider boundaries. We particularly hope the research community might consider testing and validating this approach.},
	language = {en},
	urldate = {2024-02-06},
	publisher = {medRxiv},
	author = {Singh, Baldev and Kumari-Dewat, Nisha and Ryder, Adam and Klaire, Vijay and Bennion, Gemma and Jennens, Hannah and Matthews, Dawn and Rayner, Sophie and Ritzenthaler, Benoit and Shears, Jean and Ahmed, Kamran and Sidhu, Mona and Viswanath, Ananth and Warren, Kate and Parry, Emma},
	month = sep,
	year = {2023},
	note = {Pages: 2023.09.07.23295196},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/6M5TU3TL/Singh et al. - 2023 - A prediction algorithm to improve the accuracy of .pdf:application/pdf},
}

@misc{kraljevic_multi-domain_2021,
	title = {Multi-domain {Clinical} {Natural} {Language} {Processing} with {MedCAT}: the {Medical} {Concept} {Annotation} {Toolkit}},
	shorttitle = {Multi-domain {Clinical} {Natural} {Language} {Processing} with {MedCAT}},
	url = {http://arxiv.org/abs/2010.01165},
	abstract = {Electronic health records (EHR) contain large volumes of unstructured text, requiring the application of Information Extraction (IE) technologies to enable clinical analysis. We present the open-source Medical Concept Annotation Toolkit (MedCAT) that provides: a) a novel self-supervised machine learning algorithm for extracting concepts using any concept vocabulary including UMLS/SNOMED-CT; b) a feature-rich annotation interface for customising and training IE models; and c) integrations to the broader CogStack ecosystem for vendor-agnostic health system deployment. We show improved performance in extracting UMLS concepts from open datasets (F1:0.448-0.738 vs 0.429-0.650). Further real-world validation demonstrates SNOMED-CT extraction at 3 large London hospitals with self-supervised training over {\textasciitilde}8.8B words from {\textasciitilde}17M clinical records and further fine-tuning with {\textasciitilde}6K clinician annotated examples. We show strong transferability (F1 {\textgreater} 0.94) between hospitals, datasets, and concept types indicating cross-domain EHR-agnostic utility for accelerated clinical and research use cases.},
	urldate = {2024-01-25},
	publisher = {arXiv},
	author = {Kraljevic, Zeljko and Searle, Thomas and Shek, Anthony and Roguski, Lukasz and Noor, Kawsar and Bean, Daniel and Mascio, Aurelie and Zhu, Leilei and Folarin, Amos A. and Roberts, Angus and Bendayan, Rebecca and Richardson, Mark P. and Stewart, Robert and Shah, Anoop D. and Wong, Wai Keong and Ibrahim, Zina and Teo, James T. and Dobson, Richard JB},
	month = mar,
	year = {2021},
	note = {arXiv:2010.01165 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/MUBLVBYB/2010.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EK7YAVM2/Kraljevic et al. - 2021 - Multi-domain Clinical Natural Language Processing .pdf:application/pdf},
}

@misc{ouyang_training_2022,
	title = {Training language models to follow instructions with human feedback},
	url = {http://arxiv.org/abs/2203.02155},
	doi = {10.48550/arXiv.2203.02155},
	abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
	urldate = {2024-01-23},
	publisher = {arXiv},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	month = mar,
	year = {2022},
	note = {arXiv:2203.02155 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PUQQPWLA/Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZQK3NQXY/2203.html:text/html},
}

@misc{li_graphix-t5_2023,
	title = {Graphix-{T5}: {Mixing} {Pre}-{Trained} {Transformers} with {Graph}-{Aware} {Layers} for {Text}-to-{SQL} {Parsing}},
	shorttitle = {Graphix-{T5}},
	url = {http://arxiv.org/abs/2301.07507},
	abstract = {The task of text-to-SQL parsing, which aims at converting natural language questions into executable SQL queries, has garnered increasing attention in recent years, as it can assist end users in efficiently extracting vital information from databases without the need for technical background. One of the major challenges in text-to-SQL parsing is domain generalization, i.e., how to generalize well to unseen databases. Recently, the pre-trained text-to-text transformer model, namely T5, though not specialized for text-to-SQL parsing, has achieved state-of-the-art performance on standard benchmarks targeting domain generalization. In this work, we explore ways to further augment the pre-trained T5 model with specialized components for text-to-SQL parsing. Such components are expected to introduce structural inductive bias into text-to-SQL parsers thus improving model's capacity on (potentially multi-hop) reasoning, which is critical for generating structure-rich SQLs. To this end, we propose a new architecture GRAPHIX-T5, a mixed model with the standard pre-trained transformer model augmented by some specially-designed graph-aware layers. Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5 across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5 surpass all other T5-based parsers with a significant margin, achieving new state-of-the-art performance. Notably, GRAPHIX-T5-large reach performance superior to the original T5-large by 5.7\% on exact match (EM) accuracy and 6.6\% on execution accuracy (EX). This even outperforms the T5-3B by 1.2\% on EM and 1.5\% on EX.},
	urldate = {2024-01-22},
	publisher = {arXiv},
	author = {Li, Jinyang and Hui, Binyuan and Cheng, Reynold and Qin, Bowen and Ma, Chenhao and Huo, Nan and Huang, Fei and Du, Wenyu and Si, Luo and Li, Yongbin},
	month = jan,
	year = {2023},
	note = {arXiv:2301.07507 [cs]
version: 1},
	keywords = {Computer Science - Computation and Language, Computer Science - Databases},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/6GBYL4HX/2301.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2PXZMPPX/Li et al. - 2023 - Graphix-T5 Mixing Pre-Trained Transformers with G.pdf:application/pdf},
}

@misc{van_breugel_can_2023,
	title = {Can {You} {Rely} on {Your} {Model} {Evaluation}? {Improving} {Model} {Evaluation} with {Synthetic} {Test} {Data}},
	shorttitle = {Can {You} {Rely} on {Your} {Model} {Evaluation}?},
	url = {http://arxiv.org/abs/2310.16524},
	doi = {10.48550/arXiv.2310.16524},
	abstract = {Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model's deployment setting, which may not align with the available test data. In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S Testing outperforms traditional baselines -- including real test data alone -- in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches. Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data.},
	urldate = {2024-01-17},
	publisher = {arXiv},
	author = {van Breugel, Boris and Seedat, Nabeel and Imrie, Fergus and van der Schaar, Mihaela},
	month = oct,
	year = {2023},
	note = {arXiv:2310.16524 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GM7GC5DM/van Breugel et al. - 2023 - Can You Rely on Your Model Evaluation Improving M.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/PK79C3TK/2310.html:text/html},
}

@misc{sanborn_general_2023,
	title = {A {General} {Framework} for {Robust} {G}-{Invariance} in {G}-{Equivariant} {Networks}},
	url = {http://arxiv.org/abs/2310.18564},
	abstract = {We introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks (\$G\$-CNNs), which we call the \$G\$-triple-correlation (\$G\$-TC) layer. The approach leverages the theory of the triple-correlation on groups, which is the unique, lowest-degree polynomial invariant map that is also complete. Many commonly used invariant maps - such as the max - are incomplete: they remove both group and signal structure. A complete invariant, by contrast, removes only the variation due to the actions of the group, while preserving all information about the structure of the signal. The completeness of the triple correlation endows the \$G\$-TC layer with strong robustness, which can be observed in its resistance to invariance-based adversarial attacks. In addition, we observe that it yields measurable improvements in classification accuracy over standard Max \$G\$-Pooling in \$G\$-CNN architectures. We provide a general and efficient implementation of the method for any discretized group, which requires only a table defining the group's product structure. We demonstrate the benefits of this method for \$G\$-CNNs defined on both commutative and non-commutative groups - \$SO(2)\$, \$O(2)\$, \$SO(3)\$, and \$O(3)\$ (discretized as the cyclic \$C8\$, dihedral \$D16\$, chiral octahedral \$O\$ and full octahedral \$O\_h\$ groups) - acting on \${\textbackslash}mathbb\{R\}{\textasciicircum}2\$ and \${\textbackslash}mathbb\{R\}{\textasciicircum}3\$ on both \$G\$-MNIST and \$G\$-ModelNet10 datasets.},
	urldate = {2024-01-22},
	publisher = {arXiv},
	author = {Sanborn, Sophia and Miolane, Nina},
	month = oct,
	year = {2023},
	note = {arXiv:2310.18564 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/Y43UGVTD/2310.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GMPG2Z6R/Sanborn and Miolane - 2023 - A General Framework for Robust G-Invariance in G-E.pdf:application/pdf},
}

@misc{olko_trust_2023,
	title = {Trust {Your} \${\textbackslash}nabla\$: {Gradient}-based {Intervention} {Targeting} for {Causal} {Discovery}},
	shorttitle = {Trust {Your} \${\textbackslash}nabla\$},
	url = {http://arxiv.org/abs/2211.13715},
	abstract = {Inferring causal structure from data is a challenging task of fundamental importance in science. Observational data are often insufficient to identify a system's causal structure uniquely. While conducting interventions (i.e., experiments) can improve the identifiability, such samples are usually challenging and expensive to obtain. Hence, experimental design approaches for causal discovery aim to minimize the number of interventions by estimating the most informative intervention target. In this work, we propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention acquisition function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.},
	urldate = {2024-01-22},
	publisher = {arXiv},
	author = {Olko, Mateusz and Zając, Michał and Nowak, Aleksandra and Scherrer, Nino and Annadani, Yashas and Bauer, Stefan and Kuciński, Łukasz and Miłoś, Piotr},
	month = dec,
	year = {2023},
	note = {arXiv:2211.13715 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZCUI87DW/2211.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/5JCHZIZM/Olko et al. - 2023 - Trust Your \$nabla\$ Gradient-based Intervention T.pdf:application/pdf},
}

@inproceedings{guo_towards_2019,
	address = {Florence, Italy},
	title = {Towards {Complex} {Text}-to-{SQL} in {Cross}-{Domain} {Database} with {Intermediate} {Representation}},
	url = {https://aclanthology.org/P19-1444},
	doi = {10.18653/v1/P19-1444},
	abstract = {We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges: 1) the mismatch between intents expressed in natural language (NL) and the implementation details in SQL; 2) the challenge in predicting columns caused by the large number of out-of-domain words. Instead of end-to-end synthesizing a SQL query, IRNet decomposes the synthesis process into three phases. In the first phase, IRNet performs a schema linking over a question and a database schema. Then, IRNet adopts a grammar-based neural model to synthesize a SemQL query which is an intermediate representation that we design to bridge NL and SQL. Finally, IRNet deterministically infers a SQL query from the synthesized SemQL query with domain knowledge. On the challenging Text-to-SQL benchmark Spider, IRNet achieves 46.7\% accuracy, obtaining 19.5\% absolute improvement over previous state-of-the-art approaches. At the time of writing, IRNet achieves the first position on the Spider leaderboard.},
	urldate = {2024-01-22},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Guo, Jiaqi and Zhan, Zecheng and Gao, Yan and Xiao, Yan and Lou, Jian-Guang and Liu, Ting and Zhang, Dongmei},
	editor = {Korhonen, Anna and Traum, David and Màrquez, Lluís},
	month = jul,
	year = {2019},
	pages = {4524--4535},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/TNGUVNVX/Guo et al. - 2019 - Towards Complex Text-to-SQL in Cross-Domain Databa.pdf:application/pdf},
}

@article{katsogiannis-meimarakis_survey_2023,
	title = {A survey on deep learning approaches for text-to-{SQL}},
	volume = {32},
	issn = {0949-877X},
	url = {https://doi.org/10.1007/s00778-022-00776-8},
	doi = {10.1007/s00778-022-00776-8},
	abstract = {To bridge the gap between users and data, numerous text-to-SQL systems have been developed that allow users to pose natural language questions over relational databases. Recently, novel text-to-SQL systems are adopting deep learning methods with very promising results. At the same time, several challenges remain open making this area an active and flourishing field of research and development. To make real progress in building text-to-SQL systems, we need to de-mystify what has been done, understand how and when each approach can be used, and, finally, identify the research challenges ahead of us. The purpose of this survey is to present a detailed taxonomy of neural text-to-SQL systems that will enable a deeper study of all the parts of such a system. This taxonomy will allow us to make a better comparison between different approaches, as well as highlight specific challenges in each step of the process, thus enabling researchers to better strategise their quest towards the “holy grail” of database accessibility.},
	language = {en},
	number = {4},
	urldate = {2024-01-22},
	journal = {The VLDB Journal},
	author = {Katsogiannis-Meimarakis, George and Koutrika, Georgia},
	month = jul,
	year = {2023},
	keywords = {Deep learning, Natural language interface for databases, Natural language processing, Text-to-SQL},
	pages = {905--936},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GG7HECZY/Katsogiannis-Meimarakis and Koutrika - 2023 - A survey on deep learning approaches for text-to-S.pdf:application/pdf},
}

@inproceedings{kanakarajan_bioelectrapretrained_2021,
	address = {Online},
	title = {{BioELECTRA}:{Pretrained} {Biomedical} text {Encoder} using {Discriminators}},
	shorttitle = {{BioELECTRA}},
	url = {https://aclanthology.org/2021.bionlp-1.16},
	doi = {10.18653/v1/2021.bionlp-1.16},
	abstract = {Recent advancements in pretraining strategies in NLP have shown a significant improvement in the performance of models on various text mining tasks. We apply `replaced token detection' pretraining technique proposed by ELECTRA and pretrain a biomedical language model from scratch using biomedical text and vocabulary. We introduce BioELECTRA, a biomedical domain-specific language encoder model that adapts ELECTRA for the Biomedical domain. WE evaluate our model on the BLURB and BLUE biomedical NLP benchmarks. BioELECTRA outperforms the previous models and achieves state of the art (SOTA) on all the 13 datasets in BLURB benchmark and on all the 4 Clinical datasets from BLUE Benchmark across 7 different NLP tasks. BioELECTRA pretrained on PubMed and PMC full text articles performs very well on Clinical datasets as well. BioELECTRA achieves new SOTA 86.34\%(1.39\% accuracy improvement) on MedNLI and 64\% (2.98\% accuracy improvement) on PubMedQA dataset.},
	urldate = {2024-01-05},
	booktitle = {Proceedings of the 20th {Workshop} on {Biomedical} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Kanakarajan, Kamal raj and Kundumani, Bhuvana and Sankarasubbu, Malaikannan},
	editor = {Demner-Fushman, Dina and Cohen, Kevin Bretonnel and Ananiadou, Sophia and Tsujii, Junichi},
	month = jun,
	year = {2021},
	pages = {143--154},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/VD9IYRUP/Kanakarajan et al. - 2021 - BioELECTRAPretrained Biomedical text Encoder usin.pdf:application/pdf},
}

@misc{lu_investigating_2020,
	title = {Investigating the {Effectiveness} of {Representations} {Based} on {Pretrained} {Transformer}-based {Language} {Models} in {Active} {Learning} for {Labelling} {Text} {Datasets}},
	url = {http://arxiv.org/abs/2004.13138},
	abstract = {Active learning has been shown to be an effective way to alleviate some of the effort required in utilising large collections of unlabelled data for machine learning tasks without needing to fully label them. The representation mechanism used to represent text documents when performing active learning, however, has a significant influence on how effective the process will be. While simple vector representations such as bag-of-words and embedding-based representations based on techniques such as word2vec have been shown to be an effective way to represent documents during active learning, the emergence of representation mechanisms based on the pre-trained transformer-based neural network models popular in natural language processing research (e.g. BERT) offer a promising, and as yet not fully explored, alternative. This paper describes a comprehensive evaluation of the effectiveness of representations based on pre-trained transformer-based language models for active learning. This evaluation shows that transformer-based models, especially BERT-like models, that have not yet been widely used in active learning, achieve a significant improvement over more commonly used vector representations like bag-of-words or other classical word embeddings like word2vec. This paper also investigates the effectiveness of representations based on variants of BERT such as Roberta, Albert as well as comparing the effectiveness of the [CLS] token representation and the aggregated representation that can be generated using BERT-like models. Finally, we propose an approach Adaptive Tuning Active Learning. Our experiments show that the limited label information acquired in active learning can not only be used for training a classifier but can also adaptively improve the embeddings generated by the BERT-like language models as well.},
	urldate = {2024-01-04},
	publisher = {arXiv},
	author = {Lu, Jinghui and MacNamee, Brian},
	month = apr,
	year = {2020},
	note = {arXiv:2004.13138 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/NSDQ9T8C/2004.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/57IQ5D2J/Lu and MacNamee - 2020 - Investigating the Effectiveness of Representations.pdf:application/pdf},
}

@misc{liang_cross-lingual_2023,
	title = {Cross-lingual {German} {Biomedical} {Information} {Extraction}: from {Zero}-shot to {Human}-in-the-{Loop}},
	shorttitle = {Cross-lingual {German} {Biomedical} {Information} {Extraction}},
	url = {http://arxiv.org/abs/2301.09908},
	abstract = {This paper presents our project proposal for extracting biomedical information from German clinical narratives with limited amounts of annotations. We first describe the applied strategies in transfer learning and active learning for solving our problem. After that, we discuss the design of the user interface for both supplying model inspection and obtaining user annotations in the interactive environment.},
	urldate = {2024-01-04},
	publisher = {arXiv},
	author = {Liang, Siting and Hartmann, Mareike and Sonntag, Daniel},
	month = jan,
	year = {2023},
	note = {arXiv:2301.09908 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/SGTJ7CCC/2301.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/6KI5VRA5/Liang et al. - 2023 - Cross-lingual German Biomedical Information Extrac.pdf:application/pdf},
}

@article{bernhardt_active_2022,
	title = {Active label cleaning for improved dataset quality under resource constraints},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28818-3},
	doi = {10.1038/s41467-022-28818-3},
	abstract = {Imperfections in data annotation, known as label noise, are detrimental to the training of machine learning models and have a confounding effect on the assessment of model performance. Nevertheless, employing experts to remove label noise by fully re-annotating large datasets is infeasible in resource-constrained settings, such as healthcare. This work advocates for a data-driven approach to prioritising samples for re-annotation—which we term “active label cleaning". We propose to rank instances according to estimated label correctness and labelling difficulty of each sample, and introduce a simulation framework to evaluate relabelling efficacy. Our experiments on natural images and on a specifically-devised medical imaging benchmark show that cleaning noisy labels mitigates their negative impact on model training, evaluation, and selection. Crucially, the proposed approach enables correcting labels up to 4 × more effectively than typical random selection in realistic conditions, making better use of experts’ valuable time for improving dataset quality.},
	language = {en},
	number = {1},
	urldate = {2024-01-04},
	journal = {Nature Communications},
	author = {Bernhardt, Mélanie and Castro, Daniel C. and Tanno, Ryutaro and Schwaighofer, Anton and Tezcan, Kerem C. and Monteiro, Miguel and Bannur, Shruthi and Lungren, Matthew P. and Nori, Aditya and Glocker, Ben and Alvarez-Valle, Javier and Oktay, Ozan},
	month = mar,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Machine learning, Diagnosis, Radiography},
	pages = {1161},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KSGEUVC2/Bernhardt et al. - 2022 - Active label cleaning for improved dataset quality.pdf:application/pdf},
}

@inproceedings{sap_developing_2014,
	address = {Doha, Qatar},
	title = {Developing {Age} and {Gender} {Predictive} {Lexica} over {Social} {Media}},
	url = {https://aclanthology.org/D14-1121},
	doi = {10.3115/v1/D14-1121},
	urldate = {2023-12-03},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Sap, Maarten and Park, Gregory and Eichstaedt, Johannes and Kern, Margaret and Stillwell, David and Kosinski, Michal and Ungar, Lyle and Schwartz, Hansen Andrew},
	editor = {Moschitti, Alessandro and Pang, Bo and Daelemans, Walter},
	month = oct,
	year = {2014},
	pages = {1146--1151},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EUJ63LFR/Sap et al. - 2014 - Developing Age and Gender Predictive Lexica over S.pdf:application/pdf},
}

@misc{belcak_exponentially_2023,
	title = {Exponentially {Faster} {Language} {Modelling}},
	url = {http://arxiv.org/abs/2311.10770},
	abstract = {Language models only really need to use an exponential fraction of their neurons for individual inferences. As proof, we present UltraFastBERT, a BERT variant that uses 0.3\% of its neurons during inference while performing on par with similar BERT models. UltraFastBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by replacing feedforward networks with fast feedforward networks (FFFs). While no truly efficient implementation currently exists to unlock the full acceleration potential of conditional neural execution, we provide high-level CPU code achieving 78x speedup over the optimized baseline feedforward implementation, and a PyTorch implementation delivering 40x speedup over the equivalent batched feedforward inference. We publish our training code, benchmarking setup, and model weights.},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Belcak, Peter and Wattenhofer, Roger},
	month = nov,
	year = {2023},
	note = {arXiv:2311.10770 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/H7A2GC4B/2311.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/DIQBSLW7/Belcak and Wattenhofer - 2023 - Exponentially Faster Language Modelling.pdf:application/pdf},
}

@misc{boyle_automated_2023,
	title = {Automated clinical coding using off-the-shelf large language models},
	url = {http://arxiv.org/abs/2310.06552},
	abstract = {The task of assigning diagnostic ICD codes to patient hospital admissions is typically performed by expert human coders. Efforts towards automated ICD coding are dominated by supervised deep learning models. However, difficulties in learning to predict the large number of rare codes remain a barrier to adoption in clinical practice. In this work, we leverage off-the-shelf pre-trained generative large language models (LLMs) to develop a practical solution that is suitable for zero-shot and few-shot code assignment, with no need for further task-specific training. Unsupervised pre-training alone does not guarantee precise knowledge of the ICD ontology and specialist clinical coding task, therefore we frame the task as information extraction, providing a description of each coded concept and asking the model to retrieve related mentions. For efficiency, rather than iterating over all codes, we leverage the hierarchical nature of the ICD ontology to sparsely search for relevant codes.},
	urldate = {2023-11-19},
	publisher = {arXiv},
	author = {Boyle, Joseph S. and Kascenas, Antanas and Lok, Pat and Liakata, Maria and O'Neil, Alison Q.},
	month = nov,
	year = {2023},
	note = {arXiv:2310.06552 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, I.2.7, I.2.8},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/6RRH2DDL/2310.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JXBAIY39/Boyle et al. - 2023 - Automated clinical coding using off-the-shelf larg.pdf:application/pdf},
}

@article{banker_moral_2023,
	title = {The moral foundations of cryptocurrency: evidence from {Twitter} and survey research},
	volume = {14},
	issn = {1664-1078},
	shorttitle = {The moral foundations of cryptocurrency},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10445040/},
	doi = {10.3389/fpsyg.2023.1128575},
	abstract = {Despite its relatively brief history, cryptocurrency has already had a profound impact on the economy, with some predicting that it will eventually replace traditional fiat currencies. Historically, it had dark associations with illegal activities in the early days, although perceptions and associations likely have, in recent years, changed for the better. Thus, understanding how people perceive the morality of cryptocurrency currently forms the motivation of the current research. We, in particular, examine associations dependent on political ideology. Across both a large-scale analysis of Twitter posts (N = 959,393) and controlled survey research (N = 487), we find that cryptocurrency is currently best understood as being more strongly linked to conservative vs. liberal moral foundations. Cryptocurrency-related posts were more likely to express conservative moral foundations (Authority, Purity, and Loyalty) rather than liberal moral foundations (Fairness and Care), and individual endorsement of these conservative moral foundations was associated with increased interest in crypto investment.},
	urldate = {2023-11-18},
	journal = {Frontiers in Psychology},
	author = {Banker, Sachin and Park, Joowon and Chan, Eugene Y.},
	month = aug,
	year = {2023},
	pmid = {37621936},
	pmcid = {PMC10445040},
	pages = {1128575},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/LRMP6QB6/Banker et al. - 2023 - The moral foundations of cryptocurrency evidence .pdf:application/pdf},
}

@inproceedings{agrawal_robust_2020,
	title = {Robust {Benchmarking} for {Machine} {Learning} of {Clinical} {Entity} {Extraction}},
	url = {https://proceedings.mlr.press/v126/agrawal20a.html},
	abstract = {Clinical studies often require understanding elements of a patient’s narrative that exist only in free text clinical notes. To transform notes into structured data for downstream use, these elements are commonly extracted and normalized to medical vocabularies. In this work, we audit the performance of and indicate areas of improvement for state-of-the-art systems. We find that high task accuracies for clinical entity normalization systems on the 2019 n2c2 Shared Task are misleading, and underlying performance is still brittle. Normalization accuracy is high for common concepts (95.3\%), but much lower for concepts unseen in training data (69.3\%). We demonstrate that current approaches are hindered in part by inconsistencies in medical vocabularies, limitations of existing labeling schemas, and narrow evaluation techniques. We reformulate the annotation framework for clinical entity extraction to factor in these issues to allow for robust end-to-end system benchmarking. We evaluate concordance of annotations from our new framework between two annotators and achieve a Jaccard similarity of 0.73 for entity recognition and an agreement of 0.83 for entity normalization. We propose a path forward to address the demonstrated need for the creation of a reference standard to spur method development in entity recognition and normalization.},
	language = {en},
	urldate = {2023-11-18},
	booktitle = {Proceedings of the 5th {Machine} {Learning} for {Healthcare} {Conference}},
	publisher = {PMLR},
	author = {Agrawal, Monica and O’Connell, Chloe and Fatemi, Yasmin and Levy, Ariel and Sontag, David},
	month = sep,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {928--949},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MYQCX5MV/Agrawal et al. - 2020 - Robust Benchmarking for Machine Learning of Clinic.pdf:application/pdf},
}

@article{boyle_year_nodate,
	title = {Year 1 {Progression} {Report}},
	language = {en},
	author = {Boyle, Joseph Spartacus},
	file = {Boyle - Year 1 Progression Report.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/QDCQENE4/Boyle - Year 1 Progression Report.pdf:application/pdf},
}

@misc{galles_testing_2013,
	title = {Testing {Identifiability} of {Causal} {Effects}},
	url = {http://arxiv.org/abs/1302.4948},
	doi = {10.48550/arXiv.1302.4948},
	abstract = {This paper concerns the probabilistic evaluation of the effects of actions in the presence of unmeasured variables. We show that the identification of causal effect between a singleton variable X and a set of variables Y can be accomplished systematically, in time polynomial in the number of variables in the graph. When the causal effect is identifiable, a closed-form expression can be obtained for the probability that the action will achieve a specified goal, or a set of goals.},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Galles, David and Pearl, Judea},
	month = feb,
	year = {2013},
	note = {arXiv:1302.4948 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/Z3QEBVWX/Galles and Pearl - 2013 - Testing Identifiability of Causal Effects.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/LCSKUDR6/1302.html:text/html},
}

@inproceedings{christiano_deep_2017,
	title = {Deep {Reinforcement} {Learning} from {Human} {Preferences}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html},
	abstract = {For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. Our approach separates learning the goal from learning the behavior to achieve it. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on about 0.1\% of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.},
	urldate = {2023-11-17},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
	year = {2017},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/3HQPCAFB/Christiano et al. - 2017 - Deep Reinforcement Learning from Human Preferences.pdf:application/pdf},
}

@misc{zhang_making_2023,
	title = {Making {Large} {Language} {Models} {Perform} {Better} in {Knowledge} {Graph} {Completion}},
	url = {http://arxiv.org/abs/2310.06671},
	abstract = {Large language model (LLM) based knowledge graph completion (KGC) aims to predict the missing triples in the KGs with LLMs and enrich the KGs to become better web infrastructure, which can benefit a lot of web-based automatic services. However, research about LLM-based KGC is limited and lacks effective utilization of LLM's inference capabilities, which ignores the important structural information in KGs and prevents LLMs from acquiring accurate factual knowledge. In this paper, we discuss how to incorporate the helpful KG structural information into the LLMs, aiming to achieve structrual-aware reasoning in the LLMs. We first transfer the existing LLM paradigms to structural-aware settings and further propose a knowledge prefix adapter (KoPA) to fulfill this stated goal. KoPA employs structural embedding pre-training to capture the structural information of entities and relations in the KG. Then KoPA informs the LLMs of the knowledge prefix adapter which projects the structural embeddings into the textual space and obtains virtual knowledge tokens as a prefix of the input prompt. We conduct comprehensive experiments on these structural-aware LLM-based KGC methods and provide an in-depth analysis comparing how the introduction of structural information would be better for LLM's knowledge reasoning ability. Our code is released at https://github.com/zjukg/KoPA.},
	urldate = {2023-11-17},
	publisher = {arXiv},
	author = {Zhang, Yichi and Chen, Zhuo and Zhang, Wen and Chen, Huajun},
	month = oct,
	year = {2023},
	note = {arXiv:2310.06671 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/KZW6YSGD/2310.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/3V8WICF9/Zhang et al. - 2023 - Making Large Language Models Perform Better in Kno.pdf:application/pdf},
}

@article{bates_effect_1998,
	title = {Effect of {Computerized} {Physician} {Order} {Entry} and a {Team} {Intervention} on {Prevention} of {Serious} {Medication} {Errors}},
	volume = {280},
	issn = {0098-7484},
	url = {https://doi.org/10.1001/jama.280.15.1311},
	doi = {10.1001/jama.280.15.1311},
	abstract = {Context.—Adverse drug events (ADEs) are a significant and costly cause of injury
during hospitalization.Objectives.—To evaluate the efficacy of 2 interventions for preventing nonintercepted
serious medication errors, defined as those that either resulted in or had
potential to result in an ADE and were not intercepted before reaching the
patient.Design.—Before-after comparison between phase 1 (baseline) and phase 2 (after
intervention was implemented) and, within phase 2, a randomized comparison
between physican computer order entry (POE) and the combination of POE plus
a team intervention.Setting.—Large tertiary care hospital.Participants.—For the comparison of phase 1 and 2, all patients admitted to a stratified
random sample of 6 medical and surgical units in a tertiary care hospital
over a 6-month period, and for the randomized comparison during phase 2, all
patients admitted to the same units and 2 randomly selected additional units
over a subsequent 9-month period.Interventions.—A physician computer order entry system (POE) for all units and a team-based
intervention that included changing the role of pharmacists, implemented for
half the units.Main Outcome Measure.—Nonintercepted serious medication errors.Results.—Comparing identical units between phases 1 and 2, nonintercepted serious
medication errors decreased 55\%, from 10.7 events per 1000 patient-days to
4.86 events per 1000 (P=.01). The decline occurred
for all stages of the medication-use process. Preventable ADEs declined 17\%
from 4.69 to 3.88 (P=.37), while nonintercepted potential
ADEs declined 84\% from 5.99 to 0.98 per 1000 patient-days (P=.002). When POE-only was compared with the POE plus team intervention
combined, the team intervention conferred no additonal benefit over POE.Conclusions.—Physician computer order entry decreased the rate of nonintercepted
serious medication errors by more than half, although this decrease was larger
for potential ADEs than for errors that actually resulted in an ADE.},
	number = {15},
	urldate = {2023-11-15},
	journal = {JAMA},
	author = {Bates, David W. and Leape, Lucian L. and Cullen, David J. and Laird, Nan and Petersen, Laura A. and Teich, Jonathan M. and Burdick, Elizabeth and Hickey, Mairead and Kleefield, Sharon and Shea, Brian and Vander Vliet, Martha and Seger, Diane L.},
	month = oct,
	year = {1998},
	pages = {1311--1316},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/FJJQ3FI5/188074.html:text/html},
}

@article{cui_mining_2017,
	title = {Mining non-lattice subgraphs for detecting missing hierarchical relations and concepts in {SNOMED} {CT}},
	volume = {24},
	doi = {10.1093/jamia/ocw175},
	abstract = {Objective: 
Quality assurance of large ontological systems such as SNOMED CT is an indispensable part of the terminology management lifecycle. We introduce a hybrid structural-lexical method for scalable and systematic discovery of missing hierarchical relations and concepts in SNOMED CT.

Material and methods:
All non-lattice subgraphs (the structural part) in SNOMED CT are exhaustively extracted using a scalable MapReduce algorithm. Four lexical patterns (the lexical part) are identified among the extracted non-lattice subgraphs. Non-lattice subgraphs exhibiting such lexical patterns are often indicative of missing hierarchical relations or concepts. Each lexical pattern is associated with a potential specific type of error.

Results:
Applying the structural-lexical method to SNOMED CT (September 2015 US edition), we found 6801 non-lattice subgraphs that matched these lexical patterns, of which 2046 were amenable to visual inspection. We evaluated a random sample of 100 small subgraphs, of which 59 were reviewed in detail by domain experts. All the subgraphs reviewed contained errors confirmed by the experts. The most frequent type of error was missing is-a relations due to incomplete or inconsistent modeling of the concepts.

Conclusions:
Our hybrid structural-lexical method is innovative and proved effective not only in detecting errors in SNOMED CT, but also in suggesting remediation for these errors.},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Cui, Licong and Zhu, Wei and Tao, Shiqiang and Case, James and Bodenreider, Olivier and Zhang, Guo-Qiang},
	month = feb,
	year = {2017},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/59JIXMAZ/Cui et al. - 2017 - Mining non-lattice subgraphs for detecting missing.pdf:application/pdf},
}

@article{tucker_generating_2020,
	title = {Generating high-fidelity synthetic patient data for assessing machine learning healthcare software},
	volume = {3},
	copyright = {2020 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-020-00353-9%3C},
	doi = {10.1038/s41746-020-00353-9},
	abstract = {There is a growing demand for the uptake of modern artificial intelligence technologies within healthcare systems. Many of these technologies exploit historical patient health data to build powerful predictive models that can be used to improve diagnosis and understanding of disease. However, there are many issues concerning patient privacy that need to be accounted for in order to enable this data to be better harnessed by all sectors. One approach that could offer a method of circumventing privacy issues is the creation of realistic synthetic data sets that capture as many of the complexities of the original data set (distributions, non-linear relationships, and noise) but that does not actually include any real patient data. While previous research has explored models for generating synthetic data sets, here we explore the integration of resampling, probabilistic graphical modelling, latent variable identification, and outlier analysis for producing realistic synthetic data based on UK primary care patient data. In particular, we focus on handling missingness, complex interactions between variables, and the resulting sensitivity analysis statistics from machine learning classifiers, while quantifying the risks of patient re-identification from synthetic datapoints. We show that, through our approach of integrating outlier analysis with graphical modelling and resampling, we can achieve synthetic data sets that are not significantly different from original ground truth data in terms of feature distributions, feature dependencies, and sensitivity analysis statistics when inferring machine learning classifiers. What is more, the risk of generating synthetic data that is identical or very similar to real patients is shown to be low.},
	language = {en},
	number = {1},
	urldate = {2023-11-08},
	journal = {npj Digital Medicine},
	author = {Tucker, Allan and Wang, Zhenchen and Rotalinti, Ylenia and Myles, Puja},
	month = nov,
	year = {2020},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Epidemiology, Risk factors, Statistics},
	pages = {1--13},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/FFGP5CS9/Tucker et al. - 2020 - Generating high-fidelity synthetic patient data fo.pdf:application/pdf},
}

@article{zeng_uncovering_2022,
	title = {Uncovering interpretable potential confounders in electronic medical records},
	volume = {13},
	copyright = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28546-8},
	doi = {10.1038/s41467-022-28546-8},
	abstract = {Randomized clinical trials (RCT) are the gold standard for informing treatment decisions. Observational studies are often plagued by selection bias, and expert-selected covariates may insufficiently adjust for confounding. We explore how unstructured clinical text can be used to reduce selection bias and improve medical practice. We develop a framework based on natural language processing to uncover interpretable potential confounders from text. We validate our method by comparing the estimated hazard ratio (HR) with and without the confounders against established RCTs. We apply our method to four cohorts built from localized prostate and lung cancer datasets from the Stanford Cancer Institute and show that our method shifts the HR estimate towards the RCT results. The uncovered terms can also be interpreted by oncologists for clinical insights. We present this proof-of-concept study to enable more credible causal inference using observational data, uncover meaningful insights from clinical text, and inform high-stakes medical decisions.},
	language = {en},
	number = {1},
	urldate = {2023-11-08},
	journal = {Nature Communications},
	author = {Zeng, Jiaming and Gensheimer, Michael F. and Rubin, Daniel L. and Athey, Susan and Shachter, Ross D.},
	month = feb,
	year = {2022},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Machine learning, Cancer therapy, Computational models, Data mining, Statistical methods},
	pages = {1014},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/XPL8YIL3/Zeng et al. - 2022 - Uncovering interpretable potential confounders in .pdf:application/pdf},
}

@book{koller_probabilistic_2009,
	address = {Cambridge, MA},
	series = {Adaptive computation and machine learning},
	title = {Probabilistic graphical models: principles and techniques},
	isbn = {978-0-262-01319-2},
	shorttitle = {Probabilistic graphical models},
	language = {en},
	publisher = {MIT Press},
	author = {Koller, Daphne and Friedman, Nir},
	year = {2009},
	keywords = {Bayesian statistical decision theory, Graphic methods, Graphical modeling (Statistics)},
	file = {Koller and Friedman - 2009 - Probabilistic graphical models principles and tec.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/Y2Z2E5GK/Koller and Friedman - 2009 - Probabilistic graphical models principles and tec.pdf:application/pdf},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2023-11-07},
	publisher = {arXiv},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv:1301.3781 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/N4HUXTSL/1301.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/UQF9G7YB/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf},
}

@article{heckerman_tutorial_nodate,
	title = {A {Tutorial} on {Learning} {With} {Bayesian} {Networks}},
	language = {en},
	author = {Heckerman, David},
	file = {Heckerman - A Tutorial on Learning With Bayesian Networks.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/B5HY99DB/Heckerman - A Tutorial on Learning With Bayesian Networks.pdf:application/pdf},
}

@inproceedings{wang_minilm_2020,
	title = {{MiniLM}: {Deep} {Self}-{Attention} {Distillation} for {Task}-{Agnostic} {Compression} of {Pre}-{Trained} {Transformers}},
	volume = {33},
	shorttitle = {{MiniLM}},
	url = {https://proceedings.neurips.cc/paper/2020/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {Pre-trained language models (e.g., BERT (Devlin et al., 2018) and its variants) have achieved remarkable success in varieties of NLP tasks. However, these models usually consist of hundreds of millions of parameters which brings challenges for fine-tuning and online serving in real-life applications due to latency and capacity constraints. In this work, we present a simple and effective approach to compress large Transformer (Vaswani et al., 2017) based pre-trained models, termed as deep self-attention distillation. The small model (student) is trained by deeply mimicking the self-attention module, which plays a vital role in Transformer networks, of the large model (teacher). Specifically, we propose distilling the self-attention module of the last Transformer layer of the teacher, which is effective and flexible for the student. Furthermore, we introduce the scaled dot-product between values in the self-attention module as the new deep self-attention knowledge, in addition to the attention distributions (i.e., the scaled dot-product of queries and keys) that have been used in existing works. Moreover, we show that introducing a teacher assistant (Mirzadeh et al., 2019) also helps the distillation of large pre-trained Transformer models. Experimental results demonstrate that our monolingual model outperforms state-of-the-art baselines in different parameter size of student models. In particular, it retains more than 99\% accuracy on SQuAD 2.0 and several GLUE benchmark tasks using 50\% of the Transformer parameters and computations of the teacher model. We also obtain competitive results in applying deep self-attention distillation to multilingual pre-trained models.},
	urldate = {2023-11-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
	year = {2020},
	pages = {5776--5788},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/P28SNLG6/Wang et al. - 2020 - MiniLM Deep Self-Attention Distillation for Task-.pdf:application/pdf},
}

@misc{noauthor_language_nodate,
	title = {Language of {ADHD} in {Adults} on {Social} {Media}},
	url = {https://journals.sagepub.com/doi/epub/10.1177/1087054717738083},
	language = {en},
	urldate = {2023-10-22},
	doi = {10.1177/1087054717738083},
	file = {Language of ADHD in Adults on Social Media.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/22AVRUTS/Language of ADHD in Adults on Social Media.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/K9F3V6T3/1087054717738083.html:text/html},
}

@article{fu_clinical_2020,
	title = {Clinical concept extraction: {A} methodology review},
	volume = {109},
	issn = {1532-0464},
	shorttitle = {Clinical concept extraction},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046420301544},
	doi = {10.1016/j.jbi.2020.103526},
	abstract = {Background
Concept extraction, a subdomain of natural language processing (NLP) with a focus on extracting concepts of interest, has been adopted to computationally extract clinical information from text for a wide range of applications ranging from clinical decision support to care quality improvement.
Objectives
In this literature review, we provide a methodology review of clinical concept extraction, aiming to catalog development processes, available methods and tools, and specific considerations when developing clinical concept extraction applications.
Methods
Based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a literature search was conducted for retrieving EHR-based information extraction articles written in English and published from January 2009 through June 2019 from Ovid MEDLINE In-Process \& Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and the ACM Digital Library.
Results
A total of 6,686 publications were retrieved. After title and abstract screening, 228 publications were selected. The methods used for developing clinical concept extraction applications were discussed in this review.},
	urldate = {2023-10-17},
	journal = {Journal of Biomedical Informatics},
	author = {Fu, Sunyang and Chen, David and He, Huan and Liu, Sijia and Moon, Sungrim and Peterson, Kevin J. and Shen, Feichen and Wang, Liwei and Wang, Yanshan and Wen, Andrew and Zhao, Yiqing and Sohn, Sunghwan and Liu, Hongfang},
	month = sep,
	year = {2020},
	keywords = {Machine learning, Deep learning, Electronic health records, Natural language processing, Concept extraction, Information extraction},
	pages = {103526},
	file = {ScienceDirect Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/ATQX7X23/Fu et al. - 2020 - Clinical concept extraction A methodology review.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/5XVQ68WK/S1532046420301544.html:text/html},
}

@misc{mialon_augmented_2023,
	title = {Augmented {Language} {Models}: a {Survey}},
	shorttitle = {Augmented {Language} {Models}},
	url = {http://arxiv.org/abs/2302.07842},
	abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
	urldate = {2023-10-16},
	publisher = {arXiv},
	author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07842 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/F5LDM3IG/2302.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/YZR7HMX3/Mialon et al. - 2023 - Augmented Language Models a Survey.pdf:application/pdf},
}

@misc{hu_lora_2021,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2023-10-11},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/YXA3PJAC/2106.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PJIL6G4Y/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf:application/pdf},
}

@article{wu_transparency_2023,
	title = {Transparency {Helps} {Reveal} {When} {Language} {Models} {Learn} {Meaning}},
	volume = {11},
	issn = {2307-387X},
	url = {https://doi.org/10.1162/tacl_a_00565},
	doi = {10.1162/tacl_a_00565},
	abstract = {Many current NLP systems are built from language models trained to optimize unsupervised objectives on large amounts of raw text. Under what conditions might such a procedure acquire meaning? Our systematic experiments with synthetic data reveal that, with languages where all expressions have context-independent denotations (i.e., languages with strong transparency), both autoregressive and masked language models successfully learn to emulate semantic relations between expressions. However, when denotations are changed to be context-dependent with the language otherwise unmodified, this ability degrades. Turning to natural language, our experiments with a specific phenomenon—referential opacity—add to the growing body of evidence that current language models do not represent natural language semantics well. We show this failure relates to the context-dependent nature of natural language form-meaning mappings.},
	urldate = {2023-10-11},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Wu, Zhaofeng and Merrill, William and Peng, Hao and Beltagy, Iz and Smith, Noah A.},
	month = jun,
	year = {2023},
	pages = {617--634},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/55G26JU2/Wu et al. - 2023 - Transparency Helps Reveal When Language Models Lea.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/L2L4XSQG/Transparency-Helps-Reveal-When-Language-Models.html:text/html},
}

@article{miranda-escalada_overview_2020,
	title = {Overview of automatic clinical coding: annotations, guidelines, and solutions for non-{English} clinical cases at {CodiEsp} track of {CLEF} {eHealth} 2020},
	abstract = {Clinical coding requires the analysis and transformation of medical narratives into a structured or coded format using internationally recognized classiﬁcation systems like ICD-10. These codes represent medical diagnoses and procedures. Clinical coding is critical for standardizing medical records, particularly for health information management systems used to carry out biomedical/ epidemiological research studies, monitor health trends or facilitate medical billing and reimbursement. The growing amount of clinical records has prompted the search for tools that assist manual coding. Inspired by the CCMC challenge and various eHealth CLEF shared tasks, we organized the CodiEsp track. Codiesp (eHealth CLEF 2020- Multilingual Information Extraction Shared Task) represents the ﬁrst eﬀort to promote the development and evaluation of automatic clinical coding systems for medical documents in Spanish. In this context, we have published a set of resources including (i) a manually coded Gold Standard corpus with inter-coder agreement and supporting textual evidence statements, (ii) an additional large collection of medical literature indexed with ICD-10 clinical codes and (iii) a machine translated corpus to enable multilingual approaches and testing of previous strategies developed for data in English. We have received a total of 168 runs submitted by 22 teams from 11 countries for at least one of our three sub-tracks: CodiEsp-D (Diagnosis Coding), CodiEsp-P (Procedure Coding) and CodiEsp-X (Explainable AI). Despite the considerable complexity of this task, which can be viewed as a hierarchical multi-label classiﬁcation problem using ICD-10 codes as labels and documents as input, participants obtained very promising results, specially for codes that were well covered by the training data. Participants examined a variety of strategies, speciﬁcally deep learning approaches, pre-trained language models and word embeddings (BERT, BETO, FastText, etc.), as well as NER, string lookup and knowledge graph approaches. CodiEsp Corpus: https://zenodo.org/record/3837305 Copyright c 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CLEF 2020, 22-25 September 2020, Thessaloniki, Greece.},
	language = {en},
	journal = {CLEF},
	author = {Miranda-Escalada, Antonio and Gonzalez-Agirre, Aitor and Armengol-Estape, Jordi and Krallinger, Martin},
	month = sep,
	year = {2020},
	file = {Miranda-Escalada et al. - Overview of automatic clinical coding annotations.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/823RCKEI/Miranda-Escalada et al. - Overview of automatic clinical coding annotations.pdf:application/pdf},
}

@misc{jones_consensus_2023,
	title = {Consensus of state of the art mortality prediction models: {From} all-cause mortality to sudden death prediction},
	shorttitle = {Consensus of state of the art mortality prediction models},
	url = {http://arxiv.org/abs/2308.16067},
	doi = {10.48550/arXiv.2308.16067},
	abstract = {Worldwide, many millions of people die suddenly and unexpectedly each year, either with or without a prior history of cardiovascular disease. Such events are sparse (once in a lifetime), many victims will not have had prior investigations for cardiac disease and many different definitions of sudden death exist. Accordingly, sudden death is hard to predict. This analysis used NHS Electronic Health Records (EHRs) for people aged \${\textbackslash}geq\$50 years living in the Greater Glasgow and Clyde (GG{\textbackslash}\&C) region in 2010 (n = 380,000) to try to overcome these challenges. We investigated whether medical history, blood tests, prescription of medicines, and hospitalisations might, in combination, predict a heightened risk of sudden death. We compared the performance of models trained to predict either sudden death or all-cause mortality. We built six models for each outcome of interest: three taken from state-of-the-art research (BEHRT, Deepr and Deep Patient), and three of our own creation. We trained these using two different data representations: a language-based representation, and a sparse temporal matrix. We used global interpretability to understand the most important features of each model, and compare how much agreement there was amongst models using Rank Biased Overlap. It is challenging to account for correlated variables without increasing the complexity of the interpretability technique. We overcame this by clustering features into groups and comparing the most important groups for each model. We found the agreement between models to be much higher when accounting for correlated variables. Our analysis emphasises the challenge of predicting sudden death and emphasises the need for better understanding and interpretation of machine learning models applied to healthcare applications.},
	urldate = {2023-10-09},
	publisher = {arXiv},
	author = {Jones, Yola and Deligianni, Fani and Dalton, Jeff and Pellicori, Pierpaolo and Cleland, John G. F.},
	month = aug,
	year = {2023},
	note = {arXiv:2308.16067 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/RHD8A93V/Jones et al. - 2023 - Consensus of state of the art mortality prediction.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/WIBDVGHB/2308.html:text/html},
}

@misc{noauthor_deep_nodate,
	title = {Deep {Infra}},
	url = {https://deepinfra.com/},
	abstract = {Run the top AI models using a simple API, pay per use. Low cost, scalable and production ready infrastructure.},
	language = {en},
	urldate = {2023-10-04},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/F4KUJUCW/deepinfra.com.html:text/html},
}

@inproceedings{huang_plm-icd_2022,
	address = {Seattle, WA},
	title = {{PLM}-{ICD}: {Automatic} {ICD} {Coding} with {Pretrained} {Language} {Models}},
	shorttitle = {{PLM}-{ICD}},
	url = {https://aclanthology.org/2022.clinicalnlp-1.2},
	doi = {10.18653/v1/2022.clinicalnlp-1.2},
	abstract = {Automatically classifying electronic health records (EHRs) into diagnostic codes has been challenging to the NLP community. State-of-the-art methods treated this problem as a multi-label classification problem and proposed various architectures to model this problem. However, these systems did not leverage the superb performance of pretrained language models, which achieved superb performance on natural language understanding tasks. Prior work has shown that pretrained language models underperformed on this task with the regular fine-tuning scheme. Therefore, this paper aims at analyzing the causes of the underperformance and developing a framework for automatic ICD coding with pretrained language models. We spotted three main issues through the experiments: 1) large label space, 2) long input sequences, and 3) domain mismatch between pretraining and fine-tuning. We propose PLM-ICD, a framework that tackles the challenges with various strategies. The experimental results show that our proposed framework can overcome the challenges and achieves state-of-the-art performance in terms of multiple metrics on the benchmark MIMIC data. Our source code is available at https://github.com/MiuLab/PLM-ICD.},
	urldate = {2023-10-04},
	booktitle = {Proceedings of the 4th {Clinical} {Natural} {Language} {Processing} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Huang, Chao-Wei and Tsai, Shang-Chi and Chen, Yun-Nung},
	month = jul,
	year = {2022},
	pages = {10--20},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/7N5MEWV3/Huang et al. - 2022 - PLM-ICD Automatic ICD Coding with Pretrained Lang.pdf:application/pdf},
}

@inproceedings{agrawal_large_2022,
	address = {Abu Dhabi, United Arab Emirates},
	title = {Large language models are few-shot clinical information extractors},
	url = {https://aclanthology.org/2022.emnlp-main.130},
	doi = {10.18653/v1/2022.emnlp-main.130},
	abstract = {A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. In this work, we show that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain. Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking few-shot clinical information extraction based on a manual re-annotation of the CASI dataset (Moon et al., 2014) for new tasks. On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines.},
	urldate = {2023-10-04},
	booktitle = {Proceedings of the 2022 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Agrawal, Monica and Hegselmann, Stefan and Lang, Hunter and Kim, Yoon and Sontag, David},
	month = dec,
	year = {2022},
	pages = {1998--2022},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2QSULNCI/Agrawal et al. - 2022 - Large language models are few-shot clinical inform.pdf:application/pdf},
}

@inproceedings{yang_knowledge_2022,
	address = {Abu Dhabi, United Arab Emirates},
	title = {Knowledge {Injected} {Prompt} {Based} {Fine}-tuning for {Multi}-label {Few}-shot {ICD} {Coding}},
	url = {https://aclanthology.org/2022.findings-emnlp.127},
	doi = {10.18653/v1/2022.findings-emnlp.127},
	abstract = {Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with average length of 3,000+ tokens. This task is challenging due to a high-dimensional space of multi-label assignment (tens of thousands of ICD codes) and the long-tail challenge: only a few codes (common diseases) are frequently assigned while most codes (rare diseases) are infrequently assigned. This study addresses the long-tail challenge by adapting a prompt-based fine-tuning technique with label semantics, which has been shown to be effective under few-shot setting. To further enhance the performance in medical domain, we propose a knowledge-enhanced longformer by injecting three domain-specific knowledge: hierarchy, synonym, and abbreviation with additional pretraining using contrastive learning. Experiments on MIMIC-III-full, a benchmark dataset of code assignment, show that our proposed method outperforms previous state-of-the-art method in 14.5\% in marco F1 (from 10.3 to 11.8, P{\textbackslash}textless0.001). To further test our model on few-shot setting, we created a new rare diseases coding dataset, MIMIC-III-rare50, on which our model improves marco F1 from 17.1 to 30.4 and micro F1 from 17.2 to 32.6 compared to previous method.},
	urldate = {2023-10-04},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Zhichao and Wang, Shufan and Rawat, Bhanu Pratap Singh and Mitra, Avijit and Yu, Hong},
	month = dec,
	year = {2022},
	pages = {1767--1781},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/9EMXRJFP/Yang et al. - 2022 - Knowledge Injected Prompt Based Fine-tuning for Mu.pdf:application/pdf},
}

@misc{travasci_simple_2023,
	title = {simple {ICD}-10-{CM}},
	copyright = {MIT},
	url = {https://github.com/StefanoTrv/simple_icd_10_CM},
	urldate = {2023-08-17},
	author = {Travasci, Stefano},
	month = aug,
	year = {2023},
	keywords = {icd, icd-10, icd-10-clinical-modification, icd-10-cm, icd-codes, icd10, icd10cm, python},
}

@misc{singhal_towards_2023,
	title = {Towards {Expert}-{Level} {Medical} {Question} {Answering} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2305.09617},
	doi = {10.48550/arXiv.2305.09617},
	abstract = {Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2\% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach. Med-PaLM 2 scored up to 86.5\% on the MedQA dataset, improving upon Med-PaLM by over 19\% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets. We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p {\textless} 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p {\textless} 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.},
	urldate = {2023-09-01},
	publisher = {arXiv},
	author = {Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and Pfohl, Stephen and Cole-Lewis, Heather and Neal, Darlene and Schaekermann, Mike and Wang, Amy and Amin, Mohamed and Lachgar, Sami and Mansfield, Philip and Prakash, Sushant and Green, Bradley and Dominowska, Ewa and Arcas, Blaise Aguera y and Tomasev, Nenad and Liu, Yun and Wong, Renee and Semturs, Christopher and Mahdavi, S. Sara and Barral, Joelle and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Azizi, Shekoofeh and Karthikesalingam, Alan and Natarajan, Vivek},
	month = may,
	year = {2023},
	note = {arXiv:2305.09617 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/5PS69ZGX/Singhal et al. - 2023 - Towards Expert-Level Medical Question Answering wi.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/LVI2CBEC/2305.html:text/html},
}

@misc{noauthor_emergency_nodate,
	title = {Emergency use {ICD} codes for {COVID}-19 disease outbreak},
	url = {https://www.who.int/standards/classifications/classification-of-diseases/emergency-use-icd-codes-for-covid-19-disease-outbreak},
	abstract = {The COVID-19 disease outbreak has been declared a public health emergency of international concern.},
	language = {en},
	urldate = {2023-08-30},
	author = {, World Health Organization},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/W6VC37KF/emergency-use-icd-codes-for-covid-19-disease-outbreak.html:text/html},
}

@techreport{world_health_organization_icd-10_2004,
	title = {{ICD}-10 : international statistical classification of diseases and related health problems : tenth revision},
	shorttitle = {{ICD}-10},
	url = {https://apps.who.int/iris/handle/10665/42980},
	language = {cs},
	urldate = {2023-08-30},
	institution = {World Health Organization},
	author = {{World Health Organization}},
	year = {2004},
	note = {ISBN: 9789241546492},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/6SKDWR5A/World Health Organization - 2004 - ICD-10  international statistical classification .pdf:application/pdf},
}

@article{pezzella_icd11_2022,
	title = {The {ICD}‐11 is now officially in effect},
	volume = {21},
	issn = {1723-8617},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9077598/},
	doi = {10.1002/wps.20982},
	number = {2},
	urldate = {2023-08-30},
	journal = {World Psychiatry},
	author = {Pezzella, Pasquale},
	month = jun,
	year = {2022},
	pmid = {35524598},
	pmcid = {PMC9077598},
	pages = {331--332},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/W8SBUUVF/Pezzella - 2022 - The ICD‐11 is now officially in effect.pdf:application/pdf},
}

@misc{touvron_llama_2023,
	title = {Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}},
	shorttitle = {Llama 2},
	url = {http://arxiv.org/abs/2307.09288},
	doi = {10.48550/arXiv.2307.09288},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	urldate = {2023-08-27},
	publisher = {arXiv},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
	month = jul,
	year = {2023},
	note = {arXiv:2307.09288 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/39IPIS3V/Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZMUKY3XM/2307.html:text/html},
}

@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	volume = {33},
	url = {https://papers.nips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	urldate = {2023-08-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/8EYW43VL/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf},
}

@article{singhal_large_2023,
	title = {Large language models encode clinical knowledge},
	volume = {620},
	copyright = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06291-2},
	doi = {10.1038/s41586-023-06291-2},
	abstract = {Large language models (LLMs) have demonstrated impressive capabilities, but the bar for clinical applications is high. Attempts to assess the clinical knowledge of models typically rely on automated evaluations based on limited benchmarks. Here, to address these limitations, we present MultiMedQA, a benchmark combining six existing medical question answering datasets spanning professional medicine, research and consumer queries and a new dataset of medical questions searched online, HealthSearchQA. We propose a human evaluation framework for model answers along multiple axes including factuality, comprehension, reasoning, possible harm and bias. In addition, we evaluate Pathways Language Model1 (PaLM, a 540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM2 on MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA3, MedMCQA4, PubMedQA5 and Measuring Massive Multitask Language Understanding (MMLU) clinical topics6), including 67.6\% accuracy on MedQA (US Medical Licensing Exam-style questions), surpassing the prior state of the art by more than 17\%. However, human evaluation reveals key gaps. To resolve this, we introduce instruction prompt tuning, a parameter-efficient approach for aligning LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, performs encouragingly, but remains inferior to clinicians. We show that comprehension, knowledge recall and reasoning improve with model scale and instruction prompt tuning, suggesting the potential utility of LLMs in medicine. Our human evaluations reveal limitations of today’s models, reinforcing the importance of both evaluation frameworks and method development in creating safe, helpful LLMs for clinical applications.},
	language = {en},
	number = {7972},
	urldate = {2023-08-26},
	journal = {Nature},
	author = {Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S. Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and Payne, Perry and Seneviratne, Martin and Gamble, Paul and Kelly, Chris and Babiker, Abubakr and Schärli, Nathanael and Chowdhery, Aakanksha and Mansfield, Philip and Demner-Fushman, Dina and Agüera y Arcas, Blaise and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Chou, Katherine and Gottweis, Juraj and Tomasev, Nenad and Liu, Yun and Rajkomar, Alvin and Barral, Joelle and Semturs, Christopher and Karthikesalingam, Alan and Natarajan, Vivek},
	month = aug,
	year = {2023},
	note = {Number: 7972
Publisher: Nature Publishing Group},
	keywords = {Health care, Medical research},
	pages = {172--180},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/25PE8YQQ/Singhal et al. - 2023 - Large language models encode clinical knowledge.pdf:application/pdf},
}

@book{jurafsky_speech_nodate,
	title = {Speech and {Language} {Processing} (3rd ed. draft)},
	urldate = {2023-08-26},
	author = {Jurafsky, Dan and Martin, H. James},
	file = {8.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/G9V2B7FV/8.pdf:application/pdf},
}

@inproceedings{lu_multi-label_2020,
	address = {Online},
	title = {Multi-label {Few}/{Zero}-shot {Learning} with {Knowledge} {Aggregated} from {Multiple} {Label} {Graphs}},
	url = {https://aclanthology.org/2020.emnlp-main.235},
	doi = {10.18653/v1/2020.emnlp-main.235},
	abstract = {Few/Zero-shot learning is a big challenge of many classifications tasks, where a classifier is required to recognise instances of classes that have very few or even no training samples. It becomes more difficult in multi-label classification, where each instance is labelled with more than one class. In this paper, we present a simple multi-graph aggregation model that fuses knowledge from multiple label graphs encoding different semantic label relationships in order to study how the aggregated knowledge can benefit multi-label zero/few-shot document classification. The model utilises three kinds of semantic information, i.e., the pre-trained word embeddings, label description, and pre-defined label relations. Experimental results derived on two large clinical datasets (i.e., MIMIC-II and MIMIC-III ) and the EU legislation dataset show that methods equipped with the multi-graph knowledge aggregation achieve significant performance improvement across almost all the measures on few/zero-shot labels.},
	urldate = {2023-08-25},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Lu, Jueqing and Du, Lan and Liu, Ming and Dipnall, Joanna},
	month = nov,
	year = {2020},
	pages = {2935--2943},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/UD5C6PPT/Lu et al. - 2020 - Multi-label FewZero-shot Learning with Knowledge .pdf:application/pdf},
}

@inproceedings{de_lima_hierarchical_1998,
	address = {Bethesda Maryland USA},
	title = {A hierarchical approach to the automatic categorization of medical documents},
	isbn = {978-1-58113-061-4},
	url = {https://dl.acm.org/doi/10.1145/288627.288649},
	doi = {10.1145/288627.288649},
	language = {en},
	urldate = {2023-08-18},
	booktitle = {Proceedings of the seventh international conference on {Information} and knowledge management},
	publisher = {ACM},
	author = {De Lima, Luciano R. S. and Laender, Alberto H. F. and Ribeiro-Neto, Berthier A.},
	month = nov,
	year = {1998},
	pages = {132--139},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/Y6Z6F4W4/De Lima et al. - 1998 - A hierarchical approach to the automatic categoriz.pdf:application/pdf},
}

@article{sonabend_w_automated_2020,
	title = {Automated {ICD} coding via unsupervised knowledge integration ({UNITE})},
	volume = {139},
	issn = {1386-5056},
	url = {https://www.sciencedirect.com/science/article/pii/S1386505619313024},
	doi = {10.1016/j.ijmedinf.2020.104135},
	abstract = {Objective
Accurate coding is critical for medical billing and electronic medical record (EMR)-based research. Recent research has been focused on developing supervised methods to automatically assign International Classification of Diseases (ICD) codes from clinical notes. However, supervised approaches rely on ICD code data stored in the hospital EMR system and is subject to bias rising from the practice and coding behavior. Consequently, portability of trained supervised algorithms to external EMR systems may suffer.
Method
We developed an unsupervised knowledge integration (UNITE) algorithm to automatically assign ICD codes for a specific disease by analyzing clinical narrative notes via semantic relevance assessment. The algorithm was validated using coded ICD data for 6 diseases from Partners HealthCare (PHS) Biobank and Medical Information Mart for Intensive Care (MIMIC-III). We compared the performance of UNITE against penalized logistic regression (LR), topic modeling, and neural network models within each EMR system. We additionally evaluated the portability of UNITE by training at PHS Biobank and validating at MIMIC-III, and vice versa.
Results
UNITE achieved an averaged AUC of 0.91 at PHS and 0.92 at MIMIC over 6 diseases, comparable to LR and MLP. It had substantially better performance than topic models. In regards to portability, the performance of UNITE was consistent across different EMR systems, superior to LR, topic models and neural network models.
Conclusion
UNITE accurately assigns ICD code in EMR without requiring human labor, and has major advantages over commonly used machine learning approaches. In addition, the UNITE attained stable performance and high portability across EMRs in different institutions.},
	urldate = {2023-08-16},
	journal = {International Journal of Medical Informatics},
	author = {Sonabend W, Aaron and Cai, Winston and Ahuja, Yuri and Ananthakrishnan, Ashwin and Xia, Zongqi and Yu, Sheng and Hong, Chuan},
	month = jul,
	year = {2020},
	keywords = {Automated ICD assignment, Electronic medical records, Knowledge integration, Portability, Semantic embedding, Unsupervised learning},
	pages = {104135},
	file = {ScienceDirect Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/TX2J65WH/Sonabend W et al. - 2020 - Automated ICD coding via unsupervised knowledge in.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/QNPG5F2L/S1386505619313024.html:text/html},
}

@article{kaur_ai-based_2023,
	title = {{AI}-based {ICD} coding and classification approaches using discharge summaries: {A} systematic literature review},
	volume = {213},
	issn = {09574174},
	shorttitle = {{AI}-based {ICD} coding and classification approaches using discharge summaries},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417422020152},
	doi = {10.1016/j.eswa.2022.118997},
	abstract = {The assignment of codes to free-text clinical narratives have long been recognised to be beneficial for secondary uses such as funding, insurance claim processing and research. The current scenario of assigning clinical codes is a manual process which is very expensive, time-consuming and error prone. In recent years, many researchers have studied the use of Natural Language Processing (NLP), related machine learning and deep learning methods and techniques to resolve the problem of manual coding of clinical narratives and to assist human coders to assign clinical codes more accurately and efficiently. The main objective of this systematic literature review is to provide a comprehensive overview of automated clinical coding systems that utilise appropriate NLP, machine learning and deep learning methods and techniques to assign the International Classification of Diseases (ICD) codes to discharge summaries. We have followed the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and conducted a comprehensive search of publications from January, 2010 to December 2021 in four high quality academic databases: PubMed, ScienceDirect, Association for Computing Machinery (ACM) Digital Library, and the Association for Computational Linguistics (ACL) Anthology. We reviewed 6128 publications; 42 met the inclusion criteria. This review identified: 6 datasets having discharge summaries (2 publicly available, 4 acquired from hospitals); 14 NLP techniques along with some other data extraction processes, different feature extraction and embedding techniques. The review also shows that there is a significant increase in the use of deep learning models compared to machine learning. To measure the performance of classification methods, different evaluation metrics are used. Efforts are still required to improve ICD code prediction accuracy, availability of large-scale de-identified clinical corpora with the latest version of the classification system. This can be a platform to guide and share knowledge with the less experienced coders and researchers.},
	language = {en},
	urldate = {2023-08-14},
	journal = {Expert Systems with Applications},
	author = {Kaur, Rajvir and Ginige, Jeewani Anupama and Obst, Oliver},
	month = mar,
	year = {2023},
	pages = {118997},
	file = {Kaur et al. - 2023 - AI-based ICD coding and classification approaches .pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/WM7AUFUE/Kaur et al. - 2023 - AI-based ICD coding and classification approaches .pdf:application/pdf},
}

@inproceedings{mayya_mathcallata-_2021,
	title = {{\textbackslash}{mathcalLATA}- {Label} {Attention} {Transformer} {Architectures} for {ICD}-10 {Coding} of {Unstructured} {Clinical} {Notes}},
	doi = {10.1109/CIBCB49929.2021.9562815},
	abstract = {Effective code assignment for patient clinical records in a hospital plays a significant role in the process of standardizing medical records, mainly for streamlining clinical care delivery, billing, and managing insurance claims. The current practice employed is manual coding, usually carried out by trained medical coders, making the process subjective, error-prone, inexact, and time-consuming. To alleviate this cost-intensive process, intelligent coding systems built on patients' structured electronic medical records are critical. Classification of medical diagnostic codes, like ICD-10, is widely employed to categorize patients' clinical conditions and associated diagnoses. In this work, we present a neural model {\textbackslash}mathcalLATA, built on Label Attention Transformer Architectures for automatic assignment of ICD-10 codes. Our work is benchmarked on the CodiEsp dataset, a dataset for automatic clinical coding systems for multilingual medical documents, used in the eHealth CLEF 2020-Multilingual Information Extraction Shared Task. The experimental results reveal that the proposed {\textbackslash}mathcalLATA variants outperform their basic BERT counterparts by 33-49\% in terms of standard metrics like precision, recall, F1-score and mean average precision. The label attention mechanism also enables direct extraction of textual evidence in medical documents that map to the clinical ICD-10 diagnostic codes.},
	booktitle = {2021 {IEEE} {Conference} on {Computational} {Intelligence} in {Bioinformatics} and {Computational} {Biology} ({CIBCB})},
	author = {Mayya, Veena and Kamath, S. Sowmya and Sugumaran, Vijayan},
	month = oct,
	year = {2021},
	keywords = {Predictive models, Disease prediction, Codes, Computer architecture, Encoding, Healthcare informatics, Manuals, Measurement, Predictive analytics, Transformers, Unstructured text modeling},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:/home/extasia/snap/zotero-snap/common/Zotero/storage/JYZWCEGM/9562815.html:text/html;IEEE Xplore Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/7SDI94MT/Mayya et al. - 2021 - mathcalLATA- Label Attention Transformer Architec.pdf:application/pdf},
}

@inproceedings{edin_automated_2023,
	address = {New York, NY, USA},
	series = {{SIGIR} '23},
	title = {Automated {Medical} {Coding} on {MIMIC}-{III} and {MIMIC}-{IV}: {A} {Critical} {Review} and {Replicability} {Study}},
	isbn = {978-1-4503-9408-6},
	shorttitle = {Automated {Medical} {Coding} on {MIMIC}-{III} and {MIMIC}-{IV}},
	url = {https://dl.acm.org/doi/10.1145/3539618.3591918},
	doi = {10.1145/3539618.3591918},
	abstract = {Medical coding is the task of assigning medical codes to clinical free-text documentation. Healthcare professionals manually assign such codes to track patient diagnoses and treatments. Automated medical coding can considerably alleviate this administrative burden. In this paper, we reproduce, compare, and analyze state-of-the-art automated medical coding machine learning models. We show that several models underperform due to weak configurations, poorly sampled train-test splits, and insufficient evaluation. In previous work, the macro F1 score has been calculated sub-optimally, and our correction doubles it. We contribute a revised model comparison using stratified sampling and identical experimental setups, including hyperparameters and decision boundary tuning. We analyze prediction errors to validate and falsify assumptions of previous works. The analysis confirms that all models struggle with rare codes, while long documents only have a negligible impact. Finally, we present the first comprehensive results on the newly released MIMIC-IV dataset using the reproduced models. We release our code, model parameters, and new MIMIC-III and MIMIC-IV training and evaluation pipelines to accommodate fair future comparisons.},
	urldate = {2023-08-01},
	booktitle = {Proceedings of the 46th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Edin, Joakim and Junge, Alexander and Havtorn, Jakob D. and Borgholt, Lasse and Maistro, Maria and Ruotsalo, Tuukka and Maaløe, Lars},
	month = jul,
	year = {2023},
	keywords = {automated medical coding, mimic, reproducibility},
	pages = {2572--2582},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/TA56FGIV/Edin et al. - 2023 - Automated Medical Coding on MIMIC-III and MIMIC-IV.pdf:application/pdf},
}

@article{polignano_study_nodate,
	title = {A study of {Machine} {Learning} models for {Clinical} {Coding} of {Medical} {Reports} at {CodiEsp} 2020},
	abstract = {The task of identifying one or more diseases associated with a patient’s clinical condition is often very complex, even for doctors and specialists. This process is usually time-consuming and has to take into account diﬀerent aspects of what has occurred, including symptoms elicited and previous healthcare situations. The medical diagnosis is often provided to patients in the form of written paper without any correlation with a national or international standard. Even if the WHO (World Health Organization) released the ICD10 international glossary of diseases, almost no doctor has enough time to manually associate the patient’s clinical history with international codes. The CodiEsp task at CLEF 2020 addressed this issue by proposing the development of an automatic system to deal with this task. Our solution investigated different machine learning strategies in order to identify an approach to face that challenge. The main outcomes of the experiments showed that a strategy based on BERT for pre-ﬁltering and one based on BiLSTMCNN-SelfAttention for classiﬁcation provide valuable results. We carried out several experiments on a subset of the training set for tuning the ﬁnal model submitted to the challenge. In particular, we analyzed the impact of the algorithm, the input encoding strategy, and the thresholds for multi-label classiﬁcation. A set of experiments has been carried out also during a post hoc analysis. The experiments conﬁrmed that the strategy submitted to the CodiEsp task is the best performing one among those evaluated, and it allowed us to obtain a ﬁnal mean average error value on the test set equal to 0.202. To support future developments of the proposed approach and the replicability of the experiments we decided to make the source code publicly accessible.},
	language = {en},
	author = {Polignano, Marco and Suriano, Vincenzo and Lops, Pasquale and de Gemmis, Marco and Semeraro, Giovanni},
	file = {Polignano et al. - A study of Machine Learning models for Clinical Co.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/5BRZMXKL/Polignano et al. - A study of Machine Learning models for Clinical Co.pdf:application/pdf},
}

@inproceedings{song_generalized_2020,
	address = {Yokohama, Japan},
	title = {Generalized {Zero}-{Shot} {Text} {Classification} for {ICD} {Coding}},
	isbn = {978-0-9992411-6-5},
	url = {https://www.ijcai.org/proceedings/2020/556},
	doi = {10.24963/ijcai.2020/556},
	abstract = {The International Classiﬁcation of Diseases (ICD) is a list of classiﬁcation codes for the diagnoses. Automatic ICD coding is a multi-label text classiﬁcation problem with noisy clinical document inputs and long-tailed label distribution, making it difﬁcult for ﬁne-grained classiﬁcation on both frequent and zero-shot codes at the same time, i.e. generalized zero-shot ICD coding. In this paper, we propose a latent feature generation framework to improve the prediction on unseen codes without compromising the performance on seen codes. Our framework generates semantically meaningful features for zero-shot codes by exploiting ICD code hierarchical structure and reconstructing the code-relevant keywords with a novel cycle architecture. To the best of our knowledge, this is the ﬁrst adversarial generative model for generalized zero-shot learning on multi-label text classiﬁcation. Extensive experiments demonstrate the effectiveness of our approach. On the public MIMIC-III dataset, our methods improve the F1 score from nearly 0 to 20.91\% for the zero-shot codes, and increase the AUC score by 3\% (absolute improvement) from previous state of the art. Code is available at https://github.com/csong27/gzsl text.},
	language = {en},
	urldate = {2023-07-26},
	booktitle = {Proceedings of the {Twenty}-{Ninth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Song, Congzheng and Zhang, Shanghang and Sadoughi, Najmeh and Xie, Pengtao and Xing, Eric},
	month = jul,
	year = {2020},
	pages = {4018--4024},
	file = {Song et al. - 2020 - Generalized Zero-Shot Text Classification for ICD .pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/KJPIG855/Song et al. - 2020 - Generalized Zero-Shot Text Classification for ICD .pdf:application/pdf},
}

@misc{wei_chain--thought_2023,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2201.11903},
	doi = {10.48550/arXiv.2201.11903},
	abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
	urldate = {2023-07-20},
	publisher = {arXiv},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
	month = jan,
	year = {2023},
	note = {arXiv:2201.11903 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/SLH5BXI5/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/GQZRQT2M/2201.html:text/html},
}

@techreport{soroush_assessing_2023,
	type = {preprint},
	title = {Assessing {GPT}-3.5 and {GPT}-4 in {Generating} {International} {Classification} of {Diseases} {Billing} {Codes}},
	url = {http://medrxiv.org/lookup/doi/10.1101/2023.07.07.23292391},
	abstract = {Background: Large Language Models (LLMs) like GPT-3.5 and GPT-4 are increasingly entering the healthcare domain as a proposed means to assist with administrative tasks. To ensure safe and effective use with billing coding tasks, it is crucial to assess these models’ ability to generate the correct International Classification of Diseases (ICD) codes from text descriptions.},
	language = {en},
	urldate = {2023-07-14},
	institution = {Health Informatics},
	author = {Soroush, Ali and Glicksberg, Benjamin S. and Zimlichman, Eyal and Barash, Yiftach and Freeman, Robert and Charney, Alexander W. and Nadkarni, Girish N and Klang, Eyal},
	month = jul,
	year = {2023},
	doi = {10.1101/2023.07.07.23292391},
	file = {Soroush et al. - 2023 - Assessing GPT-3.5 and GPT-4 in Generating Internat.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/DNB7HQZD/Soroush et al. - 2023 - Assessing GPT-3.5 and GPT-4 in Generating Internat.pdf:application/pdf},
}

@misc{song_learning_2022,
	title = {Learning from {Noisy} {Labels} with {Deep} {Neural} {Networks}: {A} {Survey}},
	shorttitle = {Learning from {Noisy} {Labels} with {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2007.08199},
	abstract = {Deep learning has achieved remarkable success in numerous domains with help from large amounts of big data. However, the quality of data labels is a concern because of the lack of high-quality labels in many real-world scenarios. As noisy labels severely degrade the generalization performance of deep neural networks, learning from noisy labels (robust training) is becoming an important task in modern deep learning applications. In this survey, we first describe the problem of learning with label noise from a supervised learning perspective. Next, we provide a comprehensive review of 62 state-of-the-art robust training methods, all of which are categorized into five groups according to their methodological difference, followed by a systematic comparison of six properties used to evaluate their superiority. Subsequently, we perform an in-depth analysis of noise rate estimation and summarize the typically used evaluation methodology, including public noisy datasets and evaluation metrics. Finally, we present several promising research directions that can serve as a guideline for future studies. All the contents will be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.},
	urldate = {2023-07-04},
	publisher = {arXiv},
	author = {Song, Hwanjun and Kim, Minseok and Park, Dongmin and Shin, Yooju and Lee, Jae-Gil},
	month = mar,
	year = {2022},
	note = {arXiv:2007.08199 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/SUFXJVD4/2007.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JFX3RZN7/Song et al. - 2022 - Learning from Noisy Labels with Deep Neural Networ.pdf:application/pdf},
}

@inproceedings{searle_experimental_2020,
	address = {Online},
	title = {Experimental {Evaluation} and {Development} of a {Silver}-{Standard} for the {MIMIC}-{III} {Clinical} {Coding} {Dataset}},
	url = {https://aclanthology.org/2020.bionlp-1.8},
	doi = {10.18653/v1/2020.bionlp-1.8},
	abstract = {Clinical coding is currently a labour-intensive, error-prone, but a critical administrative process whereby hospital patient episodes are manually assigned codes by qualified staff from large, standardised taxonomic hierarchies of codes. Automating clinical coding has a long history in NLP research and has recently seen novel developments setting new benchmark results. A popular dataset used in this task is MIMIC-III, a large database of clinical free text notes and their associated codes amongst other data. We argue for the reconsideration of the validity MIMIC-III's assigned codes, as MIMIC-III has not undergone secondary validation. This work presents an open-source, reproducible experimental methodology for assessing the validity of EHR discharge summaries. We exemplify the methodology with MIMIC-III discharge summaries and show the most frequently assigned codes in MIMIC-III are undercoded up to 35\%.},
	urldate = {2023-07-02},
	booktitle = {Proceedings of the 19th {SIGBioMed} {Workshop} on {Biomedical} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Searle, Thomas and Ibrahim, Zina and Dobson, Richard},
	month = jul,
	year = {2020},
	pages = {76--85},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/S4XDQHFH/Searle et al. - 2020 - Experimental Evaluation and Development of a Silve.pdf:application/pdf},
}

@misc{muller_when_2020,
	title = {When {Does} {Label} {Smoothing} {Help}?},
	url = {http://arxiv.org/abs/1906.02629},
	abstract = {The generalization and learning speed of a multi-class neural network can often be significantly improved by using soft targets that are a weighted average of the hard targets and the uniform distribution over labels. Smoothing the labels in this way prevents the network from becoming over-confident and label smoothing has been used in many state-of-the-art models, including image classification, language translation and speech recognition. Despite its widespread use, label smoothing is still poorly understood. Here we show empirically that in addition to improving generalization, label smoothing improves model calibration which can significantly improve beam-search. However, we also observe that if a teacher network is trained with label smoothing, knowledge distillation into a student network is much less effective. To explain these observations, we visualize how label smoothing changes the representations learned by the penultimate layer of the network. We show that label smoothing encourages the representations of training examples from the same class to group in tight clusters. This results in loss of information in the logits about resemblances between instances of different classes, which is necessary for distillation, but does not hurt generalization or calibration of the model's predictions.},
	urldate = {2023-06-20},
	publisher = {arXiv},
	author = {Müller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
	month = jun,
	year = {2020},
	note = {arXiv:1906.02629 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/YK3D87CW/1906.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/LTVGEGVQ/Müller et al. - 2020 - When Does Label Smoothing Help.pdf:application/pdf},
}

@incollection{ferrari_deep_2018,
	address = {Cham},
	title = {Deep {Metric} {Learning} with {Hierarchical} {Triplet} {Loss}},
	volume = {11210},
	isbn = {978-3-030-01230-4 978-3-030-01231-1},
	url = {https://link.springer.com/10.1007/978-3-030-01231-1_17},
	abstract = {We present a novel hierarchical triplet loss (HTL) capable of automatically collecting informative training samples (triplets) via a deﬁned hierarchical tree that encodes global context information. This allows us to cope with the main limitation of random sampling in training a conventional triplet loss, which is a central issue for deep metric learning. Our main contributions are two-fold. (i) we construct a hierarchical class-level tree where neighboring classes are merged recursively. The hierarchical structure naturally captures the intrinsic data distribution over the whole dataset. (ii) we formulate the problem of triplet collection by introducing a new violate margin, which is computed dynamically based on the designed hierarchical tree. This allows it to automatically select meaningful hard samples with the guide of global context. It encourages the model to learn more discriminative features from visual similar classes, leading to faster convergence and better performance. Our method is evaluated on the tasks of image retrieval and face recognition, where it can obtain comparable performance with much fewer iterations. It outperforms the standard triplet loss substantially by 1\% − 18\%, and achieves new state-of-the-art performance on a number of benchmarks.},
	language = {en},
	urldate = {2023-06-12},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Ge, Weifeng and Huang, Weilin and Dong, Dengke and Scott, Matthew R.},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01231-1_17},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {272--288},
	file = {Ge et al. - 2018 - Deep Metric Learning with Hierarchical Triplet Los.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/NSJH3KIZ/Ge et al. - 2018 - Deep Metric Learning with Hierarchical Triplet Los.pdf:application/pdf},
}

@misc{jin_what_2020,
	title = {What {Disease} does this {Patient} {Have}? {A} {Large}-scale {Open} {Domain} {Question} {Answering} {Dataset} from {Medical} {Exams}},
	shorttitle = {What {Disease} does this {Patient} {Have}?},
	url = {http://arxiv.org/abs/2009.13081},
	doi = {10.48550/arXiv.2009.13081},
	abstract = {Open domain question answering (OpenQA) tasks have been recently attracting more and more attention from the natural language processing (NLP) community. In this work, we present the first free-form multiple-choice OpenQA dataset for solving medical problems, MedQA, collected from the professional medical board exams. It covers three languages: English, simplified Chinese, and traditional Chinese, and contains 12,723, 34,251, and 14,123 questions for the three languages, respectively. We implement both rule-based and popular neural methods by sequentially combining a document retriever and a machine comprehension model. Through experiments, we find that even the current best method can only achieve 36.7{\textbackslash}\%, 42.0{\textbackslash}\%, and 70.1{\textbackslash}\% of test accuracy on the English, traditional Chinese, and simplified Chinese questions, respectively. We expect MedQA to present great challenges to existing OpenQA systems and hope that it can serve as a platform to promote much stronger OpenQA models from the NLP community in the future.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Jin, Di and Pan, Eileen and Oufattole, Nassim and Weng, Wei-Hung and Fang, Hanyi and Szolovits, Peter},
	month = sep,
	year = {2020},
	note = {arXiv:2009.13081 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/TAKSYDHC/Jin et al. - 2020 - What Disease does this Patient Have A Large-scale.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/L39KIT2C/2009.html:text/html},
}

@article{yu_natural_2024,
	title = {Natural {Language} {Reasoning}, {A} {Survey}},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3664194},
	doi = {10.1145/3664194},
	abstract = {This survey paper proposes a clearer view of natural language reasoning in the field of Natural Language Processing (NLP), both conceptually and practically. Conceptually, we provide a distinct definition for natural language reasoning in NLP, based on both philosophy and NLP scenarios, discuss what types of tasks require reasoning, and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on natural language reasoning in NLP, mainly covering classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. The paper also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in natural language reasoning research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic research and mathematical reasoning.},
	urldate = {2024-07-11},
	journal = {ACM Comput. Surv.},
	author = {Yu, Fei and Zhang, Hongbo and Tiwari, Prayag and Wang, Benyou},
	month = may,
	year = {2024},
	note = {Just Accepted},
}

@article{fachado_spanish_2018,
	title = {Spanish adaptation and validation of the supportive \&amp; palliative care indicators tool – {SPICT}-{ES}$^{\textrm{{TM}}}$},
	volume = {52},
	issn = {0034-8910, 1518-8787},
	url = {https://www.scielo.br/j/rsp/a/ggYfGHhYknpZvbbXwKMYykq/?lang=en},
	doi = {10.11606/S1518-8787.2018052000398},
	abstract = {ABSTRACT OBJECTIVE To culturally adapt and validate the SPICTTM to Spanish, which is a brief and simple tool to support a better identification of chronic patients who have palliative care needs. METHODS For this study, we designed a multicenter and national project between the centers of Galicia, Balearic Islands, and Andalusia. For the process of translation and cross-cultural adaptation of the SPICTTM to Spanish, we followed the steps proposed by Beaton et al. with successive translations and subsequent consensus of experts using the debriefing methodology. After the content validation was completed, the psychometric properties were validated. A prospective longitudinal study was designed with 188 patients from Galicia, the Balearic Islands, and Andalusia. The internal consistency and reliability of the test and retest was analyzed for 10 days by the same researcher. RESULTS For more than 90\% of the participants of the SPICT-ESTM, it seems simple to be filled out, and they consider it written in an understandable language. The average time to apply the questionnaire without prior knowledge was 4 minutes and 45 seconds. To evaluate the internal consistency of the instrument, we used the Kuder-Richardson formula 20. Internal consistency is 0.71. The agreement index of the Kappa test is between 0.983 and 0.797 for the different items. CONCLUSIONS In this study, we demonstrate the equivalence of content with the original. In addition, the validation of the psychometric properties establishes that the SPICT-ESTM maintains adequate reliability and stability. If we add the satisfaction shown by the professionals and the ease of use, the SPICT-ESTM is an adequate tool for the identification of palliative patients with chronic diseases and palliative care needs.},
	language = {en},
	urldate = {2024-06-14},
	journal = {Rev Saude Publica},
	author = {Fachado, Alfonso Alonso and Martínez, Noemí Sansó and Roselló, Marisa Martín and Rial, José Javier Ventosa and Oliver, Enric Benito and García, Rafael Gómez and García, José Manuel Fernández},
	month = jan,
	year = {2018},
	note = {Publisher: Faculdade de Saúde Pública da Universidade de São Paulo},
	keywords = {Decision Support Techniques, Multicenter Study, Palliative Care Clinical Decision-Making, Surveys and Questionnaires, Translations, utilization, Validation Studies},
	pages = {3},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/4XD3WW5S/Fachado et al. - 2018 - Spanish adaptation and validation of the supportiv.pdf:application/pdf},
}

@article{mahura_use_2024,
	title = {Use of the supportive and palliative care indicators tool ({SPICT}™) for end-of-life discussions: a scoping review},
	volume = {23},
	issn = {1472-684X},
	shorttitle = {Use of the supportive and palliative care indicators tool ({SPICT}™) for end-of-life discussions},
	url = {https://doi.org/10.1186/s12904-024-01445-z},
	doi = {10.1186/s12904-024-01445-z},
	abstract = {In order to mitigate the distress associated with life limiting conditions it is essential for all health professionals not just palliative care specialists to identify people with deteriorating health and unmet palliative care needs and to plan care. The SPICT™ tool was designed to assist with this.},
	language = {en},
	number = {1},
	urldate = {2024-07-01},
	journal = {BMC Palliative Care},
	author = {Mahura, Melanie and Karle, Brigitte and Sayers, Louise and Dick-Smith, Felicity and Elliott, Rosalind},
	month = may,
	year = {2024},
	keywords = {Communication, Documentation, Palliative Care, Patient Care Planning, Terminal Care},
	pages = {119},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZN2EW62V/Mahura et al. - 2024 - Use of the supportive and palliative care indicato.pdf:application/pdf},
}

@article{wilkinson_caregiving_2005,
	series = {Palliative and {Pain} {Medicine}: {Improving} {Care} for {Patients} with {Serious} {Illness}},
	title = {Caregiving for advanced chronic illness patients},
	volume = {9},
	issn = {1084-208X},
	url = {https://www.sciencedirect.com/science/article/pii/S1084208X05000455},
	doi = {10.1053/j.trap.2005.06.004},
	abstract = {The transfer of care from the hospital to home settings has shifted responsibility for the day-to-day care of the long-term, medically complex patient to the family. While family members have always provided care to seriously ill relatives, the care that is expected of family members in today’s health care environment is vastly more complex than it was just 10 years ago. The chronic illness trajectory denotes the fluctuating, variable course of illness phases over time as well as the actions taken by various participants to shape or control that course. The course of the patient’s illness—the illness trajectory—shapes the caregiver’s experience. Three different trajectories of advanced, eventually fatal, chronic illness represent differing patient and family caregiver needs: (1) the long stable period followed by a rather abrupt, defined terminal phase and exemplified by cancer; (2) a trajectory marked by a long course of decline with periodic crises alternating with periods of stability, and with a sudden death, exemplified by congestive heart failure and chronic obstructive pulmonary disease; and (3) a long, slow decline with steadily progressive disability before dying of complications of old age, stroke, or dementia. Patients and families want good pain and symptom management for their loved one; accurate, timely, and adequate information (communication); emotional support from and accessibility to providers; and continuity care across settings. The health care system could be doing more to support family caregivers.},
	number = {3},
	urldate = {2024-07-01},
	journal = {Techniques in Regional Anesthesia and Pain Management},
	author = {Wilkinson, Anne M. and Lynn, Joanne},
	month = jul,
	year = {2005},
	keywords = {Cancer, Care giving, Chronic illness trajectories, Chronic obstructive pulmonary disease, Congestive heart failure, Dementia, End of life},
	pages = {122--132},
	file = {ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/RZAN6U8C/S1084208X05000455.html:text/html;Wilkinson and Lynn - 2005 - Caregiving for advanced chronic illness patients.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/PHS2SNEZ/Wilkinson and Lynn - 2005 - Caregiving for advanced chronic illness patients.pdf:application/pdf},
}

@inproceedings{chang_selective_2023,
	address = {Singapore},
	title = {Selective {Demonstrations} for {Cross}-domain {Text}-to-{SQL}},
	url = {https://aclanthology.org/2023.findings-emnlp.944},
	doi = {10.18653/v1/2023.findings-emnlp.944},
	abstract = {Large language models (LLMs) with in-context learning have demonstrated impressive generalization capabilities in the cross-domain text-to-SQL task, without the use of in-domain annotations. However, incorporating in-domain demonstration examples has been found to greatly enhance LLMs' performance. In this paper, we delve into the key factors within in-domain examples that contribute to the improvement and explore whether we can harness these benefits without relying on in-domain annotations. Based on our findings, we propose a demonstration selection framework, ODIS, which utilizes both out-of-domain examples and synthetically generated in-domain examples to construct demonstrations. By retrieving demonstrations from hybrid sources, ODIS leverages the advantages of both, showcasing its effectiveness compared to baseline methods that rely on a single data source. Furthermore, ODIS outperforms state-of-the-art approaches on two cross-domain text-to-SQL datasets, with improvements of 1.1 and 11.8 points in execution accuracy, respectively.},
	urldate = {2024-06-25},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Chang, Shuaichen and Fosler-Lussier, Eric},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	month = dec,
	year = {2023},
	pages = {14174--14189},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/68C5F8LC/Chang and Fosler-Lussier - 2023 - Selective Demonstrations for Cross-domain Text-to-.pdf:application/pdf},
}

@article{harrison_are_2012,
	title = {Are {UK} primary care teams formally identifying patients for palliative care before they die?},
	volume = {62},
	copyright = {© British Journal of General Practice 2012},
	issn = {0960-1643, 1478-5242},
	url = {https://bjgp.org/content/62/598/e344},
	doi = {10.3399/bjgp12X641465},
	abstract = {Background The palliative care approach has the potential to improve care for patients with progressive life-threatening illnesses from the time of diagnosis. Policy and clinical directives in the UK advocate early identification.
Aim To determine the extent to which practices identify patients for palliative care, including factors influencing early identification and possible effects on place of death.
Design and setting Qualitative and quantitative data were collected from six general practices from three Scottish NHS boards and analysed.
Method Records of patients who had died in the previous 6 months were analysed and interviews with practice staff (n = 21) and with patients currently on the practice palliative care register and bereaved relatives (n = 14) were conducted. In addition, a practice meeting was observed.
Results In total, 29\% of patients who died were recorded as being on the practice palliative care register before death. Two-thirds of patients with cancer were recorded on the register, but for those with non-malignant conditions only around 20\% had any palliative care documented. This was a result of GPs not finding the current guidelines useful and being reluctant to discuss palliative care overtly with patients early in their illness. Palliative care services and documentation were geared towards patients with cancer. More district nurses than GPs saw the benefits of inclusion on the palliative care register. Only 25\% of patients on the register died in hospital.
Conclusion Most patients with advanced progressive illnesses, especially those with non-malignant disease, are not being formally identified for a palliative care approach before they die. Those identified are more likely to benefit from coordinated care and may be more likely to die at home.},
	language = {en},
	number = {598},
	urldate = {2024-06-19},
	journal = {British Journal of General Practice},
	author = {Harrison, Nadine and Cavers, Debbie and Campbell, Christine and Murray, Scott A.},
	month = may,
	year = {2012},
	pmid = {22546594},
	note = {Publisher: British Journal of General Practice
Section: Research},
	keywords = {family practice, palliative care, palliative care approach, primary care},
	pages = {e344--e352},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/N3PZHPU8/Harrison et al. - 2012 - Are UK primary care teams formally identifying pat.pdf:application/pdf},
}

@article{markowetz_all_2024,
	title = {All models are wrong and yours are useless: making clinical prediction models impactful for patients},
	volume = {8},
	copyright = {2024 The Author(s)},
	issn = {2397-768X},
	shorttitle = {All models are wrong and yours are useless},
	url = {https://www.nature.com/articles/s41698-024-00553-6},
	doi = {10.1038/s41698-024-00553-6},
	language = {en},
	number = {1},
	urldate = {2024-06-17},
	journal = {npj Precision Oncology},
	author = {Markowetz, Florian},
	month = feb,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomarkers, Mathematics and computing},
	pages = {1--3},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EID8NQV8/Markowetz - 2024 - All models are wrong and yours are useless making.pdf:application/pdf},
}

@misc{ziletti_retrieval_2024,
	title = {Retrieval augmented text-to-{SQL} generation for epidemiological question answering using electronic health records},
	url = {http://arxiv.org/abs/2403.09226},
	doi = {10.48550/arXiv.2403.09226},
	abstract = {Electronic health records (EHR) and claims data are rich sources of real-world data that reflect patient health status and healthcare utilization. Querying these databases to answer epidemiological questions is challenging due to the intricacy of medical terminology and the need for complex SQL queries. Here, we introduce an end-to-end methodology that combines text-to-SQL generation with retrieval augmented generation (RAG) to answer epidemiological questions using EHR and claims data. We show that our approach, which integrates a medical coding step into the text-to-SQL process, significantly improves the performance over simple prompting. Our findings indicate that although current language models are not yet sufficiently accurate for unsupervised use, RAG offers a promising direction for improving their capabilities, as shown in a realistic industry setting.},
	urldate = {2024-06-14},
	publisher = {arXiv},
	author = {Ziletti, Angelo and D'Ambrosi, Leonardo},
	month = may,
	year = {2024},
	note = {arXiv:2403.09226 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/QX63GZ9S/Ziletti and D'Ambrosi - 2024 - Retrieval augmented text-to-SQL generation for epi.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/AWFSDYBI/2403.html:text/html},
}

@article{murtagh_how_2014,
	title = {How many people need palliative care? {A} study developing and comparing methods for population-based estimates},
	volume = {28},
	issn = {1477-030X},
	shorttitle = {How many people need palliative care?},
	doi = {10.1177/0269216313489367},
	abstract = {BACKGROUND: Understanding the need for palliative care is essential in planning services.
AIM: To refine existing methods of estimating population-based need for palliative care and to compare these methods to better inform their use.
DESIGN: (1) Refinement of existing population-based methods, based on the views of an expert panel, and (2) application/comparison of existing and refined approaches in an example dataset. Existing methods vary in approach and in data sources. (a) Higginson used cause of death/symptom prevalence, and using pain prevalence, estimates that 60.28\% (95\% confidence interval = 60.20\%-60.36\%) of all deaths need palliative care, (b) Rosenwax used the International Statistical Classification of Diseases and Related Health Problems-10th Revision (ICD-10) causes of death/hospital-use data, and estimates that 37.01\% (95\% confidence interval = 36.94\%-37.07\%) to 96.61\% (95\% confidence interval = 96.58\%-96.64\%) of deaths need palliative care, and (c) Gómez-Batiste used percentage of deaths plus chronic disease data, and estimates that 75\% of deaths need palliative care.
SETTING/PARTICIPANTS: All deaths in England, January 2006-December 2008, using linked mortality and hospital episode data.
RESULTS: Expert panel review identified changing practice (e.g. extension of palliative care to more non-cancer conditions), changing patterns of hospital/home care and multiple, rather than single, causes of death as important. We therefore refined methods (using updated ICD-10 causes of death, underlying/contributory causes, and hospital use) to estimate a minimum of 63.03\% (95\% confidence interval = 62.95\%-63.11\%) of all deaths needing palliative care, with lower and upper mid-range estimates between 69.10\% (95\% confidence interval = 69.02\%-69.17\%) and 81.87\% (95\% confidence interval = 81.81\%-81.93\%).
CONCLUSIONS: Death registration data using both underlying and contributory causes can give reliable estimates of the population-based need for palliative care, without needing symptom or hospital activity data. In high-income countries, 69\%-82\% of those who die need palliative care.},
	language = {eng},
	number = {1},
	journal = {Palliative Medicine},
	author = {Murtagh, Fliss E. M. and Bausewein, Claudia and Verne, Julia and Groeneveld, E. Iris and Kaloki, Yvonne E. and Higginson, Irene J.},
	month = jan,
	year = {2014},
	pmid = {23695827},
	keywords = {International Classification of Diseases, Palliative Care, Terminal Care, Adolescent, Adult, Aged, Cause of Death, Child, Child, Preschool, Chronic Disease, delivery of health care, end-of-life care, England, Female, health services needs and demand, Health Services Needs and Demand, Health Status Indicators, Hospital Mortality, Humans, Infant, Infant, Newborn, Male, Middle Aged, needs assessment, Needs Assessment, Palliative care, Population Surveillance, public health, Registries, terminal care, Young Adult},
	pages = {49--58},
	file = {Accepted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/GGNDX7VN/Murtagh et al. - 2014 - How many people need palliative care A study deve.pdf:application/pdf},
}

@misc{elgohary_speak_2020,
	title = {Speak to your {Parser}: {Interactive} {Text}-to-{SQL} with {Natural} {Language} {Feedback}},
	shorttitle = {Speak to your {Parser}},
	url = {http://arxiv.org/abs/2005.02539},
	doi = {10.48550/arXiv.2005.02539},
	abstract = {We study the task of semantic parse correction with natural language feedback. Given a natural language utterance, most semantic parsing systems pose the problem as one-shot translation where the utterance is mapped to a corresponding logical form. In this paper, we investigate a more interactive scenario where humans can further interact with the system by providing free-form natural language feedback to correct the system when it generates an inaccurate interpretation of an initial utterance. We focus on natural language to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback. We compare various reference models for the correction task and show that incorporating such a rich form of feedback can significantly improve the overall semantic parsing accuracy while retaining the flexibility of natural language interaction. While we estimated human correction accuracy is 81.5\%, our best model achieves only 25.1\%, which leaves a large gap for improvement in future research. SPLASH is publicly available at https://aka.ms/Splash\_dataset.},
	urldate = {2024-06-10},
	publisher = {arXiv},
	author = {Elgohary, Ahmed and Hosseini, Saghar and Awadallah, Ahmed Hassan},
	month = jun,
	year = {2020},
	note = {arXiv:2005.02539 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PU24D7FY/Elgohary et al. - 2020 - Speak to your Parser Interactive Text-to-SQL with.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/BV7FJCME/2005.html:text/html},
}

@misc{noauthor_search_nodate,
	title = {Search},
	url = {https://open.spotify.com/search},
	abstract = {Looking for something? Find artists, songs, albums, playlists, and more.},
	language = {en},
	urldate = {2024-06-10},
	journal = {Spotify},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DJRHXCXQ/open.spotify.com.html:text/html},
}

@misc{rajkumar_evaluating_2022,
	title = {Evaluating the {Text}-to-{SQL} {Capabilities} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2204.00498},
	doi = {10.48550/arXiv.2204.00498},
	abstract = {We perform an empirical evaluation of Text-to-SQL capabilities of the Codex language model. We find that, without any finetuning, Codex is a strong baseline on the Spider benchmark; we also analyze the failure modes of Codex in this setting. Furthermore, we demonstrate on the GeoQuery and Scholar benchmarks that a small number of in-domain examples provided in the prompt enables Codex to perform better than state-of-the-art models finetuned on such few-shot examples.},
	urldate = {2024-06-10},
	publisher = {arXiv},
	author = {Rajkumar, Nitarshan and Li, Raymond and Bahdanau, Dzmitry},
	month = mar,
	year = {2022},
	note = {arXiv:2204.00498 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Databases},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/DHDH4658/Rajkumar et al. - 2022 - Evaluating the Text-to-SQL Capabilities of Large L.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/5NWR7B9I/2204.html:text/html},
}

@inproceedings{liu_effective_2021,
	address = {Online and Punta Cana, Dominican Republic},
	title = {Effective {Convolutional} {Attention} {Network} for {Multi}-label {Clinical} {Document} {Classification}},
	url = {https://aclanthology.org/2021.emnlp-main.481},
	doi = {10.18653/v1/2021.emnlp-main.481},
	abstract = {Multi-label document classification (MLDC) problems can be challenging, especially for long documents with a large label set and a long-tail distribution over labels. In this paper, we present an effective convolutional attention network for the MLDC problem with a focus on medical code prediction from clinical documents. Our innovations are three-fold: (1) we utilize a deep convolution-based encoder with the squeeze-and-excitation networks and residual networks to aggregate the information across the document and learn meaningful document representations that cover different ranges of texts; (2) we explore multi-layer and sum-pooling attention to extract the most informative features from these multi-scale representations; (3) we combine binary cross entropy loss and focal loss to improve performance for rare labels. We focus our evaluation study on MIMIC-III, a widely used dataset in the medical domain. Our models outperform prior work on medical coding and achieve new state-of-the-art results on multiple metrics. We also demonstrate the language independent nature of our approach by applying it to two non-English datasets. Our model outperforms prior best model and a multilingual Transformer model by a substantial margin.},
	urldate = {2024-06-10},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Yang and Cheng, Hua and Klopfer, Russell and Gormley, Matthew R. and Schaaf, Thomas},
	editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
	month = nov,
	year = {2021},
	pages = {5941--5953},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/AWJ8J69A/Liu et al. - 2021 - Effective Convolutional Attention Network for Mult.pdf:application/pdf},
}

@misc{yang_multi-label_2022,
	title = {Multi-label {Few}-shot {ICD} {Coding} as {Autoregressive} {Generation} with {Prompt}},
	url = {http://arxiv.org/abs/2211.13813},
	doi = {10.48550/arXiv.2211.13813},
	abstract = {Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with an average of 3,000+ tokens. This task is challenging due to the high-dimensional space of multi-label assignment (155,000+ ICD code candidates) and the long-tail challenge - Many ICD codes are infrequently assigned yet infrequent ICD codes are important clinically. This study addresses the long-tail challenge by transforming this multi-label classification task into an autoregressive generation task. Specifically, we first introduce a novel pretraining objective to generate free text diagnoses and procedure using the SOAP structure, the medical logic physicians use for note documentation. Second, instead of directly predicting the high dimensional space of ICD codes, our model generates the lower dimension of text descriptions, which then infer ICD codes. Third, we designed a novel prompt template for multi-label classification. We evaluate our Generation with Prompt model with the benchmark of all code assignment (MIMIC-III-full) and few shot ICD code assignment evaluation benchmark (MIMIC-III-few). Experiments on MIMIC-III-few show that our model performs with a marco F1 30.2, which substantially outperforms the previous MIMIC-III-full SOTA model (marco F1 4.3) and the model specifically designed for few/zero shot setting (marco F1 18.7). Finally, we design a novel ensemble learner, a cross attention reranker with prompts, to integrate previous SOTA and our best few-shot coding predictions. Experiments on MIMIC-III-full show that our ensemble learner substantially improves both macro and micro F1, from 10.4 to 14.6 and from 58.2 to 59.1, respectively.},
	urldate = {2024-06-07},
	publisher = {arXiv},
	author = {Yang, Zhichao and Kwon, Sunjae and Yao, Zonghai and Yu, Hong},
	month = nov,
	year = {2022},
	note = {arXiv:2211.13813 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/IGQL2CYD/Yang et al. - 2022 - Multi-label Few-shot ICD Coding as Autoregressive .pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/6A4ZGB3H/2211.html:text/html},
}

@misc{schoenegger_wisdom_2024,
	title = {Wisdom of the {Silicon} {Crowd}: {LLM} {Ensemble} {Prediction} {Capabilities} {Rival} {Human} {Crowd} {Accuracy}},
	shorttitle = {Wisdom of the {Silicon} {Crowd}},
	url = {http://arxiv.org/abs/2402.19379},
	doi = {10.48550/arXiv.2402.19379},
	abstract = {Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our preregistered main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is not statistically different from the human crowd. In exploratory analyses, we find that these two approaches are equivalent with respect to medium-effect-size equivalence bounds. We also observe an acquiescence effect, with mean model predictions being significantly above 50\%, despite an almost even split of positive and negative resolutions. Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2) can be improved by drawing on human cognitive output. We find that both models' forecasting accuracy benefits from exposure to the median human prediction as information, improving accuracy by between 17\% and 28\%: though this leads to less accurate predictions than simply averaging human and machine forecasts. Our results suggest that LLMs can achieve forecasting accuracy rivaling that of human crowd forecasting tournaments: via the simple, practically applicable method of forecast aggregation. This replicates the 'wisdom of the crowd' effect for LLMs, and opens up their use for a variety of applications throughout society.},
	urldate = {2024-06-06},
	publisher = {arXiv},
	author = {Schoenegger, Philipp and Tuminauskaite, Indre and Park, Peter S. and Tetlock, Philip E.},
	month = may,
	year = {2024},
	note = {arXiv:2402.19379 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MP96X64N/Schoenegger et al. - 2024 - Wisdom of the Silicon Crowd LLM Ensemble Predicti.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/BIP3J27H/2402.html:text/html},
}

@article{liupengfei_pre-train_2023,
	title = {Pre-train, {Prompt}, and {Predict}: {A} {Systematic} {Survey} of {Prompting} {Methods} in {Natural} {Language} {Processing}},
	copyright = {Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.},
	shorttitle = {Pre-train, {Prompt}, and {Predict}},
	url = {https://dl.acm.org/doi/10.1145/3560815},
	doi = {10.1145/3560815},
	abstract = {This article surveys and organizes research works in a new paradigm in natural language
processing, which we dub “prompt-based learning.” Unlike traditional supervised learning,
which trains a model to take in an input x and predict an output y as P(y{\textbar}x), ...},
	language = {EN},
	urldate = {2024-06-04},
	journal = {ACM Computing Surveys},
	author = {LiuPengfei and YuanWeizhe and FuJinlan and JiangZhengbao and HayashiHiroaki and NeubigGraham},
	month = jan,
	year = {2023},
	note = {Publisher: ACMPUB27New York, NY},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/UB56RUYR/LiuPengfei et al. - 2023 - Pre-train, Prompt, and Predict A Systematic Surve.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/NJHHSZ8D/3560815.html:text/html},
}

@misc{herlihy_mednli_2021,
	title = {{MedNLI} {Is} {Not} {Immune}: {Natural} {Language} {Inference} {Artifacts} in the {Clinical} {Domain}},
	shorttitle = {{MedNLI} {Is} {Not} {Immune}},
	url = {http://arxiv.org/abs/2106.01491},
	abstract = {Crowdworker-constructed natural language inference (NLI) datasets have been found to contain statistical artifacts associated with the annotation process that allow hypothesis-only classiﬁers to achieve better-than-random performance (Poliak et al., 2018; Gururangan et al., 2018; Tsuchiya, 2018). We investigate whether MedNLI, a physician-annotated dataset with premises extracted from clinical notes, contains such artifacts (Romanov and Shivade, 2018).},
	language = {en},
	urldate = {2024-06-02},
	publisher = {arXiv},
	author = {Herlihy, Christine and Rudinger, Rachel},
	month = jun,
	year = {2021},
	note = {arXiv:2106.01491 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Herlihy and Rudinger - 2021 - MedNLI Is Not Immune Natural Language Inference A.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZEA6WEPC/Herlihy and Rudinger - 2021 - MedNLI Is Not Immune Natural Language Inference A.pdf:application/pdf},
}

@misc{romanov_lessons_2018,
	title = {Lessons from {Natural} {Language} {Inference} in the {Clinical} {Domain}},
	url = {http://arxiv.org/abs/1808.06752},
	abstract = {State of the art models using deep neural networks have become very good in learning an accurate mapping from inputs to outputs. However, they still lack generalization capabilities in conditions that differ from the ones encountered during training. This is even more challenging in specialized, and knowledge intensive domains, where training data is limited. To address this gap, we introduce MedNLI1 – a dataset annotated by doctors, performing a natural language inference task (NLI), grounded in the medical history of patients. We present strategies to: 1) leverage transfer learning using datasets from the open domain, (e.g. SNLI) and 2) incorporate domain knowledge from external data and lexical sources (e.g. medical terminologies). Our results demonstrate performance gains using both strategies.},
	language = {en},
	urldate = {2024-05-27},
	publisher = {arXiv},
	author = {Romanov, Alexey and Shivade, Chaitanya},
	month = aug,
	year = {2018},
	note = {arXiv:1808.06752 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Romanov and Shivade - 2018 - Lessons from Natural Language Inference in the Cli.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZKJBXUNS/Romanov and Shivade - 2018 - Lessons from Natural Language Inference in the Cli.pdf:application/pdf},
}

@misc{dada_clue_2024,
	title = {{CLUE}: {A} {Clinical} {Language} {Understanding} {Evaluation} for {LLMs}},
	shorttitle = {{CLUE}},
	url = {http://arxiv.org/abs/2404.04067},
	doi = {10.48550/arXiv.2404.04067},
	abstract = {Large Language Models (LLMs) have shown the potential to significantly contribute to patient care, diagnostics, and administrative processes. Emerging biomedical LLMs address healthcare-specific challenges, including privacy demands and computational constraints. However, evaluation of these models has primarily been limited to non-clinical tasks, which do not reflect the complexity of practical clinical applications. Additionally, there has been no thorough comparison between biomedical and general-domain LLMs for clinical tasks. To fill this gap, we present the Clinical Language Understanding Evaluation (CLUE), a benchmark tailored to evaluate LLMs on real-world clinical tasks. CLUE includes two novel datasets derived from MIMIC IV discharge letters and four existing tasks designed to test the practical applicability of LLMs in healthcare settings. Our evaluation covers several biomedical and general domain LLMs, providing insights into their clinical performance and applicability. CLUE represents a step towards a standardized approach to evaluating and developing LLMs in healthcare to align future model development with the real-world needs of clinical application. We publish our evaluation and data generation scripts: https://github.com/TIO-IKIM/CLUE.},
	urldate = {2024-05-27},
	publisher = {arXiv},
	author = {Dada, Amin and Bauer, Marie and Contreras, Amanda Butler and Koraş, Osman Alperen and Seibold, Constantin Marc and Smith, Kaleb E. and Kleesiek, Jens},
	month = apr,
	year = {2024},
	note = {arXiv:2404.04067 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZF8N45P6/Dada et al. - 2024 - CLUE A Clinical Language Understanding Evaluation.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/4RDKQ67A/2404.html:text/html},
}

@misc{adams_longhealth_2024,
	title = {{LongHealth}: {A} {Question} {Answering} {Benchmark} with {Long} {Clinical} {Documents}},
	shorttitle = {{LongHealth}},
	url = {http://arxiv.org/abs/2401.14490},
	abstract = {Background: Recent advancements in large language models (LLMs) offer potential benefits in healthcare, particularly in processing extensive patient records. However, existing benchmarks do not fully assess LLMs’ capability in handling real-world, lengthy clinical data.
Methods: We present the LongHealth benchmark, comprising 20 detailed fictional patient cases across various diseases, with each case containing 5,090 to 6,754 words. The benchmark challenges LLMs with 400 multiple-choice questions in three categories: information extraction, negation, and sorting, challenging LLMs to extract and interpret information from large clinical documents.
Results: We evaluated nine open-source LLMs with a minimum of 16,000 tokens and also included OpenAI’s proprietary and cost-efficient GPT-3.5 Turbo for comparison. The highest accuracy was observed for Mixtral-8x7B-Instruct-v0.1, particularly in tasks focused on information retrieval from single and multiple patient documents. However, all models struggled significantly in tasks requiring the identification of missing information, highlighting a critical area for improvement in clinical data interpretation.
Conclusion: While LLMs show considerable potential for processing long clinical documents, their current accuracy levels are insufficient for reliable clinical use, especially in scenarios requiring the identification of missing information. The LongHealth benchmark provides a more realistic assessment of LLMs in a healthcare setting and highlights the need for further model refinement for safe and effective clinical application.},
	language = {en},
	urldate = {2024-05-27},
	publisher = {arXiv},
	author = {Adams, Lisa and Busch, Felix and Han, Tianyu and Excoffier, Jean-Baptiste and Ortala, Matthieu and Löser, Alexander and Aerts, Hugo JWL and Kather, Jakob Nikolas and Truhn, Daniel and Bressem, Keno},
	month = jan,
	year = {2024},
	note = {arXiv:2401.14490 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Adams et al. - 2024 - LongHealth A Question Answering Benchmark with Lo.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/BZTCD8RV/Adams et al. - 2024 - LongHealth A Question Answering Benchmark with Lo.pdf:application/pdf},
}

@article{wallis_association_2015,
	title = {Association of the clinical frailty scale with hospital outcomes},
	volume = {108},
	issn = {1460-2725},
	url = {https://doi.org/10.1093/qjmed/hcv066},
	doi = {10.1093/qjmed/hcv066},
	abstract = {Background: the clinical frailty scale (CFS) was validated as a predictor of adverse outcomes in community-dwelling older people. In our hospital, the use of the CFS in emergency admissions of people aged ≥ 75 years was introduced under the Commissioning for Quality and Innovation payment framework.Aim: we retrospectively studied the association of the CFS with patient characteristics and outcomes.Design: retrospective observational study in a large tertiary university National Health Service hospital in UK.Methods: the CFS was correlated with transfer to specialist Geriatric ward, length of stay (LOS), in-patient mortality and 30-day readmission rate.Results: between 1st August 2013 and 31st July 2014, there were 11 271 emergency admission episodes of people aged ≥ 75 years (all specialties), corresponding to 7532 unique patients (first admissions); of those, 5764 had the CFS measured by the admitting team (81\% of them within 72 hr of admission). After adjustment for age, gender, Charlson comorbidity index and history of dementia and/or current cognitive concern, the CFS was an independent predictor of in-patient mortality [odds ratio (OR) = 1.60, 95\% confidence interval (CI): 1.48 to 1.74, P \&lt; 0.001], transfer to Geriatric ward (OR = 1.33, 95\% CI: 1.24 to 1.42, P \&lt; 0.001) and LOS ≥ 10 days (OR = 1.19, 95\% CI: 1.14 to 1.23, P \&lt; 0.001). The CFS was not a multivariate predictor of 30-day readmission.Conclusions: the CFS may help predict in-patient mortality and target specialist geriatric resources within the hospital. Usual hospital metrics such as mortality and LOS should take into account measurable patient complexity.},
	number = {12},
	urldate = {2024-05-21},
	journal = {QJM: An International Journal of Medicine},
	author = {Wallis, S.J. and Wall, J. and Biram, R.W.S. and Romero-Ortuno, R.},
	month = dec,
	year = {2015},
	pages = {943--949},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/DZ5QE7TZ/Wallis et al. - 2015 - Association of the clinical frailty scale with hos.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/RMAGF4GB/1889634.html:text/html},
}

@article{clegg_development_2016,
	title = {Development and validation of an electronic frailty index using routine primary care electronic health record data},
	volume = {45},
	issn = {0002-0729},
	url = {https://doi.org/10.1093/ageing/afw039},
	doi = {10.1093/ageing/afw039},
	abstract = {Background: frailty is an especially problematic expression of population ageing. International guidelines recommend routine identification of frailty to provide evidence-based treatment, but currently available tools require additional resource.Objectives: to develop and validate an electronic frailty index (eFI) using routinely available primary care electronic health record data.Study design and setting: retrospective cohort study. Development and internal validation cohorts were established using a randomly split sample of the ResearchOne primary care database. External validation cohort established using THIN database.Participants: patients aged 65–95, registered with a ResearchOne or THIN practice on 14 October 2008.Predictors: we constructed the eFI using the cumulative deficit frailty model as our theoretical framework. The eFI score is calculated by the presence or absence of individual deficits as a proportion of the total possible. Categories of fit, mild, moderate and severe frailty were defined using population quartiles.Outcomes: outcomes were 1-, 3- and 5-year mortality, hospitalisation and nursing home admission.Statistical analysis: hazard ratios (HRs) were estimated using bivariate and multivariate Cox regression analyses. Discrimination was assessed using receiver operating characteristic (ROC) curves. Calibration was assessed using pseudo-R2 estimates.Results: we include data from a total of 931,541 patients. The eFI incorporates 36 deficits constructed using 2,171 CTV3 codes. One-year adjusted HR for mortality was 1.92 (95\% CI 1.81–2.04) for mild frailty, 3.10 (95\% CI 2.91–3.31) for moderate frailty and 4.52 (95\% CI 4.16–4.91) for severe frailty. Corresponding estimates for hospitalisation were 1.93 (95\% CI 1.86–2.01), 3.04 (95\% CI 2.90–3.19) and 4.73 (95\% CI 4.43–5.06) and for nursing home admission were 1.89 (95\% CI 1.63–2.15), 3.19 (95\% CI 2.73–3.73) and 4.76 (95\% CI 3.92–5.77), with good to moderate discrimination but low calibration estimates.Conclusions: the eFI uses routine data to identify older people with mild, moderate and severe frailty, with robust predictive validity for outcomes of mortality, hospitalisation and nursing home admission. Routine implementation of the eFI could enable delivery of evidence-based interventions to improve outcomes for this vulnerable group.},
	number = {3},
	urldate = {2024-05-21},
	journal = {Age and Ageing},
	author = {Clegg, Andrew and Bates, Chris and Young, John and Ryan, Ronan and Nichols, Linda and Ann Teale, Elizabeth and Mohammed, Mohammed A. and Parry, John and Marshall, Tom},
	month = may,
	year = {2016},
	pages = {353--360},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/HNHHVLVX/Clegg et al. - 2016 - Development and validation of an electronic frailt.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/KWZUPBL5/1739750.html:text/html},
}

@article{mason_developing_2015,
	title = {Developing a computerised search to help {UK} {General} {Practices} identify more patients for palliative care planning: a feasibility study},
	volume = {16},
	issn = {1471-2296},
	shorttitle = {Developing a computerised search to help {UK} {General} {Practices} identify more patients for palliative care planning},
	url = {https://doi.org/10.1186/s12875-015-0312-z},
	doi = {10.1186/s12875-015-0312-z},
	abstract = {Approximately 600,000 people die in the UK annually, usually after months or years of increasing debility. Many patients with advanced conditions are not identified for appropriate support before they die because they are not seen as having “palliative” care needs. General practice information technology systems can improve care by identifying patients with deteriorating health so that their healthcare needs can be reviewed more systematically and effectively. The aim was to develop and test a computerised search of primary care records in routine clinical practice as a tool to improve patient identification for a palliative care approach.},
	language = {en},
	number = {1},
	urldate = {2024-05-19},
	journal = {BMC Family Practice},
	author = {Mason, Bruce and Boyd, Kirsty and Murray, Scott A. and Steyn, John and Cormie, Paul and Kendall, Marilyn and Munday, Dan and Weller, David and Fife, Shirley and Murchie, Peter and Campbell, Christine},
	month = aug,
	year = {2015},
	keywords = {Palliative care, General practice, Primary healthcare, Qualitative research},
	pages = {99},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JTZAKUW3/Mason et al. - 2015 - Developing a computerised search to help UK Genera.pdf:application/pdf},
}

@article{krause_delphi_2022,
	title = {A {Delphi} study to guide the development of a clinical indicator tool for palliative care in {South} {Africa}},
	volume = {14},
	copyright = {Copyright (c) 2022 Rene Krause},
	issn = {2071-2936},
	url = {https://phcfm.org/index.php/phcfm/article/view/3351},
	doi = {10.4102/phcfm.v14i1.3351},
	abstract = {Background:  The South African National Policy Framework and Strategy on Palliative Care (NPFSPC) recommends that when integrating palliative care (PC) into the health system, a PC indicators tool should be used to guide clinicians to recognise a patient who should receive PC. The policy document recommends ‘a simple screening tool developed for use in South Africa that would assist healthcare professionals (HCPs) to recognise patients who may have unmet palliative care needs’.   Aim:  This research study sought to develop South African consensus on indicators for PC to assist clinicians to recognise a patient in need of PC.   Setting:  The South African healthcare setting.   Methods:  A Delphi study was considered suitable as a methodology to develop consensus. The methodology was based on the Conducting and REporting of DElphi studies (CREDES) guidance on Delphi studies to ensure rigour and transparency in conducting and reporting. Six different Delphi rounds were used to develop consensus. Each round allowed participants to anonymously rate statements with predefined rating scales.   Results:  Cognisant of the disparities in healthcare provision and access to equitable healthcare in South Africa, the expert advisory group recommended, especially for South Africa, that ‘this tool is for deteriorating patients with an advanced life-limiting illness where all available and appropriate management for underlying illnesses and reversible complications has been offered’. The expert advisory group felt that disease-specific indicators should be described before the general indicators in the South African indicators tool, so all users of the tool orientate themselves to the disease categories first. This study included three new domains to address the South African context: trauma, infectious diseases and haematological diseases. General indicators for PC aligned with the original Supportive and Palliative Care Indicators Tool (SPICT) tool.   Conclusion:  The Supportive and Palliative Care Indicators Tool for South Africa (SPICT TM -SA) is a simple screening tool for South Africa that may assist HCPs to recognise patients who may have unmet PC needs.},
	language = {en},
	number = {1},
	urldate = {2024-05-18},
	journal = {African Journal of Primary Health Care \& Family Medicine},
	author = {Krause, Rene and Barnard, Alan and Burger, Henriette and Vos, Andre de and Evans, Katya and Farrant, Lindsay and Fouche, Nicki and Kalula, Sebastiana and Morgan, Jennie and Mohamed, Zainab and Panieri, Eugenio and Ras, Tasleem and Raubenheimer, Peter and Verburg, Estelle and Boyd, Kirsty and Gwyther, Liz},
	month = may,
	year = {2022},
	note = {Number: 1},
	pages = {7},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/F263BV94/Krause et al. - 2022 - A Delphi study to guide the development of a clini.pdf:application/pdf},
}

@article{boyle_autospict_nodate,
	title = {{AutoSPICT}: {Automatic} {Palliative} {Care} {Screening}},
	abstract = {As the global population ages, the role of palliative care in minimizing the suffering of patients nearing death has increasing importance[1]. Patients who receive palliative care on average require fewer hospitalizations, experience reduced distress, and incur reduced healthcare costs. However, the difficulty of accurate prognostication means that proactive care is similarly difficult: clinicians are systematically optimistic in estimating a patient’s remaining lifespan[2, 3], meaning opportunities for palliative interventions are often missed. Screening tools such as the Supportive and Palliative Care Indicators Tool (SPICT) have been developed with the aim of standardizing the process. We observe that many criteria in the SPICT guidelines can be answered using data already recorded in patient health records. We hypothesize that automated application of the SPICT guidelines could improve identification of potential palliative care patients. In this study we retrospectively analysed all patients registered with NHS Nottinghamshire who were aged 65 or older in the period 2018 – 2023. Of the 2,055,672 included patients (mean age 40.83 years, s.d = 21.96, 50.70\% female), our automated system detected 112,566 patients who met the automated SPICT criteria. Positive identification with the automated SPICT criteria was associated with a 1-year mortality hazard ratio (HR) of 15.93 with a 95\% CI of [15.37, 16.50]. Of the identified patients, 9.57\% were on, or were placed on within 1 year, a palliative care register; compared to just 0.47\% in the non-identified group, validating the utility of our automated screening tool in obtaining a cohort with enhanced signal purity.},
	language = {en},
	author = {Boyle, Joseph S and O’Neil, Mike and Kascenas, Antanas and Liakata, Maria and O’Neil, Alison Q},
	file = {Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (15).pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/MWVCXSVW/Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (15).pdf:application/pdf;Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (21).pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/R7JQR9F3/Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (21).pdf:application/pdf;Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (26).pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/NHUKG6I9/Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (26).pdf:application/pdf;Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (28).pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/P8P4AGQ6/Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (28).pdf:application/pdf;Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (32).pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/NY2R7EJQ/Auto_SPICT__Automatic_Identification_of_Palliative_Care_Needs (32).pdf:application/pdf;Boyle et al. - AutoSPICT Automatic Palliative Care Screening.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/994N88IV/Boyle et al. - AutoSPICT Automatic Palliative Care Screening.pdf:application/pdf},
}

@misc{noauthor_using_nodate,
	title = {Using intuition or a formal palliative care needs assessment screening process in general practice to predict death within 12 months: {A} randomised controlled trial},
	shorttitle = {Using intuition or a formal palliative care needs assessment screening process in general practice to predict death within 12 months},
	url = {https://journals.sagepub.com/doi/epdf/10.1177/0269216317698621},
	language = {en},
	urldate = {2024-05-18},
	doi = {10.1177/0269216317698621},
	file = {mitchell-et-al-2017-using-intuition-or-a-formal-palliative-care-needs-assessment-screening-process-in-general-practice.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/7XIBC68Z/mitchell-et-al-2017-using-intuition-or-a-formal-palliative-care-needs-assessment-screening-process-in-general-practice.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/5AQXB9X4/0269216317698621.html:text/html},
}

@article{peleg_computer-interpretable_2013,
	title = {Computer-interpretable clinical guidelines: {A} methodological review},
	volume = {46},
	issn = {1532-0464},
	shorttitle = {Computer-interpretable clinical guidelines},
	url = {https://www.sciencedirect.com/science/article/pii/S1532046413000841},
	doi = {10.1016/j.jbi.2013.06.009},
	abstract = {Clinical practice guidelines (CPGs) aim to improve the quality of care, reduce unjustified practice variations and reduce healthcare costs. In order for them to be effective, clinical guidelines need to be integrated with the care flow and provide patient-specific advice when and where needed. Hence, their formalization as computer-interpretable guidelines (CIGs) makes it possible to develop CIG-based decision-support systems (DSSs), which have a better chance of impacting clinician behavior than narrative guidelines. This paper reviews the literature on CIG-related methodologies since the inception of CIGs, while focusing and drawing themes for classifying CIG research from CIG-related publications in the Journal of Biomedical Informatics (JBI). The themes span the entire life-cycle of CIG development and include: knowledge acquisition and specification for improved CIG design, including (1) CIG modeling languages and (2) CIG acquisition and specification methodologies, (3) integration of CIGs with electronic health records (EHRs) and organizational workflow, (4) CIG validation and verification, (5) CIG execution engines and supportive tools, (6) exception handling in CIGs, (7) CIG maintenance, including analyzing clinician’s compliance to CIG recommendations and CIG versioning and evolution, and finally (8) CIG sharing. I examine the temporal trends in CIG-related research and discuss additional themes that were not identified in JBI papers, including existing themes such as overcoming implementation barriers, modeling clinical goals, and temporal expressions, as well as futuristic themes, such as patient-centric CIGs and distributed CIGs.},
	number = {4},
	urldate = {2024-05-17},
	journal = {Journal of Biomedical Informatics},
	author = {Peleg, Mor},
	month = aug,
	year = {2013},
	keywords = {Clinical practice guidelines, Computer-interpretable clinical guidelines, Decision-support systems, Knowledge representation},
	pages = {744--763},
	file = {Peleg - 2013 - Computer-interpretable clinical guidelines A meth.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/4I7G2NDC/Peleg - 2013 - Computer-interpretable clinical guidelines A meth.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/VCWQZ3YM/S1532046413000841.html:text/html},
}

@misc{song_combining_2024,
	title = {Combining {Hierachical} {VAEs} with {LLMs} for clinically meaningful timeline summarisation in social media},
	url = {http://arxiv.org/abs/2401.16240},
	abstract = {We introduce a hybrid abstractive summarisation approach combining hierarchical VAE with LLMs (LlaMA-2) to produce clinically meaningful summaries from social media user timelines, appropriate for mental health monitoring. The summaries combine two different narrative points of view: clinical insights in third person useful for a clinician are generated by feeding into an LLM specialised clinical prompts, and importantly, a temporally sensitive abstractive summary of the user’s timeline in first person, generated by a novel hierarchical variational autoencoder, TH-VAE. We assess the generated summaries via automatic evaluation against expert summaries and via human evaluation with clinical experts, showing that timeline summarisation by TH-VAE results in more factual and logically coherent summaries rich in clinical utility and superior to LLM-only approaches in capturing changes over time.},
	language = {en},
	urldate = {2024-05-14},
	publisher = {arXiv},
	author = {Song, Jiayu and Chim, Jenny and Tsakalidis, Adam and Ive, Julia and Atzil-Slonim, Dana and Liakata, Maria},
	month = feb,
	year = {2024},
	note = {arXiv:2401.16240 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Song et al. - 2024 - Combining Hierachical VAEs with LLMs for clinicall.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/HJ4GGZSP/Song et al. - 2024 - Combining Hierachical VAEs with LLMs for clinicall.pdf:application/pdf},
}

@article{larsen_enough_2024,
	title = {Enough {With} the {Incels}! {A} {Literary} {Cry} for {Help} {From} {Female} {Insings} ({Involuntary} {Single})},
	doi = {10.1037/ebs0000349},
	abstract = {Modern mating markets relegate a growing number of men to being incels (involuntary celibate). Increasing attention befalls another group struggling in the same markets: female insings (involuntary single). In the partly autobiographical novel, Half of Malmö Consists of Guys Who Dumped Me (2021), Amanda Romare dramatizes how urban dating and technologies like Tinder exploit women's evolved mate preferences in a manner that drives addiction and dysfunction. Many women have practically unlimited access to serial dating and short-term sex with highly attractive men, but such experiences can leave women less able to calibrate their mating strategies, thus making it harder to acquire a long-term partner. Romare argues that incels get too much attention, as our culture blinds us to the plight of lonely women. To investigate the insing phenomenon , we apply sexual strategies theory, sexual conflict theory, and other frameworks from evolutionary psychology. Mismatch, conflicting desires, and exploitative technologies make many women prioritize mate qualities that misalign with their pair-bonding ambitions. Juxtaposing Romare's novel with the TV series Sigurd Can't Get Laid (2020-2022) aids us in comparing insings to incels. Our analysis illustrates how both groups fall victim to our evolved mate preferences. Communities that develop a better understanding of these preferences could improve intersexual communication, which might help them find more productive ways to mate. Public Significance Statement Our two fictional case studies illuminate why an alarming number of youths are opting out of both short-and long-term mating. High singledom and sexual inactivity may contribute to our era's impending demographic collapse, which threatens social stability and human prospering. Analyzing fictional portrayals of dating dysfunction through the lens of evolutionary psychology could generate insights that help individuals and communities progress past our current malaise.},
	journal = {Evolutionary Behavioral Sciences},
	author = {Larsen, Mads and Kennair, Leif Edward},
	month = may,
	year = {2024},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CDX7TMV2/Larsen and Kennair - 2024 - Enough With the Incels! A Literary Cry for Help Fr.pdf:application/pdf},
}

@article{gomez-batiste_prevalence_2014,
	title = {Prevalence and characteristics of patients with advanced chronic conditions in need of palliative care in the general population: {A} cross-sectional study},
	volume = {28},
	shorttitle = {Prevalence and characteristics of patients with advanced chronic conditions in need of palliative care in the general population},
	doi = {10.1177/0269216313518266},
	abstract = {Background: 
Of deaths in high-income countries, 75\% are caused by progressive advanced chronic conditions. Palliative care needs to be extended from terminal cancer to these patients. However, direct measurement of the prevalence of people in need of palliative care in the population has not been attempted.

Aim:
Determine, by direct measurement, the prevalence of people in need of palliative care among advanced chronically ill patients in a whole geographic population.

Design:
Cross-sectional, population-based study.

Main outcome measure:
prevalence of advanced chronically ill patients in need of palliative care according to the NECPAL CCOMS-ICO(©) tool. NECPAL+ patients were considered as in need of palliative care.

Setting/participants:
County of Osona, Catalonia, Spain (156,807 inhabitants, 21.4\% {\textgreater} 65 years). Three randomly selected primary care centres (51,595 inhabitants, 32.9\% of County's population) and one district general hospital, one social-health centre and four nursing homes serving the patients. Subjects were all patients attending participating settings between November 2010 and October 2011.

Results:
A total of 785 patients (1.5\% of study population) were NECPAL+: mean age = 81.4 years; 61.4\% female. Main disease/condition: 31.3\% advanced frailty, 23.4\% dementia, 12.9\% cancer (ratio of cancer/non-cancer = 1/7), 66.8\% living at home and 19.7\% in nursing home; only 15.5\% previously identified as requiring palliative care; general clinical indicators of severity and progression present in 94\% of cases.

Conclusions:
Direct measurement of prevalence of palliative care needs on a population basis is feasible. Early identification and prevalence determination of these patients is likely to be the cornerstone of palliative care public health policies.},
	journal = {Palliative medicine},
	author = {Gómez-Batiste, Xavier and Martínez-Muñoz, Marisa and Blay, Carles and Amblàs Novellas, Jordi and Vila, Laura and Costa, Xavier and Espaulella, Joan and Espinosa, Jose and Constante, Carles and Mitchell, Geoffrey},
	month = jan,
	year = {2014},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/AGUF3PPS/Gómez-Batiste et al. - 2014 - Prevalence and characteristics of patients with ad.pdf:application/pdf},
}

@article{scott_modelling_2023,
	title = {Modelling clinical narrative as computable knowledge: {The} {NICE} computable implementation guidance project},
	volume = {7},
	issn = {2379-6146},
	shorttitle = {Modelling clinical narrative as computable knowledge},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/lrh2.10394},
	doi = {10.1002/lrh2.10394},
	abstract = {Introduction Translating narrative clinical guidelines to computable knowledge is a long-standing challenge that has seen a diverse range of approaches. The UK National Institute for Health and Care Excellence (NICE) Content Advisory Board (CAB) aims ultimately to (1) guide clinical decision support and other software developers to increase traceability, fidelity and consistency in supporting clinical use of NICE recommendations, (2) guide local practice audit and intervention to reduce unwarranted variation, (3) provide feedback to NICE on how future recommendations should be developed. Objectives The first phase of work was to explore a range of technical approaches to transition NICE toward the production of natively digital content. Methods Following an initial ‘collaborathon’ in November 2022, the NICE Computable Implementation Guidance project (NCIG) was established. We held a series of workstream calls approximately fortnightly, focusing on (1) user stories and trigger events, (2) information model and definitions, (3) horizon-scanning and output format. A second collaborathon was held in March 2023 to consolidate progress across the workstreams and agree residual actions to complete. Results While we initially focussed on technical implementation standards, we decided that an intermediate logical model was a more achievable first step in the journey from narrative to fully computable representation. NCIG adopted the WHO Digital Adaptation Kit (DAK) as a technology-agnostic method to model user scenarios, personae, processes and workflow, core data elements and decision-support logic. Further work will address indicators, such as prescribing compliance, and implementation in document templates for primary care patient record systems. Conclusions The project has shown that the WHO DAK, with some modification, is a promising approach to build technology-neutral logical specifications of NICE recommendations. Implementation of concurrent computable modelling by multidisciplinary teams during guideline development poses methodological and cultural questions that are complex but tractable given suitable will and leadership.},
	language = {en},
	number = {4},
	urldate = {2024-05-12},
	journal = {Learning Health Systems},
	author = {Scott, Philip and Heigl, Michaela and McCay, Charles and Shepperdson, Polly and Lima-Walton, Elia and Andrikopoulou, Elisavet and Brunnhuber, Klara and Cornelius, Gary and Faulding, Susan and McAlister, Ben and Rowark, Shaun and South, Matthew and Thomas, Mark R. and Whatling, Justin and Williams, John and Wyatt, Jeremy C. and Greaves, Felix},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/lrh2.10394},
	keywords = {clinical decision support systems, computable knowledge, decision modelling, practice guideline},
	pages = {e10394},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/S5J5DDRB/Scott et al. - 2023 - Modelling clinical narrative as computable knowled.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/VGV4CTCY/lrh2.html:text/html},
}

@misc{nhs_england_quality_nodate,
	title = {Quality and {Outcomes} {Framework}, 2022-23},
	url = {https://digital.nhs.uk/data-and-information/publications/statistical/quality-and-outcomes-framework-achievement-prevalence-and-exceptions-data/2022-23},
	abstract = {Quality and Outcomes Framework (QOF) 2022-23 prevalence, achievement and personalised care adjustments data. Data in the publication are presented at national, regional, ICB, sub ICB and GP practice level.},
	language = {en},
	urldate = {2024-05-10},
	journal = {NHS England Digital},
	author = {{NHS England}},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/225CNI8Q/2022-23.html:text/html},
}

@misc{noauthor_quality_nodate,
	title = {Quality and {Outcomes} {Framework} ({QOF})},
	url = {https://digital.nhs.uk/data-and-information/data-tools-and-services/data-services/general-practice-data-hub/quality-outcomes-framework-qof},
	abstract = {Measures, called indicators are agreed as part of the GP contract negotiations every year. These indicators have points attached that are given to GP practices based on how they are doing against these measures, disease prevalence and care quality achievement rates.},
	language = {en},
	urldate = {2024-05-10},
	journal = {NHS England Digital},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/NQDN4EYS/quality-outcomes-framework-qof.html:text/html},
}

@misc{noauthor_notitle_nodate,
	file = {433_do_large_language_models_under.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/CBR7GDS9/433_do_large_language_models_under.pdf:application/pdf},
}

@article{low_screening_2022,
	title = {Do screening tools assess palliative care needs and 12-month mortality in patients admitted to hepatology in-patient wards?},
	volume = {13},
	issn = {2041-4137, 2041-4145},
	url = {https://fg.bmj.com/lookup/doi/10.1136/flgastro-2020-101709},
	doi = {10.1136/flgastro-2020-101709},
	abstract = {Background  Many liver patients have unmet palliative care needs, but liver clinicians are unclear whom to refer to specialist palliative care (SPC). The Supportive and Palliative Care Indicator Tool (SPICT) and the Bristol Prognostic Screening Tool (BPST) could help identify suitable patients, but neither has been tested for this role. This study evaluated their role as screening tools for palliative care needs and for predicting 12-­month mortality.
Methods  A case note review of hepatology in-­patients, who were not peritransplant and post-­ transplant status, was conducted in one tertiary unit. Main outcomes were clinical judgement of need for SPC referral, BPST scores, SPICT attribution of caseness and 12-­month survival status. Discriminatory ability of tools was assessed using sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV) and area under the receiver operating characteristic (AUROC) curve.
Results  117 medical notes were reviewed for survival analysis, 47 of which were additionally assessed for suitability for SPC referral, using clinical judgement. SPICT (sensitivity=93\%; PPV=93\%; AUROC=0.933) and BPST (sensitivity=59\%, PPV=79\%, AUROC=0.693) demonstrated excellent and good performance, respectively, in predicting patients’ need for SPC referral. SPICT and BPST only had moderate ability at predicting death at 12 months (PPV: 54\% and 56\%, respectively).
Conclusion  SPICT and BPST show potential as screening tools for identifying patients for referral to SPC. Further work is needed to determine how to implement these tools in a clinical setting.},
	language = {en},
	number = {3},
	urldate = {2024-05-01},
	journal = {Frontline Gastroenterology},
	author = {Low, Joseph and Carroll, Catherine and Wilson, Jo and Craig, Rachel and Vadera, Shree and Cococcia, Sara and Thorburn, Douglas and Stone, Patrick and Marshall, Aileen and Vickerstaff, Victoria},
	month = may,
	year = {2022},
	pages = {211--217},
	file = {Low et al. - 2022 - Do screening tools assess palliative care needs an.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/4VYSSUTE/Low et al. - 2022 - Do screening tools assess palliative care needs an.pdf:application/pdf},
}

@article{effendy_identifying_2022,
	title = {Identifying palliative care needs of patients with non-communicable diseases in {Indonesia} using the {SPICT} tool: a descriptive cross-sectional study},
	volume = {21},
	issn = {1472-684X},
	shorttitle = {Identifying palliative care needs of patients with non-communicable diseases in {Indonesia} using the {SPICT} tool},
	url = {https://doi.org/10.1186/s12904-021-00881-5},
	doi = {10.1186/s12904-021-00881-5},
	abstract = {In Indonesia, Non-Communicable Diseases (NCD) are a contributing factor to mortality with most cases involving heart disease, cancer, chronic lung disease and diabetes. Accordingly, the identification of palliative care needs is very important as a first step in providing palliative care for these patients with NCD. However, currently there is no national standardized tool nor guidance system for identifying palliative care needs of NCD patients in Indonesia. The Supportive and Palliative Care Indicators Tool (SPICT) has been used worldwide for screening palliative care needs. This study aimed to identify palliative care needs in NCD patients using the SPICT tool.},
	language = {en},
	number = {1},
	urldate = {2024-04-30},
	journal = {BMC Palliative Care},
	author = {Effendy, Christantie and Silva, Jony Francisco Dos Santos and Padmawati, Retna Siwi},
	month = jan,
	year = {2022},
	keywords = {Palliative care, Indonesia, Non-communicable diseases, Screening, SPICT tool},
	pages = {13},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/93XV8XDA/Effendy et al. - 2022 - Identifying palliative care needs of patients with.pdf:application/pdf},
}

@article{casale_supportive_2020,
	title = {Supportive and palliative care indicators tool ({SPICT}™): content validity, feasibility and pre-test of the {Italian} version},
	volume = {19},
	issn = {1472-684X},
	shorttitle = {Supportive and palliative care indicators tool ({SPICT}™)},
	url = {https://doi.org/10.1186/s12904-020-00584-3},
	doi = {10.1186/s12904-020-00584-3},
	abstract = {Difficulties in identifying patients at risk of clinical deterioration or death represent one of the main barriers to Palliative Care (PC) development in the community. Currently, no specific Italian tools aimed at identifying patients with PC needs are available. Of the different European tools available, the SPICT™ can be used easily in any kind of setting and does not include the Surprise Question. The purpose of the study was to translate, cross-culturally adapt and pre-test the Italian version of the SPICT™.},
	language = {en},
	number = {1},
	urldate = {2024-04-30},
	journal = {BMC Palliative Care},
	author = {Casale, Giuseppe and Magnani, Caterina and Fanelli, Renato and Surdo, Laura and Goletti, Mauro and Boyd, Kirsty and D’Angelo, Daniela and Mastroianni, Chiara and Cancian, Maurizio and Colotto, Marco and Di Giacomo, Antonella and Fucito, Giuseppe and Gentili, Giorgio and Latorre, Patrizia and Aprile, Pierangelo Lora and Massaro, Michele and Pace, Andrea and Savarese, Antonella and Scarlata, Simone and Stefanelli, Maria Consiglia and Turriziani, Adriana and {the SPICT-IT™ study group}},
	month = jun,
	year = {2020},
	keywords = {Palliative care, Italian, Primary care, SPICT, Supportive care},
	pages = {79},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EGFJGIEF/Casale et al. - 2020 - Supportive and palliative care indicators tool (SP.pdf:application/pdf},
}

@article{afshar_systematic_2018,
	title = {Systematic development and adjustment of the {German} version of the {Supportive} and {Palliative} {Care} {Indicators} {Tool} ({SPICT}-{DE})},
	volume = {17},
	issn = {1472-684X},
	url = {https://doi.org/10.1186/s12904-018-0283-7},
	doi = {10.1186/s12904-018-0283-7},
	abstract = {The Supportive and Palliative Care Indicators tool (SPICT) supports the identification of patients with potential palliative care (PC) needs. An Austrian-German expert group translated SPICT into German (SPICT-DE) in 2014. The aim of this study was the systematic development, refinement, and testing of SPICT-DE for its application in primary care (general practice).},
	language = {en},
	number = {1},
	urldate = {2024-04-30},
	journal = {BMC Palliative Care},
	author = {Afshar, Kambiz and Feichtner, Angelika and Boyd, Kirsty and Murray, Scott and Jünger, Saskia and Wiese, Birgitt and Schneider, Nils and Müller-Mundt, Gabriele},
	month = feb,
	year = {2018},
	keywords = {Palliative care, General practice, Primary care, SPICT, Identification tool},
	pages = {27},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/H7V5RHWM/Afshar et al. - 2018 - Systematic development and adjustment of the Germa.pdf:application/pdf},
}

@article{bergenholtz_talking_2020,
	title = {Talking about death and dying in a hospital setting - a qualitative study of the wishes for end-of-life conversations from the perspective of patients and spouses},
	volume = {19},
	issn = {1472-684X},
	url = {https://doi.org/10.1186/s12904-020-00675-1},
	doi = {10.1186/s12904-020-00675-1},
	abstract = {End-of-life (EOL) conversations are highly important for patients living with life-threatening diseases and for their relatives. Talking about the EOL is associated with reduced costs and better quality of care in the final weeks of life. However, there is therefore a need for further clarification of the actual wishes of patients and their relatives concerning EOL conversations in an acute hospital setting.},
	number = {1},
	urldate = {2024-04-30},
	journal = {BMC Palliative Care},
	author = {Bergenholtz, Heidi and Missel, Malene and Timm, Helle},
	month = nov,
	year = {2020},
	keywords = {Communication, Palliative care, End-of-life, Hospital, Patient, Spouses},
	pages = {168},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/VUJ6754Q/Bergenholtz et al. - 2020 - Talking about death and dying in a hospital settin.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/YLTTH6DB/s12904-020-00675-1.html:text/html},
}

@misc{noauthor_recruiting_nodate,
	title = {Recruiting patients into a primary care based study of palliative care: why is it so difficult?},
	shorttitle = {Recruiting patients into a primary care based study of palliative care},
	url = {https://journals.sagepub.com/doi/epdf/10.1191/0269216304pm905oa},
	language = {en},
	urldate = {2024-04-28},
	doi = {10.1191/0269216304pm905oa},
	file = {Recruiting patients into a primary care based stud.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/MEH2BZMA/Recruiting patients into a primary care based stud.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/PNYHCWVR/0269216304pm905oa.html:text/html},
}

@article{zou_forecasting_nodate,
	title = {Forecasting {Future} {World} {Events} with {Neural} {Networks}},
	abstract = {Forecasting future world events is a challenging but valuable task. Forecasts of climate, geopolitical conflict, pandemics and economic indicators help shape policy and decision making. In these domains, the judgment of expert humans contributes to the best forecasts. Given advances in language modeling, can these forecasts be automated? To this end, we introduce Autocast, a dataset containing thousands of forecasting questions and an accompanying news corpus. Questions are taken from forecasting tournaments, ensuring high quality, real-world importance, and diversity. The news corpus is organized by date, allowing us to precisely simulate the conditions under which humans made past forecasts (avoiding leakage from the future). Motivated by the difficulty of forecasting numbers across orders of magnitude (e.g. global cases of COVID-19 in 2022), we also curate IntervalQA, a dataset of numerical questions and metrics for calibration. We test language models on our forecasting task and find that performance is far below a human expert baseline. However, performance improves with increased model size and incorporation of relevant information from the news corpus. In sum, Autocast poses a novel challenge for large language models and improved performance could bring large practical benefits.},
	language = {en},
	author = {Zou, Andy and Xiao, Tristan and Jia, Ryan and Kwon, Joe and Mazeika, Mantas and Li, Richard and Song, Dawn and Steinhardt, Jacob and Evans, Owain and Hendrycks, Dan},
	file = {Zou et al. - Forecasting Future World Events with Neural Networ.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/QQMA968V/Zou et al. - Forecasting Future World Events with Neural Networ.pdf:application/pdf},
}

@article{ellis_human-like_nodate,
	title = {Human-like {Few}-{Shot} {Learning} via {Bayesian} {Reasoning} over {Natural} {Language}},
	abstract = {A core tension in models of concept learning is that the model must carefully balance the tractability of inference against the expressivity of the hypothesis class. Humans, however, can efficiently learn a broad range of concepts. We introduce a model of inductive learning that seeks to be human-like in that sense. It implements a Bayesian reasoning process where a language model first proposes candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood. By estimating the prior from human data, we can predict human judgments on learning problems involving numbers and sets, spanning concepts that are generative, discriminative, propositional, and higher-order.},
	language = {en},
	author = {Ellis, Kevin},
	file = {Ellis - Human-like Few-Shot Learning via Bayesian Reasonin.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/LEWE6C4B/Ellis - Human-like Few-Shot Learning via Bayesian Reasonin.pdf:application/pdf},
}

@article{scott_modelling_2023-1,
	title = {Modelling clinical narrative as computable knowledge: {The} {NICE} computable implementation guidance project},
	volume = {7},
	copyright = {© 2023 The Authors. Learning Health Systems published by Wiley Periodicals LLC on behalf of University of Michigan.},
	issn = {2379-6146},
	shorttitle = {Modelling clinical narrative as computable knowledge},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/lrh2.10394},
	doi = {10.1002/lrh2.10394},
	abstract = {Introduction Translating narrative clinical guidelines to computable knowledge is a long-standing challenge that has seen a diverse range of approaches. The UK National Institute for Health and Care Excellence (NICE) Content Advisory Board (CAB) aims ultimately to (1) guide clinical decision support and other software developers to increase traceability, fidelity and consistency in supporting clinical use of NICE recommendations, (2) guide local practice audit and intervention to reduce unwarranted variation, (3) provide feedback to NICE on how future recommendations should be developed. Objectives The first phase of work was to explore a range of technical approaches to transition NICE toward the production of natively digital content. Methods Following an initial ‘collaborathon’ in November 2022, the NICE Computable Implementation Guidance project (NCIG) was established. We held a series of workstream calls approximately fortnightly, focusing on (1) user stories and trigger events, (2) information model and definitions, (3) horizon-scanning and output format. A second collaborathon was held in March 2023 to consolidate progress across the workstreams and agree residual actions to complete. Results While we initially focussed on technical implementation standards, we decided that an intermediate logical model was a more achievable first step in the journey from narrative to fully computable representation. NCIG adopted the WHO Digital Adaptation Kit (DAK) as a technology-agnostic method to model user scenarios, personae, processes and workflow, core data elements and decision-support logic. Further work will address indicators, such as prescribing compliance, and implementation in document templates for primary care patient record systems. Conclusions The project has shown that the WHO DAK, with some modification, is a promising approach to build technology-neutral logical specifications of NICE recommendations. Implementation of concurrent computable modelling by multidisciplinary teams during guideline development poses methodological and cultural questions that are complex but tractable given suitable will and leadership.},
	language = {en},
	number = {4},
	urldate = {2024-04-25},
	journal = {Learning Health Systems},
	author = {Scott, Philip and Heigl, Michaela and McCay, Charles and Shepperdson, Polly and Lima-Walton, Elia and Andrikopoulou, Elisavet and Brunnhuber, Klara and Cornelius, Gary and Faulding, Susan and McAlister, Ben and Rowark, Shaun and South, Matthew and Thomas, Mark R. and Whatling, Justin and Williams, John and Wyatt, Jeremy C. and Greaves, Felix},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/lrh2.10394},
	keywords = {clinical decision support systems, computable knowledge, decision modelling, practice guideline},
	pages = {e10394},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/V5XMYDZI/Scott et al. - 2023 - Modelling clinical narrative as computable knowled.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/AVADLQC3/lrh2.html:text/html},
}

@inproceedings{ng_modelling_2023,
	address = {Dubrovnik, Croatia},
	title = {Modelling {Temporal} {Document} {Sequences} for {Clinical} {ICD} {Coding}},
	url = {https://aclanthology.org/2023.eacl-main.120},
	doi = {10.18653/v1/2023.eacl-main.120},
	abstract = {Past studies on the ICD coding problem focus on predicting clinical codes primarily based on the discharge summary. This covers only a small fraction of the notes generated during each hospital stay and leaves potential for improving performance by analysing all the available clinical notes. We propose a hierarchical transformer architecture that uses text across the entire sequence of clinical notes in each hospital stay for ICD coding, and incorporates embeddings for text metadata such as their position, time, and type of note. While using all clinical notes increases the quantity of data substantially, superconvergence can be used to reduce training costs. We evaluate the model on the MIMIC-III dataset. Our model exceeds the prior state-of-the-art when using only discharge summaries as input, and achieves further performance improvements when all clinical notes are used as input.},
	urldate = {2024-04-24},
	booktitle = {Proceedings of the 17th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Ng, Boon Liang Clarence and Santos, Diogo and Rei, Marek},
	editor = {Vlachos, Andreas and Augenstein, Isabelle},
	month = may,
	year = {2023},
	pages = {1640--1649},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MPNA65YE/Ng et al. - 2023 - Modelling Temporal Document Sequences for Clinical.pdf:application/pdf},
}

@article{limsomwong_identifying_2024,
	title = {Identifying cancer patients who received palliative care using the {SPICT}-{LIS} in medical records: a rule-based algorithm and text-mining technique},
	volume = {23},
	issn = {1472-684X},
	shorttitle = {Identifying cancer patients who received palliative care using the {SPICT}-{LIS} in medical records},
	url = {https://doi.org/10.1186/s12904-024-01419-1},
	doi = {10.1186/s12904-024-01419-1},
	abstract = {Due to limited numbers of palliative care specialists and/or resources, accessing palliative care remains limited in many low and middle-income countries. Data science methods, such as rule-based algorithms and text mining, have potential to improve palliative care by facilitating analysis of electronic healthcare records. This study aimed to develop and evaluate a rule-based algorithm for identifying cancer patients who may benefit from palliative care based on the Thai version of the Supportive and Palliative Care Indicators for a Low-Income Setting (SPICT-LIS) criteria.},
	number = {1},
	urldate = {2024-04-22},
	journal = {BMC Palliative Care},
	author = {Limsomwong, Pawita and Ingviya, Thammasin and Fumaneeshoat, Orapan},
	month = apr,
	year = {2024},
	keywords = {Palliative care, cancer patients, Rule-based algorithm, SPICT-LIS criteria, Text-mining techniques},
	pages = {83},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/53GJ3U2E/Limsomwong et al. - 2024 - Identifying cancer patients who received palliativ.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/EQL2RBCE/s12904-024-01419-1.html:text/html},
}

@article{bourmorck_spict_2023,
	title = {{SPICT} as a predictive tool for risk of 1-year health degradation and death in older patients admitted to the emergency department: a bicentric cohort study in {Belgium}},
	volume = {22},
	issn = {1472-684X},
	shorttitle = {{SPICT} as a predictive tool for risk of 1-year health degradation and death in older patients admitted to the emergency department},
	url = {https://doi.org/10.1186/s12904-023-01201-9},
	doi = {10.1186/s12904-023-01201-9},
	abstract = {Older patients are increasingly showing multi-comorbidities, including advanced chronic diseases. When admitted to the emergency department (ED), the decision to pursue life-prolonging treatments or to initiate a palliative care approach is a challenge for clinicians. We test for the first time the diagnostic accuracy of the Supportive and Palliative Care Indicators Tool (SPICT) in the ED to identify older patients at risk of deteriorating and dying, and timely address palliative care needs.},
	language = {en},
	number = {1},
	urldate = {2024-04-22},
	journal = {BMC Palliative Care},
	author = {Bourmorck, Delphine and de Saint-Hubert, Marie and Desmedt, Marianne and Piers, Ruth and Flament, Julien and De Brauwer, Isabelle},
	month = jun,
	year = {2023},
	keywords = {Prognosis, Palliative Care, SPICT, Emergency Department, Older patients},
	pages = {79},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/X4DI8MLU/Bourmorck et al. - 2023 - SPICT as a predictive tool for risk of 1-year heal.pdf:application/pdf},
}

@article{minne_prognostic_2011,
	title = {Prognostic models for predicting mortality in elderly {ICU} patients: a systematic review},
	volume = {37},
	issn = {1432-1238},
	shorttitle = {Prognostic models for predicting mortality in elderly {ICU} patients},
	url = {https://doi.org/10.1007/s00134-011-2265-6},
	doi = {10.1007/s00134-011-2265-6},
	abstract = {To systematically review prognostic research literature on development and/or validation of mortality predictive models in elderly patients.},
	language = {en},
	number = {8},
	urldate = {2024-04-13},
	journal = {Intensive Care Medicine},
	author = {Minne, Lilian and Ludikhuize, Jeroen and de Jonge, Evert and de Rooij, Sophia and Abu-Hanna, Ameen},
	month = aug,
	year = {2011},
	keywords = {Clinical credibility, Elderly, Intensive care, Predictive performance, Prognostic models, Validity},
	pages = {1258--1268},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CPPD69JC/Minne et al. - 2011 - Prognostic models for predicting mortality in elde.pdf:application/pdf},
}

@inproceedings{rongali_dont_2020,
	address = {Taipei Taiwan},
	title = {Don’t {Parse}, {Generate}! {A} {Sequence} to {Sequence} {Architecture} for {Task}-{Oriented} {Semantic} {Parsing}},
	isbn = {978-1-4503-7023-3},
	url = {https://dl.acm.org/doi/10.1145/3366423.3380064},
	doi = {10.1145/3366423.3380064},
	language = {en},
	urldate = {2024-04-11},
	booktitle = {Proceedings of {The} {Web} {Conference} 2020},
	publisher = {ACM},
	author = {Rongali, Subendhu and Soldaini, Luca and Monti, Emilio and Hamza, Wael},
	month = apr,
	year = {2020},
	pages = {2962--2968},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/7BZK9E8M/Rongali et al. - 2020 - Don’t Parse, Generate! A Sequence to Sequence Arch.pdf:application/pdf},
}

@article{yao_interactive_2019,
	title = {Interactive {Semantic} {Parsing} for {If}-{Then} {Recipes} via {Hierarchical} {Reinforcement} {Learning}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4101},
	doi = {10.1609/aaai.v33i01.33012547},
	abstract = {Given a text description, most existing semantic parsers synthesize a program in one shot. However, it is quite challenging to produce a correct program solely based on the description, which in reality is often ambiguous or incomplete. In this paper, we investigate interactive semantic parsing, where the agent can ask the user clarification questions to resolve ambiguities via a multi-turn dialogue, on an important type of programs called “If-Then recipes.” We develop a hierarchical reinforcement learning (HRL) based agent that significantly improves the parsing performance with minimal questions to the user. Results under both simulation and human evaluation show that our agent substantially outperforms non-interactive semantic parsers and rule-based agents.1},
	language = {en},
	number = {01},
	urldate = {2024-04-11},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Yao, Ziyu and Li, Xiujun and Gao, Jianfeng and Sadler, Brian and Sun, Huan},
	month = jul,
	year = {2019},
	note = {Number: 01},
	pages = {2547--2554},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/A2C9AKX8/Yao et al. - 2019 - Interactive Semantic Parsing for If-Then Recipes v.pdf:application/pdf},
}

@misc{zhou_least--most_2023,
	title = {Least-to-{Most} {Prompting} {Enables} {Complex} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2205.10625},
	doi = {10.48550/arXiv.2205.10625},
	abstract = {Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99\% using just 14 exemplars, compared to only 16\% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.},
	urldate = {2024-04-08},
	publisher = {arXiv},
	author = {Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed},
	month = apr,
	year = {2023},
	note = {arXiv:2205.10625 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/3U4RG265/Zhou et al. - 2023 - Least-to-Most Prompting Enables Complex Reasoning .pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DVNWAESE/2205.html:text/html},
}

@article{pourreza_din-sql_nodate,
	title = {{DIN}-{SQL}: {Decomposed} {In}-{Context} {Learning} of {Text}-to-{SQL} with {Self}-{Correction}},
	abstract = {There is currently a signiﬁcant gap between the performance of ﬁne-tuned models and prompting approaches using Large Language Models (LLMs) on the challenging task of text-to-SQL, as evaluated on datasets such as Spider. To improve the performance of LLMs in the reasoning process, we study how decomposing the task into smaller sub-tasks can be effective. In particular, we show that breaking down the generation problem into sub-problems and feeding the solutions of those sub-problems into LLMs can be an effective approach for signiﬁcantly improving their performance. Our experiments with three LLMs show that this approach consistently improves their simple few-shot performance by roughly 10\%, pushing the accuracy of LLMs towards SOTA or surpassing it. On the holdout test set of Spider, the SOTA, in terms of execution accuracy, was 79.9 and the new SOTA at the time of this writing using our approach is 85.3. Our approach with in-context learning beats many heavily ﬁne-tuned models by at least 5\%. Additionally, when evaluated on the BIRD benchmark, our approach achieved an execution accuracy of 55.9\%, setting a new SOTA on its holdout test set.},
	language = {en},
	author = {Pourreza, Mohammadreza and Raﬁei, Davood},
	file = {Pourreza and Raﬁei - DIN-SQL Decomposed In-Context Learning of Text-to.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/4IJN69EH/Pourreza and Raﬁei - DIN-SQL Decomposed In-Context Learning of Text-to.pdf:application/pdf},
}

@misc{li_pet-sql_2024,
	title = {{PET}-{SQL}: {A} {Prompt}-enhanced {Two}-stage {Text}-to-{SQL} {Framework} with {Cross}-consistency},
	shorttitle = {{PET}-{SQL}},
	url = {http://arxiv.org/abs/2403.09732},
	abstract = {Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large language models (LLM) on in-context learning, achieving significant results. Nevertheless, they face challenges when dealing with verbose database information and complex user intentions. This paper presents a two-stage framework to enhance the performance of current LLM-based natural language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information. In the second stage, with the linked schema, we simplify the prompt's schema information and instruct the LLM to produce the final SQL. Finally, as the post-refinement module, we propose using cross-consistency across different LLMs rather than self-consistency within a particular LLM. Our methods achieve new SOTA results on the Spider benchmark, with an execution accuracy of 87.6\%.},
	urldate = {2024-04-08},
	publisher = {arXiv},
	author = {Li, Zhishuai and Wang, Xiang and Zhao, Jingjing and Yang, Sun and Du, Guoqing and Hu, Xiaoru and Zhang, Bin and Ye, Yuxiao and Li, Ziyue and Zhao, Rui and Mao, Hangyu},
	month = mar,
	year = {2024},
	note = {arXiv:2403.09732 [cs]
version: 3},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/IF5CAEXG/2403.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/4N52QV6A/Li et al. - 2024 - PET-SQL A Prompt-enhanced Two-stage Text-to-SQL F.pdf:application/pdf},
}

@article{avati_improving_2018,
	title = {Improving palliative care with deep learning},
	volume = {18},
	issn = {1472-6947},
	url = {https://doi.org/10.1186/s12911-018-0677-8},
	doi = {10.1186/s12911-018-0677-8},
	abstract = {Access to palliative care is a key quality metric which most healthcare organizations strive to improve. The primary challenges to increasing palliative care access are a combination of physicians over-estimating patient prognoses, and a shortage of palliative staff in general. This, in combination with treatment inertia can result in a mismatch between patient wishes, and their actual care towards the end of life.},
	language = {en},
	number = {4},
	urldate = {2024-04-07},
	journal = {BMC Medical Informatics and Decision Making},
	author = {Avati, Anand and Jung, Kenneth and Harman, Stephanie and Downing, Lance and Ng, Andrew and Shah, Nigam H.},
	month = dec,
	year = {2018},
	keywords = {Deep learning, Electronic health records, Palliative care, Interpretation},
	pages = {122},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/H7JZDTVW/Avati et al. - 2018 - Improving palliative care with deep learning.pdf:application/pdf},
}

@article{storick_improving_2019,
	title = {Improving palliative care with machine learning and routine data: a rapid review},
	volume = {2},
	shorttitle = {Improving palliative care with machine learning and routine data},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6973530/},
	doi = {10.12688/hrbopenres.12923.2},
	abstract = {Introduction: Improving palliative care is a priority worldwide as this population experiences poor outcomes and accounts disproportionately for costs. In clinical practice, physician judgement is the core method of identifying palliative care needs ...},
	language = {en},
	urldate = {2024-04-07},
	journal = {HRB Open Research},
	author = {Storick, Virginia and O’Herlihy, Aoife and Abdelhafeez, Sarah and Ahmed, Rakesh and May, Peter},
	year = {2019},
	pmid = {32002512},
	note = {Publisher: Health Research Board Ireland},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/7TSUT8JT/Storick et al. - 2019 - Improving palliative care with machine learning an.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/F25E5Q4A/PMC6973530.html:text/html},
}

@article{sanchez_causal_2022,
	title = {Causal machine learning for healthcare and precision medicine},
	volume = {9},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.220638},
	doi = {10.1098/rsos.220638},
	abstract = {Causal machine learning (CML) has experienced increasing popularity in healthcare. Beyond the inherent capabilities of adding domain knowledge into learning systems, CML provides a complete toolset for investigating how a system would react to an intervention (e.g. outcome given a treatment). Quantifying effects of interventions allows actionable decisions to be made while maintaining robustness in the presence of confounders. Here, we explore how causal inference can be incorporated into different aspects of clinical decision support systems by using recent advances in machine learning. Throughout this paper, we use Alzheimer’s disease to create examples for illustrating how CML can be advantageous in clinical scenarios. Furthermore, we discuss important challenges present in healthcare applications such as processing high-dimensional and unstructured data, generalization to out-of-distribution samples and temporal relationships, that despite the great effort from the research community remain to be solved. Finally, we review lines of research within causal representation learning, causal discovery and causal reasoning which offer the potential towards addressing the aforementioned challenges.},
	number = {8},
	urldate = {2024-04-07},
	journal = {Royal Society Open Science},
	author = {Sanchez, Pedro and Voisey, Jeremy P. and Xia, Tian and Watson, Hannah I. and O’Neil, Alison Q. and Tsaftaris, Sotirios A.},
	month = aug,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {causal machine learning, causal representation learning, precision medicine},
	pages = {220638},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/L4UJRXPU/Sanchez et al. - 2022 - Causal machine learning for healthcare and precisi.pdf:application/pdf},
}

@article{christakis_extent_2000,
	title = {Extent and determinants of error in doctors' prognoses in terminally ill patients: prospective cohort study {Commentary}: {Why} do doctors overestimate? {Commentary}: {Prognoses} should be based on proved indices not intuition},
	volume = {320},
	issn = {09598138},
	shorttitle = {Extent and determinants of error in doctors' prognoses in terminally ill patients},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.320.7233.469},
	doi = {10.1136/bmj.320.7233.469},
	abstract = {Objective To describe doctors’ prognostic accuracy in terminally ill patients and to evaluate the determinants of that accuracy. Design Prospective cohort study. Setting Five outpatient hospice programmes in Chicago. Participants 343 doctors provided survival estimates for 468 terminally ill patients at the time of hospice referral. Main outcome measures Patients’ estimated and actual survival.
Results Median survival was 24 days. Only 20\% (92/468) of predictions were accurate (within 33\% of actual survival); 63\% (295/468) were overoptimistic and 17\% (81/468) were overpessimistic. Overall, doctors overestimated survival by a factor of 5.3. Few patient or doctor characteristics were associated with prognostic accuracy. Male patients were 58\% less likely to have overpessimistic predictions. Non-oncology medical specialists were 326\% more likely than general internists to make overpessimistic predictions. Doctors in the upper quartile of practice experience were the most accurate. As duration of doctor-patient relationship increased and time since last contact decreased, prognostic accuracy decreased.
Conclusion Doctors are inaccurate in their prognoses for terminally ill patients and the error is systematically optimistic. The inaccuracy is, in general, not restricted to certain kinds of doctors or patients. These phenomena may be adversely affecting the quality of care given to patients near the end of life.},
	language = {en},
	number = {7233},
	urldate = {2024-04-05},
	journal = {BMJ},
	author = {Christakis, N. A},
	month = feb,
	year = {2000},
	pages = {469--473},
	file = {Christakis - 2000 - Extent and determinants of error in doctors' progn.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/RS6TYD5S/Christakis - 2000 - Extent and determinants of error in doctors' progn.pdf:application/pdf},
}

@article{thoonsen_early_2011,
	title = {Early identification of and proactive palliative care for patients in general practice, incentive and methods of a randomized controlled trial},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/2.0},
	issn = {1471-2296},
	url = {https://bmcfampract.biomedcentral.com/articles/10.1186/1471-2296-12-123},
	doi = {10.1186/1471-2296-12-123},
	language = {en},
	number = {1},
	urldate = {2024-04-05},
	journal = {BMC Family Practice},
	author = {Thoonsen, Bregje and Groot, Marieke and Engels, Yvonne and Prins, Judith and Verhagen, Stans and Galesloot, Cilia and Van Weel, Chris and Vissers, Kris},
	month = dec,
	year = {2011},
	pages = {123},
	file = {Thoonsen et al. - 2011 - Early identification of and proactive palliative c.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/BMQRA4V5/Thoonsen et al. - 2011 - Early identification of and proactive palliative c.pdf:application/pdf},
}

@misc{neyman_algorithmic_2024,
	title = {Algorithmic {Bayesian} {Epistemology}},
	url = {http://arxiv.org/abs/2403.07949},
	abstract = {One aspect of the algorithmic lens in theoretical computer science is a view on other scientific disciplines that focuses on satisfactory solutions that adhere to real-world constraints, as opposed to solutions that would be optimal ignoring such constraints. The algorithmic lens has provided a unique and important perspective on many academic fields, including molecular biology, ecology, neuroscience, quantum physics, economics, and social science. This thesis applies the algorithmic lens to Bayesian epistemology. Traditional Bayesian epistemology provides a comprehensive framework for how an individual's beliefs should evolve upon receiving new information. However, these methods typically assume an exhaustive model of such information, including the correlation structure between different pieces of evidence. In reality, individuals might lack such an exhaustive model, while still needing to form beliefs. Beyond such informational constraints, an individual may be bounded by limited computation, or by limited communication with agents that have access to information, or by the strategic behavior of such agents. Even when these restrictions prevent the formation of a *perfectly* accurate belief, arriving at a *reasonably* accurate belief remains crucial. In this thesis, we establish fundamental possibility and impossibility results about belief formation under a variety of restrictions, and lay the groundwork for further exploration.},
	urldate = {2024-04-05},
	publisher = {arXiv},
	author = {Neyman, Eric},
	month = mar,
	year = {2024},
	note = {arXiv:2403.07949 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Science and Game Theory},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/RSZ7EE7L/2403.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/59W2TY8D/Neyman - 2024 - Algorithmic Bayesian Epistemology.pdf:application/pdf},
}

@article{walsh_what_2015,
	title = {What {Diagnostic} {Tools} {Exist} for the {Early} {Identification} of {Palliative} {Care} {Patients} in {General} {Practice}? {A} systematic {Review}},
	volume = {31},
	issn = {0825-8597},
	shorttitle = {What {Diagnostic} {Tools} {Exist} for the {Early} {Identification} of {Palliative} {Care} {Patients} in {General} {Practice}?},
	url = {https://doi.org/10.1177/082585971503100208},
	doi = {10.1177/082585971503100208},
	number = {2},
	urldate = {2024-04-05},
	journal = {Journal of Palliative Care},
	author = {Walsh, Robert I. and Mitchell, Geoffrey and Francis, Lily and van Driel, Mieke L.},
	month = jun,
	year = {2015},
	note = {Publisher: SAGE Publications Inc},
	pages = {118--123},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/YYEQAB4H/Walsh et al. - 2015 - What Diagnostic Tools Exist for the Early Identifi.pdf:application/pdf},
}

@article{highet_development_2013,
	title = {Development and evaluation of the {Supportive} and {Palliative} {Care} {Indicators} {Tool} ({SPICT}): a mixed-methods study},
	volume = {4},
	shorttitle = {Development and evaluation of the {Supportive} and {Palliative} {Care} {Indicators} {Tool} ({SPICT})},
	doi = {10.1136/bmjspcare-2013-000488},
	abstract = {To refine and evaluate a practical, clinical tool to help multidisciplinary teams in the UK and internationally, to identify patients at risk of deteriorating and dying in all care settings.
We used a participatory research approach to refine the 2010 Supportive and Palliative Care Indicators Tool (SPICT) and evaluate its use in clinical practice. We conducted an ongoing peer review process for 18 months via an open access webpage, and engaged over 30 clinicians from the UK and internationally in developing an effective tool. Secondly, we carried out a prospective case-finding study in an acute hospital in SE Scotland. Four multidisciplinary teams identified 130 patients with advanced kidney, liver, cardiac or lung disease following an unplanned hospital admission.
The SPICT was refined and updated to consist of readily identifiable, general indicators relevant to patients with any advanced illness, and disease-specific indicators for common advanced conditions. Hospital clinicians used the SPICT to identify patients at risk of deteriorating and dying. Patients who died had significantly more unplanned admissions, persistent symptoms and increased care needs. By 12 months, 62 (48\%) of the identified patients had died. 69\% of them died in hospital, having spent 22\% of their last 6 months there.
The SPICT can support clinical judgment by multidisciplinary teams when identifying patients at risk of deteriorating and dying. It helped identify patients with multiple unmet needs who would benefit from earlier, holistic needs assessment, a review of care goals, and anticipatory care planning.},
	journal = {BMJ supportive \& palliative care},
	author = {Highet, Gill and Crawford, Debbie and Murray, Scott and Boyd, Kirsty},
	month = jul,
	year = {2013},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/VVXIKFQD/Highet et al. - 2013 - Development and evaluation of the Supportive and P.pdf:application/pdf;SPICT-4ALL-2023.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/LR6F8R6U/SPICT-4ALL-2023.pdf:application/pdf;SPICT-2022.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/7QX2DWAQ/SPICT-2022.pdf:application/pdf;SPICT-LIS-2021.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/865JNAY9/SPICT-LIS-2021.pdf:application/pdf;SPICT.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/N28MNZAF/SPICT.pdf:application/pdf;SPICT.png:/home/extasia/snap/zotero-snap/common/Zotero/storage/PZ4N67UC/SPICT.png:image/png;Using-SPICT-Nov-2023.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/F9HCR2MP/Using-SPICT-Nov-2023.pdf:application/pdf},
}

@article{mudge_risk_2018,
	title = {Risk of 12-month mortality among hospital inpatients using the surprise question and {SPICT} criteria: a prospective study},
	volume = {8},
	copyright = {© Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2018. All rights reserved. No commercial use is permitted unless otherwise expressly granted.},
	issn = {2045-435X, 2045-4368},
	shorttitle = {Risk of 12-month mortality among hospital inpatients using the surprise question and {SPICT} criteria},
	url = {https://spcare.bmj.com/content/8/2/213},
	doi = {10.1136/bmjspcare-2017-001441},
	abstract = {Objectives People with serious life-limiting disease benefit from advance care planning, but require active identification. This study applied the Gold Standards Framework Proactive Identification Guidance (GSF-PIG) to a general hospital population to describe high-risk patients and explore prognostic performance for 12-month mortality.
Methods Prospective cohort study conducted in a metropolitan teaching hospital in Australia. Hospital inpatients on a single day aged 18 years and older were eligible, excluding maternity and neonatal, mental health and day treatment patients. Data sources included medical record and structured questions for medical and nursing staff. High-risk was predefined as positive response to the surprise question (SQ) plus two or more SPICT indicators of general deterioration. Descriptive variables included demographics, frailty and functional measures, treating team, advance care planning documentation and hospital utilisation. Primary outcome for prognostic performance was 12-month mortality.
Results We identified 540 eligible inpatients on the study day and 513 had complete data (mean age 60, 54\% male, 30\% living alone, 19\% elective admissions). Of these, 191 (37\%) were high-risk; they were older, frailer, more dependent and had been in hospital longer than low-risk participants. Within 12 months, 92 participants (18\%) died (72/191(38\%) high-risk versus 20/322(6\%) low-risk, P{\textless}0.001), providing sensitivity 78\%, specificity 72\%, positive predictive value 38\% and negative predictive value 94\%. SQ alone provided higher sensitivity, adding advanced disease indicators improved specificity.
Conclusions The GSF-PIG approach identified a large minority of hospital inpatients who might benefit from advance care planning. Future studies are needed to investigate the feasibility, cost and impact of screening in hospitals.},
	language = {en},
	number = {2},
	urldate = {2024-04-05},
	journal = {BMJ Supportive \& Palliative Care},
	author = {Mudge, Alison M. and Douglas, Carol and Sansome, Xanthe and Tresillian, Michael and Murray, Stephen and Finnigan, Simon and Blaber, Cheryl Ruth},
	month = jun,
	year = {2018},
	pmid = {29500239},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research},
	keywords = {advance care planning, death, decision support techniques, hospitals, prognosis},
	pages = {213--220},
	file = {Mudge et al. - 2018 - Risk of 12-month mortality among hospital inpatien.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/GLMTJJUL/Mudge et al. - 2018 - Risk of 12-month mortality among hospital inpatien.pdf:application/pdf},
}

@article{raubenheimer_utility_2019,
	title = {The utility of a shortened palliative care screening tool to predict death within 12 months – a prospective observational study in two south {African} hospitals with a high {HIV} burden},
	volume = {18},
	issn = {1472-684X},
	url = {https://doi.org/10.1186/s12904-019-0487-5},
	doi = {10.1186/s12904-019-0487-5},
	abstract = {Timely identification of people who are at risk of dying is an important first component of end-of-life care. Clinicians often fail to identify such patients, thus trigger tools have been developed to assist in this process. We aimed to evaluate the performance of a identification tool (based on the Gold Standards Framework Prognostic Indicator Guidance) to predict death at 12 months in a population of hospitalised patients in South Africa.},
	language = {en},
	number = {1},
	urldate = {2024-04-05},
	journal = {BMC Palliative Care},
	author = {Raubenheimer, Peter J. and Day, Cascia and Abdullah, Faried and Manning, Katherine and Cupido, Clint and Peter, Jonny},
	month = nov,
	year = {2019},
	keywords = {Prognosis, Palliative care, Clinical decision-making, Hospitilization},
	pages = {101},
	file = {12904_2019_487_MOESM1_ESM.docx:/home/extasia/snap/zotero-snap/common/Zotero/storage/5RLL7LRC/12904_2019_487_MOESM1_ESM.docx:application/vnd.openxmlformats-officedocument.wordprocessingml.document;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KUJLA8BJ/Raubenheimer et al. - 2019 - The utility of a shortened palliative care screeni.pdf:application/pdf},
}

@inproceedings{choi_multi-layer_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {Multi-layer {Representation} {Learning} for {Medical} {Concepts}},
	isbn = {978-1-4503-4232-2},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939823},
	doi = {10.1145/2939672.2939823},
	abstract = {Proper representations of medical concepts such as diagnosis, medication, procedure codes and visits from Electronic Health Records (EHR) has broad applications in healthcare analytics. Patient EHR data consists of a sequence of visits over time, where each visit includes multiple medical concepts, e.g., diagnosis, procedure, and medication codes. This hierarchical structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within a visit. In this work, we propose Med2Vec, which not only learns the representations for both medical codes and visits from large EHR datasets with over million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts. In the experiments, Med2Vec shows significant improvement in prediction accuracy in clinical applications compared to baselines such as Skip-gram, GloVe, and stacked autoencoder, while providing clinically meaningful interpretation.},
	urldate = {2024-04-04},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Choi, Edward and Bahadori, Mohammad Taha and Searles, Elizabeth and Coffey, Catherine and Thompson, Michael and Bost, James and Tejedor-Sojo, Javier and Sun, Jimeng},
	month = aug,
	year = {2016},
	keywords = {healthcare analytics, medical concepts, neural networks, representation learning},
	pages = {1495--1504},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/5HM55SKI/Choi et al. - 2016 - Multi-layer Representation Learning for Medical Co.pdf:application/pdf},
}

@inproceedings{ma_dipole_2017,
	address = {New York, NY, USA},
	series = {{KDD} '17},
	title = {Dipole: {Diagnosis} {Prediction} in {Healthcare} via {Attention}-based {Bidirectional} {Recurrent} {Neural} {Networks}},
	isbn = {978-1-4503-4887-4},
	shorttitle = {Dipole},
	url = {https://dl.acm.org/doi/10.1145/3097983.3098088},
	doi = {10.1145/3097983.3098088},
	abstract = {Predicting the future health information of patients from the historical Electronic Health Records (EHR) is a core research task in the development of personalized healthcare. Patient EHR data consist of sequences of visits over time, where each visit contains multiple medical codes, including diagnosis, medication, and procedure codes. The most important challenges for this task are to model the temporality and high dimensionality of sequential EHR data and to interpret the prediction results. Existing work solves this problem by employing recurrent neural networks (RNNs) to model EHR data and utilizing simple attention mechanism to interpret the results. However, RNN-based approaches suffer from the problem that the performance of RNNs drops when the length of sequences is large, and the relationships between subsequent visits are ignored by current RNN-based approaches. To address these issues, we propose Dipole, an end-to-end, simple and robust model for predicting patients' future health information. Dipole employs bidirectional recurrent neural networks to remember all the information of both the past visits and the future visits, and it introduces three attention mechanisms to measure the relationships of different visits for the prediction. With the attention mechanisms, Dipole can interpret the prediction results effectively. Dipole also allows us to interpret the learned medical code representations which are confirmed positively by medical experts. Experimental results on two real world EHR datasets show that the proposed Dipole can significantly improve the prediction accuracy compared with the state-of-the-art diagnosis prediction approaches and provide clinically meaningful interpretation.},
	urldate = {2024-04-04},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ma, Fenglong and Chitta, Radha and Zhou, Jing and You, Quanzeng and Sun, Tong and Gao, Jing},
	month = aug,
	year = {2017},
	keywords = {attention mechanism, bidirectional recurrent neural networks, healthcare informatics},
	pages = {1903--1911},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/QQRU7JLU/Ma et al. - 2017 - Dipole Diagnosis Prediction in Healthcare via Att.pdf:application/pdf},
}

@misc{von_oswald_transformers_2023,
	title = {Transformers learn in-context by gradient descent},
	url = {http://arxiv.org/abs/2212.07677},
	doi = {10.48550/arXiv.2212.07677},
	abstract = {At present, the mechanisms of in-context learning in Transformers are not well understood and remain mostly an intuition. In this paper, we suggest that training Transformers on auto-regressive objectives is closely related to gradient-based meta-learning formulations. We start by providing a simple weight construction that shows the equivalence of data transformations induced by 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a regression loss. Motivated by that construction, we show empirically that when training self-attention-only Transformers on simple regression tasks either the models learned by GD and Transformers show great similarity or, remarkably, the weights found by optimization match the construction. Thus we show how trained Transformers become mesa-optimizers i.e. learn models by gradient descent in their forward pass. This allows us, at least in the domain of regression problems, to mechanistically understand the inner workings of in-context learning in optimized Transformers. Building on this insight, we furthermore identify how Transformers surpass the performance of plain gradient descent by learning an iterative curvature correction and learn linear models on deep data representations to solve non-linear regression tasks. Finally, we discuss intriguing parallels to a mechanism identified to be crucial for in-context learning termed induction-head (Olsson et al., 2022) and show how it could be understood as a specific case of in-context learning by gradient descent learning within Transformers. Code to reproduce the experiments can be found at https://github.com/google-research/self-organising-systems/tree/master/transformers\_learn\_icl\_by\_gd .},
	urldate = {2024-04-02},
	publisher = {arXiv},
	author = {von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, João and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
	month = may,
	year = {2023},
	note = {arXiv:2212.07677 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/XQ54C7EJ/von Oswald et al. - 2023 - Transformers learn in-context by gradient descent.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/RG6DBNEH/2212.html:text/html},
}

@article{yao_tree_nodate,
	title = {Tree of {Thoughts}: {Deliberate} {Problem} {Solving} with {Large} {Language} {Models}},
	abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, “Tree of Thoughts” (ToT), which generalizes over the popular “Chain of Thought” approach to prompting language models, and enables exploration over coherent units of text (“thoughts”) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/princeton-nlp/tree-of-thought-llm.},
	language = {en},
	author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
	file = {Yao et al. - Tree of Thoughts Deliberate Problem Solving with .pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/DI7P6HH6/Yao et al. - Tree of Thoughts Deliberate Problem Solving with .pdf:application/pdf},
}

@inproceedings{cheng_mdace_2023,
	address = {Toronto, Canada},
	title = {{MDACE}: {MIMIC} {Documents} {Annotated} with {Code} {Evidence}},
	shorttitle = {{MDACE}},
	url = {https://aclanthology.org/2023.acl-long.416},
	doi = {10.18653/v1/2023.acl-long.416},
	abstract = {We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset – annotated by professional medical coders – consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evidence spans. We implemented several evidence extraction methods based on the EffectiveCAN model (Liu et al., 2021) to establish baseline performance on this dataset. MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.},
	urldate = {2024-04-01},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Cheng, Hua and Jafari, Rana and Russell, April and Klopfer, Russell and Lu, Edmond and Striner, Benjamin and Gormley, Matthew},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	month = jul,
	year = {2023},
	pages = {7534--7550},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/DBLJZR9U/Cheng et al. - 2023 - MDACE MIMIC Documents Annotated with Code Evidenc.pdf:application/pdf},
}

@misc{yuan_code_2022,
	title = {Code {Synonyms} {Do} {Matter}: {Multiple} {Synonyms} {Matching} {Network} for {Automatic} {ICD} {Coding}},
	shorttitle = {Code {Synonyms} {Do} {Matter}},
	url = {http://arxiv.org/abs/2203.01515},
	doi = {10.48550/arXiv.2203.01515},
	abstract = {Automatic ICD coding is defined as assigning disease codes to electronic medical records (EMRs). Existing methods usually apply label attention with code representations to match related text snippets. Unlike these works that model the label with the code hierarchy or description, we argue that the code synonyms can provide more comprehensive knowledge based on the observation that the code expressions in EMRs vary from their descriptions in ICD. By aligning codes to concepts in UMLS, we collect synonyms of every code. Then, we propose a multiple synonyms matching network to leverage synonyms for better code representation learning, and finally help the code classification. Experiments on the MIMIC-III dataset show that our proposed method outperforms previous state-of-the-art methods.},
	urldate = {2024-03-31},
	publisher = {arXiv},
	author = {Yuan, Zheng and Tan, Chuanqi and Huang, Songfang},
	month = mar,
	year = {2022},
	note = {arXiv:2203.01515 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/DR4UULM4/Yuan et al. - 2022 - Code Synonyms Do Matter Multiple Synonyms Matchin.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/55E87C3N/2203.html:text/html},
}

@misc{yang_surpassing_2023,
	title = {Surpassing {GPT}-4 {Medical} {Coding} with a {Two}-{Stage} {Approach}},
	url = {http://arxiv.org/abs/2311.13735},
	abstract = {Recent advances in large language models (LLMs) show potential for clinical applications, such as clinical decision support and trial recommendations. However, the GPT-4 LLM predicts an excessive number of ICD codes for medical coding tasks, leading to high recall but low precision. To tackle this challenge, we introduce LLM-codex, a two-stage approach to predict ICD codes that first generates evidence proposals using an LLM and then employs an LSTM-based verification stage. The LSTM learns from both the LLM's high recall and human expert's high precision, using a custom loss function. Our model is the only approach that simultaneously achieves state-of-the-art results in medical coding accuracy, accuracy on rare codes, and sentence-level evidence identification to support coding decisions without training on human-annotated evidence according to experiments on the MIMIC dataset.},
	urldate = {2024-03-31},
	publisher = {arXiv},
	author = {Yang, Zhichao and Batra, Sanjit Singh and Stremmel, Joel and Halperin, Eran},
	month = nov,
	year = {2023},
	note = {arXiv:2311.13735 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/K42AXI3M/2311.html:text/html;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/WXPBD52V/Yang et al. - 2023 - Surpassing GPT-4 Medical Coding with a Two-Stage A.pdf:application/pdf},
}

@misc{peng_rwkv_2023,
	title = {{RWKV}: {Reinventing} {RNNs} for the {Transformer} {Era}},
	shorttitle = {{RWKV}},
	url = {http://arxiv.org/abs/2305.13048},
	doi = {10.48550/arXiv.2305.13048},
	abstract = {Transformers have revolutionized almost all natural language processing (NLP) tasks but suffer from memory and computational complexity that scales quadratically with sequence length. In contrast, recurrent neural networks (RNNs) exhibit linear scaling in memory and computational requirements but struggle to match the same performance as Transformers due to limitations in parallelization and scalability. We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of transformers with the efficient inference of RNNs. Our approach leverages a linear attention mechanism and allows us to formulate the model as either a Transformer or an RNN, thus parallelizing computations during training and maintains constant computational and memory complexity during inference. We scale our models as large as 14 billion parameters, by far the largest dense RNN ever trained, and find RWKV performs on par with similarly sized Transformers, suggesting future work can leverage this architecture to create more efficient models. This work presents a significant step towards reconciling trade-offs between computational efficiency and model performance in sequence processing tasks.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Peng, Bo and Alcaide, Eric and Anthony, Quentin and Albalak, Alon and Arcadinho, Samuel and Biderman, Stella and Cao, Huanqi and Cheng, Xin and Chung, Michael and Grella, Matteo and GV, Kranthi Kiran and He, Xuzheng and Hou, Haowen and Lin, Jiaju and Kazienko, Przemyslaw and Kocon, Jan and Kong, Jiaming and Koptyra, Bartlomiej and Lau, Hayden and Mantri, Krishna Sri Ipsit and Mom, Ferdinand and Saito, Atsushi and Song, Guangyu and Tang, Xiangru and Wang, Bolun and Wind, Johan S. and Wozniak, Stanislaw and Zhang, Ruichong and Zhang, Zhenyuan and Zhao, Qihang and Zhou, Peng and Zhou, Qinghua and Zhu, Jian and Zhu, Rui-Jie},
	month = dec,
	year = {2023},
	note = {arXiv:2305.13048 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/Z9APB2WL/Peng et al. - 2023 - RWKV Reinventing RNNs for the Transformer Era.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/XWRATFK3/2305.html:text/html},
}

@article{olsson_iinn-dcuocntitoenxthleeaadrsning_nodate,
	title = {{IInn}-{dcuocntitoenxtHLeeaadrsning} and},
	language = {en},
	author = {Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Johnston, Scott and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
	file = {Olsson et al. - IInn-dcuocntitoenxtHLeeaadrsning and.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/TJN4ICEE/Olsson et al. - IInn-dcuocntitoenxtHLeeaadrsning and.pdf:application/pdf},
}

@article{sutskever_sequence_2014,
	title = {Sequence to sequence learning with neural networks},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html},
	urldate = {2024-03-26},
	journal = {Advances in neural information processing systems},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	year = {2014},
	file = {Available Version (via Google Scholar):/home/extasia/snap/zotero-snap/common/Zotero/storage/6YMG59M3/Sutskever et al. - 2014 - Sequence to sequence learning with neural networks.pdf:application/pdf},
}

@article{gu_mamba_nodate,
	title = {Mamba: {Linear}-{Time} {Sequence} {Modeling} with {Selective} {State} {Spaces}},
	abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models (SSMs) have been developed to address Transformers’ computational ineﬃciency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the SSM parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of eﬃcient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective SSMs into a simpliﬁed end-to-end neural network architecture without attention or even MLP blocks (Mamba). Mamba enjoys fast inference (5× higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
	language = {en},
	author = {Gu, Albert and Dao, Tri},
	file = {Gu and Dao - Mamba Linear-Time Sequence Modeling with Selectiv.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/TGHBCLHL/Gu and Dao - Mamba Linear-Time Sequence Modeling with Selectiv.pdf:application/pdf},
}

@article{gwilliam_development_2011,
	title = {Development of {Prognosis} in {Palliative} care {Study} ({PiPS}) predictor models to improve prognostication in advanced cancer: prospective cohort study},
	volume = {343},
	copyright = {© Gwilliam et al 2011. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits use, distribution, and reproduction in any medium, provided the original work is properly cited, the use is non commercial and is otherwise in compliance with the license. See: http://creativecommons.org/licenses/by-nc/2.0/  and  http://creativecommons.org/licenses/by-nc/2.0/legalcode.},
	issn = {0959-8138, 1468-5833},
	shorttitle = {Development of {Prognosis} in {Palliative} care {Study} ({PiPS}) predictor models to improve prognostication in advanced cancer},
	url = {https://www.bmj.com/content/343/bmj.d4920},
	doi = {10.1136/bmj.d4920},
	abstract = {Objective To develop a novel prognostic indicator for use in patients with advanced cancer that is significantly better than clinicians’ estimates of survival.
Design Prospective multicentre observational cohort study.
Setting 18 palliative care services in the UK (including hospices, hospital support teams, and community teams).
Participants 1018 patients with locally advanced or metastatic cancer, no longer being treated for cancer, and recently referred to palliative care services.
Main outcome measures Performance of a composite model to predict whether patients were likely to survive for “days” (0-13 days), “weeks” (14-55 days), or “months+” ({\textgreater}55 days), compared with actual survival and clinicians’ predictions.
Results On multivariate analysis, 11 core variables (pulse rate, general health status, mental test score, performance status, presence of anorexia, presence of any site of metastatic disease, presence of liver metastases, C reactive protein, white blood count, platelet count, and urea) independently predicted both two week and two month survival. Four variables had prognostic significance only for two week survival (dyspnoea, dysphagia, bone metastases, and alanine transaminase), and eight variables had prognostic significance only for two month survival (primary breast cancer, male genital cancer, tiredness, loss of weight, lymphocyte count, neutrophil count, alkaline phosphatase, and albumin). Separate prognostic models were created for patients without (PiPS-A) or with (PiPS-B) blood results. The area under the curve for all models varied between 0.79 and 0.86. Absolute agreement between actual survival and PiPS predictions was 57.3\% (after correction for over-optimism). The median survival across the PiPS-A categories was 5, 33, and 92 days and survival across PiPS-B categories was 7, 32, and 100.5 days. All models performed as well as, or better than, clinicians’ estimates of survival.
Conclusions In patients with advanced cancer no longer being treated, a combination of clinical and laboratory variables can reliably predict two week and two month survival.},
	language = {en},
	urldate = {2024-03-08},
	journal = {BMJ},
	author = {Gwilliam, Bridget and Keeley, Vaughan and Todd, Chris and Gittins, Matthew and Roberts, Chris and Kelly, Laura and Barclay, Stephen and Stone, Patrick C.},
	month = aug,
	year = {2011},
	pmid = {21868477},
	note = {Publisher: British Medical Journal Publishing Group
Section: Research},
	pages = {d4920},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EHWV38FM/Gwilliam et al. - 2011 - Development of Prognosis in Palliative care Study .pdf:application/pdf},
}

@article{chu_prognostication_2019,
	title = {Prognostication in palliative care},
	volume = {19},
	issn = {1470-2118},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6752241/},
	doi = {10.7861/clinmedicine.19-4-306},
	abstract = {An accurate prognosis about how long a terminally ill patient has left to live, when disclosed sensitively in open discussions, can facilitate patient-centred care and shared decision making. In addition, several guidelines, policies and funding streams rely, to some extent, on a clinician estimated prognosis. However, clinician predictions alone have been shown to be unreliable and over-optimistic. The factors underlying clinicians’ prognostic decisions (particularly at the very end of life) are beginning to be elucidated. As an alternative to clinicians’ subjective estimates, a number of prognostic algorithms and scores have been developed and validated, but only a few have consistently shown superiority to clinician predictions. Therefore, an element of uncertainty remains and this needs to be acknowledged when having conversations with patients and their families. Guidelines are available to advise clinicians about how to prepare for, participate in and record prognostic conversations.},
	number = {4},
	urldate = {2024-03-08},
	journal = {Clinical Medicine},
	author = {Chu, Christina and White, Nicola and Stone, Patrick},
	month = jul,
	year = {2019},
	pmid = {31308109},
	pmcid = {PMC6752241},
	pages = {306--310},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/LQ2SJITA/Chu et al. - 2019 - Prognostication in palliative care.pdf:application/pdf},
}

@misc{dong_language_2024,
	title = {A {Language} {Model} based {Framework} for {New} {Concept} {Placement} in {Ontologies}},
	url = {http://arxiv.org/abs/2402.17897},
	doi = {10.48550/arXiv.2402.17897},
	abstract = {We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies.},
	urldate = {2024-03-07},
	publisher = {arXiv},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Gao, Yongsheng and Horrocks, Ian},
	month = mar,
	year = {2024},
	note = {arXiv:2402.17897 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, I.2.7, I.2.4},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/HL84F9ER/Dong et al. - 2024 - A Language Model based Framework for New Concept P.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/QWZ2QZRZ/2402.html:text/html},
}

@inproceedings{choi_retain_2016,
	title = {{RETAIN}: {An} {Interpretable} {Predictive} {Model} for {Healthcare} using {Reverse} {Time} {Attention} {Mechanism}},
	volume = {29},
	shorttitle = {{RETAIN}},
	url = {https://proceedings.neurips.cc/paper/2016/hash/231141b34c82aa95e48810a9d1b33a79-Abstract.html},
	abstract = {Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models.},
	urldate = {2024-03-07},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Choi, Edward and Bahadori, Mohammad Taha and Sun, Jimeng and Kulas, Joshua and Schuetz, Andy and Stewart, Walter},
	year = {2016},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/5CM374AE/Choi et al. - 2016 - RETAIN An Interpretable Predictive Model for Heal.pdf:application/pdf},
}

@book{bhattacharyya_introduction_2015,
	title = {Introduction to {SNOMED} {CT}},
	isbn = {978-981-287-895-3},
	abstract = {As a general introduction to the SNOMED CT clinical terminology code system, the book explains in simple terms a wealth of key aspects, including the fundamentals of SNOMED CT, the various ways in which it can be used, and the methods by which it may quickly be deployed for use within an electronic documentation system that deals with clinical and clinics-related data. Further considerations include how end users can employ the system, how healthcare IT designers and developers can build highly ergonomic systems, and how health informatics experts and clinical analysts can successfully harness the various features that the clinical terminology code system provides in order to unleash the hidden potentials of clinical data.  The book brings together material from various sources, presenting it in an easy-to-follow manner and supplemented by analyses of a number of different (imaginary) scenarios including case summaries from the author’s experience and knowledge. The book will greatly benefit all stakeholders involved: clinicians, nurses, paramedics, dentists, public health professionals, health informatics professionals and healthcare IT engineers involved in the design and development of information systems for healthcare. Students at both the undergraduate and postgraduate levels seeking a practical introduction to SNOMED CT will find this book to be a valuable guide.},
	language = {en},
	publisher = {Springer},
	author = {Bhattacharyya, S. B.},
	month = dec,
	year = {2015},
	note = {Google-Books-ID: xTk3CwAAQBAJ},
	keywords = {Education / General, Education / Teaching / General, Medical / General},
}

@misc{clare_gardiner_extent_nodate,
	title = {Extent of palliative care need in the acute hospital setting: {A} survey of two acute hospitals in the {UK}},
	shorttitle = {Extent of palliative care need in the acute hospital setting},
	url = {https://journals.sagepub.com/doi/epub/10.1177/0269216312447592},
	language = {en},
	urldate = {2024-03-06},
	author = {{Clare Gardiner} and {Merryn Gott} and {Jane Seymour} and {Mark Cobb} and {Bill Noble} and {Mike Bennet}},
	doi = {10.1177/0269216312447592},
	file = {Accepted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/QKRTGGJB/Extent of palliative care need in the acute hospit.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/93UTJT3B/0269216312447592.html:text/html},
}

@inproceedings{ng_feature_2004,
	address = {Banff, Alberta, Canada},
	title = {Feature selection, \textit{{L}} $_{\textrm{1}}$ vs. \textit{{L}} $_{\textrm{2}}$ regularization, and rotational invariance},
	url = {http://portal.acm.org/citation.cfm?doid=1015330.1015435},
	doi = {10.1145/1015330.1015435},
	abstract = {We consider supervised learning in the presence of very many irrelevant features, and study two diﬀerent regularization methods for preventing overﬁtting. Focusing on logistic regression, we show that using L1 regularization of the parameters, the sample complexity (i.e., the number of training examples required to learn “well,”) grows only logarithmically in the number of irrelevant features. This logarithmic rate matches the best known bounds for feature selection, and indicates that L1 regularized logistic regression can be eﬀective even if there are exponentially many irrelevant features as there are training examples. We also give a lowerbound showing that any rotationally invariant algorithm—including logistic regression with L2 regularization, SVMs, and neural networks trained by backpropagation—has a worst case sample complexity that grows at least linearly in the number of irrelevant features.},
	language = {en},
	urldate = {2024-03-06},
	booktitle = {Twenty-first international conference on {Machine} learning  - {ICML} '04},
	publisher = {ACM Press},
	author = {Ng, Andrew Y.},
	year = {2004},
	pages = {78},
	file = {Ng - 2004 - Feature selection, L 1 vs. L.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/2UVZGBXN/Ng - 2004 - Feature selection, L 1 vs. L.pdf:application/pdf},
}

@misc{grinsztajn_why_2022,
	title = {Why do tree-based models still outperform deep learning on tabular data?},
	url = {http://arxiv.org/abs/2207.08815},
	doi = {10.48550/arXiv.2207.08815},
	abstract = {While deep learning has enabled tremendous progress on text and image datasets, its superiority on tabular data is not clear. We contribute extensive benchmarks of standard and novel deep learning methods as well as tree-based models such as XGBoost and Random Forests, across a large number of datasets and hyperparameter combinations. We define a standard set of 45 datasets from varied domains with clear characteristics of tabular data and a benchmarking methodology accounting for both fitting models and finding good hyperparameters. Results show that tree-based models remain state-of-the-art on medium-sized data (\${\textbackslash}sim\$10K samples) even without accounting for their superior speed. To understand this gap, we conduct an empirical investigation into the differing inductive biases of tree-based models and Neural Networks (NNs). This leads to a series of challenges which should guide researchers aiming to build tabular-specific NNs: 1. be robust to uninformative features, 2. preserve the orientation of the data, and 3. be able to easily learn irregular functions. To stimulate research on tabular architectures, we contribute a standard benchmark and raw data for baselines: every point of a 20 000 compute hours hyperparameter search for each learner.},
	urldate = {2024-03-06},
	publisher = {arXiv},
	author = {Grinsztajn, Léo and Oyallon, Edouard and Varoquaux, Gaël},
	month = jul,
	year = {2022},
	note = {arXiv:2207.08815 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2BQMB26E/Grinsztajn et al. - 2022 - Why do tree-based models still outperform deep lea.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/QSGNZZMW/2207.html:text/html},
}

@article{badaro_transformers_2023,
	title = {Transformers for {Tabular} {Data} {Representation}: {A} {Survey} of {Models} and {Applications}},
	volume = {11},
	issn = {2307-387X},
	shorttitle = {Transformers for {Tabular} {Data} {Representation}},
	url = {https://doi.org/10.1162/tacl_a_00544},
	doi = {10.1162/tacl_a_00544},
	abstract = {In the last few years, the natural language processing community has witnessed advances in neural representations of free texts with transformer-based language models (LMs). Given the importance of knowledge available in tabular data, recent research efforts extend LMs by developing neural representations for structured data. In this article, we present a survey that analyzes these efforts. We first abstract the different systems according to a traditional machine learning pipeline in terms of training data, input representation, model training, and supported downstream tasks. For each aspect, we characterize and compare the proposed solutions. Finally, we discuss future work directions.},
	urldate = {2024-02-28},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Badaro, Gilbert and Saeed, Mohammed and Papotti, Paolo},
	month = mar,
	year = {2023},
	pages = {227--249},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/WSRJCJSJ/Badaro et al. - 2023 - Transformers for Tabular Data Representation A Su.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DJFXCGD8/Transformers-for-Tabular-Data-Representation-A.html:text/html},
}

@article{shahmirzalou_survival_2023,
	title = {Survival analysis of recurrent breast cancer patients using mix {Bayesian} network},
	volume = {9},
	issn = {24058440},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405844023075680},
	doi = {10.1016/j.heliyon.2023.e20360},
	abstract = {Introduction: Breast cancer (BC) is the most common cancer among women. Iranians have an 11\% BC recurrence rate, which lowers their survival rates. Few studies have investigated cancer recurrence survival rates. This study’s major purpose is to use a mixed Bayesian network (BN) to analyze recurrent patients’ survival. Material and methods: This study aimed to evaluate the pathobiological features, age, gender, final status, and survival time of the patients. Bayesian imputation was used for missing data. The performance of BN was optimized through the utilization of a blacklist and prior probability. After structural and parametric learning, posterior conditional probabilities and mean survival periods for the node arcs were predicted. The hold-out technique based on the posterior classi­ fication error was used to investigate the model’s validation.
Results: The study included 220 cancer recurrence patients. These patients averaged 47 years old. The BN with a blacklist and prior probability has a higher network score than other networks. The hold-out technique verified structural learning. The Directed Acyclic Graph showed a statistically significant relationship between cancer biomarkers (ER, PR, and HER2 receptors), cancer stage, and tumor grade and patient survival duration. Patient death was also significantly associated with education, ER, PR, HER2, and tumor grade. The BN reports that HER2 negative, ER positive, and PR positive patients had a higher survival rate.
Conclusion: Survival and death of relapsed patients depend on biomarkers. Based on the findings, patient survival can be predicted with their features.},
	language = {en},
	number = {10},
	urldate = {2024-02-26},
	journal = {Heliyon},
	author = {Shahmirzalou, Parviz and Khaledi, Majid Jafari and Khayamzadeh, Maryam and Rasekhi, Aliakbar},
	month = oct,
	year = {2023},
	pages = {e20360},
	file = {Shahmirzalou et al. - 2023 - Survival analysis of recurrent breast cancer patie.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/Y2HWAM8V/Shahmirzalou et al. - 2023 - Survival analysis of recurrent breast cancer patie.pdf:application/pdf},
}

@misc{turtel_llms_2025,
	title = {{LLMs} {Can} {Teach} {Themselves} to {Better} {Predict} the {Future}},
	url = {http://arxiv.org/abs/2502.05253},
	doi = {10.48550/arXiv.2502.05253},
	abstract = {We present an outcome-driven fine-tuning framework that enhances the forecasting capabilities of large language models (LLMs) without relying on human-curated reasoning samples. Our method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date. We then rank pairs of these reasoning traces by their distance to the actual outcomes before fine-tuning the model via Direct Preference Optimization (DPO). On a separate test set, our approach increases prediction accuracy of Phi-4 14B and DeepSeek-R1 14B by between 7--10{\textbackslash}\% over a base model and a DPO fine-tuned control model with randomized labels, bringing them on par with forecasting capabilities of much larger frontier models like GPT-4o.},
	urldate = {2025-03-05},
	publisher = {arXiv},
	author = {Turtel, Benjamin and Franklin, Danny and Schoenegger, Philipp},
	month = feb,
	year = {2025},
	note = {arXiv:2502.05253 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/G39PT8AI/2502.html:text/html},
}

@misc{rafailov_direct_2024,
	title = {Direct {Preference} {Optimization}: {Your} {Language} {Model} is {Secretly} a {Reward} {Model}},
	shorttitle = {Direct {Preference} {Optimization}},
	url = {http://arxiv.org/abs/2305.18290},
	doi = {10.48550/arXiv.2305.18290},
	abstract = {While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper we introduce a new parameterization of the reward model in RLHF that enables extraction of the corresponding optimal policy in closed form, allowing us to solve the standard RLHF problem with only a simple classification loss. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for sampling from the LM during fine-tuning or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of generations, and matches or improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
	urldate = {2025-03-05},
	publisher = {arXiv},
	author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea},
	month = jul,
	year = {2024},
	note = {arXiv:2305.18290 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZZQBAIN5/2305.html:text/html},
}

@article{jain_td-dnn_2022,
	title = {{TD}-{DNN}: {A} {Time} {Decay}-{Based} {Deep} {Neural} {Network} for {Recommendation} {System}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	shorttitle = {{TD}-{DNN}},
	url = {https://www.mdpi.com/2076-3417/12/13/6398},
	doi = {10.3390/app12136398},
	abstract = {In recent years, commercial platforms have embraced recommendation algorithms to provide customers with personalized recommendations. Collaborative Filtering is the most widely used technique of recommendation systems, whose accuracy is primarily reliant on the computed similarity by a similarity measure. Data sparsity is one problem that affects the performance of the similarity measures. In addition, most recommendation algorithms do not remove noisy data from datasets while recommending the items, reducing the accuracy of the recommendation. Furthermore, existing recommendation algorithms only consider historical ratings when recommending the items to users, but users’ tastes may change over time. To address these issues, this research presents a Deep Neural Network based on Time Decay (TD-DNN). In the data preprocessing phase of the model, noisy ratings are detected from the dataset and corrected using the Matrix Factorization approach. A power decay function is applied to the preprocessed input to provide more weightage to the recent ratings. This non-noisy weighted matrix is fed into the Deep Learning model, consisting of an input layer, a Multi-Layer Perceptron, and an output layer to generate predicted ratings. The model’s performance is tested on three benchmark datasets, and experimental results confirm that TD-DNN outperforms other existing approaches.},
	language = {en},
	number = {13},
	urldate = {2025-03-05},
	journal = {Applied Sciences},
	author = {Jain, Gourav and Mahara, Tripti and Sharma, Subhash Chander and Agarwal, Saurabh and Kim, Hyunsung},
	month = jan,
	year = {2022},
	note = {Number: 13
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {collaborative filtering, deep neural network, matrix factorization, noisy ratings, recommendation system, time decay functions},
	pages = {6398},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/B4YXVC6V/Jain et al. - 2022 - TD-DNN A Time Decay-Based Deep Neural Network for Recommendation System.pdf:application/pdf},
}

@article{boyle_year_nodate-1,
	title = {Year 2 {Progression} {Report}},
	language = {en},
	author = {Boyle, Joseph Spartacus},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KQEW8N9Y/Boyle - Year 2 Progression Report.pdf:application/pdf},
}

@misc{johnson_querygpt_2024,
	title = {{QueryGPT} - {Natural} {Language} to {SQL} using {Generative} {AI}},
	url = {https://www.uber.com/en-BD/blog/query-gpt/},
	abstract = {Discover how QueryGPT revolutionizes SQL query generation at Uber! Learn about the cutting-edge AI that turns natural language prompts into efficient SQL queries, boosting productivity at Uber. Dive into our journey of innovation and transformation.},
	language = {en},
	urldate = {2025-02-19},
	journal = {Uber Blog},
	author = {Johnson, Jeffrey},
	month = sep,
	year = {2024},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/2DTBTUHI/query-gpt.html:text/html},
}

@misc{lei_spider_2024,
	title = {Spider 2.0: {Evaluating} {Language} {Models} on {Real}-{World} {Enterprise} {Text}-to-{SQL} {Workflows}},
	shorttitle = {Spider 2.0},
	url = {http://arxiv.org/abs/2411.07763},
	doi = {10.48550/arXiv.2411.07763},
	abstract = {Real-world enterprise text-to-SQL workflows often involve complex cloud or local data across various database systems, multiple SQL queries in various dialects, and diverse operations from data transformation to analytics. We introduce Spider 2.0, an evaluation framework comprising 632 real-world text-to-SQL workflow problems derived from enterprise-level database use cases. The databases in Spider 2.0 are sourced from real data applications, often containing over 1,000 columns and stored in local or cloud database systems such as BigQuery and Snowflake. We show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata, dialect documentation, and even project-level codebases. This challenge calls for models to interact with complex SQL workflow environments, process extremely long contexts, perform intricate reasoning, and generate multiple SQL queries with diverse operations, often exceeding 100 lines, which goes far beyond traditional text-to-SQL challenges. Our evaluations indicate that based on o1-preview, our code agent framework successfully solves only 17.0\% of the tasks, compared with 91.2\% on Spider 1.0 and 73.0\% on BIRD. Our results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation -- especially in prior text-to-SQL benchmarks -- they require significant improvement in order to achieve adequate performance for real-world enterprise usage. Progress on Spider 2.0 represents crucial steps towards developing intelligent, autonomous, code agents for real-world enterprise settings. Our code, baseline models, and data are available at https://spider2-sql.github.io.},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Lei, Fangyu and Chen, Jixuan and Ye, Yuxiao and Cao, Ruisheng and Shin, Dongchan and Su, Hongjin and Suo, Zhaoqing and Gao, Hongcheng and Hu, Wenjing and Yin, Pengcheng and Zhong, Victor and Xiong, Caiming and Sun, Ruoxi and Liu, Qian and Wang, Sida and Yu, Tao},
	month = nov,
	year = {2024},
	note = {arXiv:2411.07763 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Databases},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/96UFCTGV/2411.html:text/html},
}

@inproceedings{yu_spider_2018,
	address = {Brussels, Belgium},
	title = {Spider: {A} {Large}-{Scale} {Human}-{Labeled} {Dataset} for {Complex} and {Cross}-{Domain} {Semantic} {Parsing} and {Text}-to-{SQL} {Task}},
	shorttitle = {Spider},
	url = {https://aclanthology.org/D18-1425/},
	doi = {10.18653/v1/D18-1425},
	abstract = {We present Spider, a large-scale complex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 college students. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains. We define a new complex and cross-domain semantic parsing and text-to-SQL task so that different complicated SQL queries and databases appear in train and test sets. In this way, the task requires the model to generalize well to both new SQL queries and new database schemas. Therefore, Spider is distinct from most of the previous semantic parsing tasks because they all use a single database and have the exact same program in the train set and the test set. We experiment with various state-of-the-art models and the best model achieves only 9.7\% exact matching accuracy on a database split setting. This shows that Spider presents a strong challenge for future research. Our dataset and task with the most recent updates are publicly available at https://yale-lily.github.io/seq2sql/spider.},
	urldate = {2025-02-19},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and Zhang, Zilin and Radev, Dragomir},
	editor = {Riloff, Ellen and Chiang, David and Hockenmaier, Julia and Tsujii, Jun'ichi},
	month = oct,
	year = {2018},
	pages = {3911--3921},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CFI7445W/Yu et al. - 2018 - Spider A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-t.pdf:application/pdf},
}

@misc{chu_timebench_2024,
	title = {{TimeBench}: {A} {Comprehensive} {Evaluation} of {Temporal} {Reasoning} {Abilities} in {Large} {Language} {Models}},
	shorttitle = {{TimeBench}},
	url = {http://arxiv.org/abs/2311.17667},
	doi = {10.48550/arXiv.2311.17667},
	abstract = {Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly comprehending the intricacies of the world. Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark. To address this, we propose TIMEBENCH, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena. TIMEBENCH provides a thorough evaluation for investigating the temporal reasoning capabilities of large language models. We conduct extensive experiments on GPT-4, LLaMA2, and other popular LLMs under various settings. Our experimental results indicate a significant performance gap between the state-of-the-art LLMs and humans, highlighting that there is still a considerable distance to cover in temporal reasoning. Besides, LLMs exhibit capability discrepancies across different reasoning categories. Furthermore, we thoroughly analyze the impact of multiple aspects on temporal reasoning and emphasize the associated challenges. We aspire for TIMEBENCH to serve as a comprehensive benchmark, fostering research in temporal reasoning1.},
	language = {en},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and Wang, Haotian and Liu, Ming and Qin, Bing},
	month = jun,
	year = {2024},
	note = {arXiv:2311.17667 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MFUXF8ID/Chu et al. - 2024 - TimeBench A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models.pdf:application/pdf},
}

@misc{chu_timebench_2024-1,
	title = {{TimeBench}: {A} {Comprehensive} {Evaluation} of {Temporal} {Reasoning} {Abilities} in {Large} {Language} {Models}},
	shorttitle = {{TimeBench}},
	url = {http://arxiv.org/abs/2311.17667},
	doi = {10.48550/arXiv.2311.17667},
	abstract = {Grasping the concept of time is a fundamental facet of human cognition, indispensable for truly comprehending the intricacies of the world. Previous studies typically focus on specific aspects of time, lacking a comprehensive temporal reasoning benchmark. To address this, we propose TimeBench, a comprehensive hierarchical temporal reasoning benchmark that covers a broad spectrum of temporal reasoning phenomena. TimeBench provides a thorough evaluation for investigating the temporal reasoning capabilities of large language models. We conduct extensive experiments on GPT-4, LLaMA2, and other popular LLMs under various settings. Our experimental results indicate a significant performance gap between the state-of-the-art LLMs and humans, highlighting that there is still a considerable distance to cover in temporal reasoning. Besides, LLMs exhibit capability discrepancies across different reasoning categories. Furthermore, we thoroughly analyze the impact of multiple aspects on temporal reasoning and emphasize the associated challenges. We aspire for TimeBench to serve as a comprehensive benchmark, fostering research in temporal reasoning. Resources are available at: https://github.com/zchuz/TimeBench},
	urldate = {2025-02-19},
	publisher = {arXiv},
	author = {Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and Wang, Haotian and Liu, Ming and Qin, Bing},
	month = jun,
	year = {2024},
	note = {arXiv:2311.17667 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PLBVTCDN/Chu et al. - 2024 - TimeBench A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/HQ8PSYE8/2311.html:text/html},
}

@article{boyle_year_nodate-2,
	title = {Year 2 {Progression} {Report}},
	language = {en},
	author = {Boyle, Joseph Spartacus},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/9UVKFLJ5/Boyle - Year 2 Progression Report.pdf:application/pdf},
}

@article{pollard_eicu_2018,
	title = {The {eICU} {Collaborative} {Research} {Database}, a freely available multi-center database for critical care research},
	volume = {5},
	copyright = {2018 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata2018178},
	doi = {10.1038/sdata.2018.178},
	abstract = {Critical care patients are monitored closely through the course of their illness. As a result of this monitoring, large amounts of data are routinely collected for these patients. Philips Healthcare has developed a telehealth system, the eICU Program, which leverages these data to support management of critically ill patients. Here we describe the eICU Collaborative Research Database, a multi-center intensive care unit (ICU)database with high granularity data for over 200,000 admissions to ICUs monitored by eICU Programs across the United States. The database is deidentified, and includes vital sign measurements, care plan documentation, severity of illness measures, diagnosis information, treatment information, and more. Data are publicly available after registration, including completion of a training course in research with human subjects and signing of a data use agreement mandating responsible handling of the data and adhering to the principle of collaborative research. The freely available nature of the data will support a number of applications including the development of machine learning algorithms, decision support tools, and clinical research.},
	language = {en},
	number = {1},
	urldate = {2025-02-12},
	journal = {Scientific Data},
	author = {Pollard, Tom J. and Johnson, Alistair E. W. and Raffa, Jesse D. and Celi, Leo A. and Mark, Roger G. and Badawi, Omar},
	month = sep,
	year = {2018},
	note = {Publisher: Nature Publishing Group},
	keywords = {Health care, Databases, Translational research},
	pages = {180178},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/3KXUYNNC/Pollard et al. - 2018 - The eICU Collaborative Research Database, a freely available multi-center database for critical care.pdf:application/pdf},
}

@article{contreras_apricot-mamba_2024,
	title = {{APRICOT}-{Mamba}: {Acuity} {Prediction} in {Intensive} {Care} {Unit} ({ICU}): {Development} and {Validation} of a {Stability}, {Transitions}, and {Life}-{Sustaining} {Therapies} {Prediction} {Model}},
	issn = {2693-5015},
	shorttitle = {{APRICOT}-{Mamba}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11326394/},
	doi = {10.21203/rs.3.rs-4790824/v1},
	abstract = {On average, more than 5 million patients are admitted to intensive care units (ICUs) in the US, with mortality rates ranging from 10 to 29\%. The acuity state of patients in the ICU can quickly change from stable to unstable, sometimes leading to life-threatening conditions. Early detection of deteriorating conditions can assist in more timely interventions and improved survival rates. While Artificial Intelligence (AI)-based models show potential for assessing acuity in a more granular and automated manner, they typically use mortality as a proxy of acuity in the ICU. Furthermore, these methods do not determine the acuity state of a patient (i.e., stable or unstable), the transition between acuity states, or the need for life-sustaining therapies. In this study, we propose APRICOT-M (Acuity Prediction in Intensive Care Unit-Mamba), a 1M-parameter state space-based neural network to predict acuity state, transitions, and the need for life-sustaining therapies in real-time among ICU patients. The model integrates ICU data in the preceding four hours (including vital signs, laboratory results, assessment scores, and medications) and patient characteristics (age, sex, race, and comorbidities) to predict the acuity outcomes in the next four hours. Our state space-based model can process sparse and irregularly sampled data without manual imputation, thus reducing the noise in input data and increasing inference speed. The model was trained on data from 107,473 patients (142,062 ICU admissions) from 55 hospitals between 2014–2017 and validated externally on data from 74,901 patients (101,356 ICU admissions) from 143 hospitals. Additionally, it was validated temporally on data from 12,927 patients (15,940 ICU admissions) from one hospital in 2018–2019 and prospectively on data from 215 patients (369 ICU admissions) from one hospital in 2021–2023. Three datasets were used for training and evaluation: the University of Florida Health (UFH) dataset, the electronic ICU Collaborative Research Database (eICU), and the Medical Information Mart for Intensive Care (MIMIC)-IV dataset. APRICOT-M significantly outperforms the baseline acuity assessment, Sequential Organ Failure Assessment (SOFA), for mortality prediction in both external (AUROC 0.95 CI: 0.94–0.95 compared to 0.78 CI: 0.78–0.79) and prospective (AUROC 0.99 CI: 0.97–1.00 compared to 0.80 CI: 0.65–0.92) cohorts, as well as for instability prediction (external AUROC 0.75 CI: 0.74–0.75 compared to 0.51 CI: 0.51–0.51, and prospective AUROC 0.69 CI: 0.64–0.74 compared to 0.53 CI: 0.50–0.57). This tool has the potential to help clinicians make timely interventions by predicting the transition between acuity states and decision-making on life-sustaining within the next four hours in the ICU.},
	urldate = {2025-02-12},
	journal = {Research Square},
	author = {Contreras, Miguel and Silva, Brandon and Shickel, Benjamin and Davidson, Andrea and Ozrazgat-Baslanti, Tezcan and Ren, Yuanfang and Guan, Ziyuan and Balch, Jeremy and Zhang, Jiaqing and Bandyopadhyay, Sabyasachi and Loftus, Tyler and Khezeli, Kia and Nerella, Subhash and Bihorac, Azra and Rashidi, Parisa},
	month = aug,
	year = {2024},
	pmid = {39149454},
	pmcid = {PMC11326394},
	pages = {rs.3.rs--4790824},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/B7835K4E/Contreras et al. - 2024 - APRICOT-Mamba Acuity Prediction in Intensive Care Unit (ICU) Development and Validation of a Stabi.pdf:application/pdf},
}

@misc{labach_duett_2023,
	title = {{DuETT}: {Dual} {Event} {Time} {Transformer} for {Electronic} {Health} {Records}},
	shorttitle = {{DuETT}},
	url = {http://arxiv.org/abs/2304.13017},
	doi = {10.48550/arXiv.2304.13017},
	abstract = {Electronic health records (EHRs) recorded in hospital settings typically contain a wide range of numeric time series data that is characterized by high sparsity and irregular observations. Effective modelling for such data must exploit its time series nature, the semantic relationship between different types of observations, and information in the sparsity structure of the data. Self-supervised Transformers have shown outstanding performance in a variety of structured tasks in NLP and computer vision. But multivariate time series data contains structured relationships over two dimensions: time and recorded event type, and straightforward applications of Transformers to time series data do not leverage this distinct structure. The quadratic scaling of self-attention layers can also significantly limit the input sequence length without appropriate input engineering. We introduce the DuETT architecture, an extension of Transformers designed to attend over both time and event type dimensions, yielding robust representations from EHR data. DuETT uses an aggregated input where sparse time series are transformed into a regular sequence with fixed length; this lowers the computational complexity relative to previous EHR Transformer models and, more importantly, enables the use of larger and deeper neural networks. When trained with self-supervised prediction tasks, that provide rich and informative signals for model pre-training, our model outperforms state-of-the-art deep learning models on multiple downstream tasks from the MIMIC-IV and PhysioNet-2012 EHR datasets.},
	urldate = {2025-02-12},
	publisher = {arXiv},
	author = {Labach, Alex and Pokhrel, Aslesha and Huang, Xiao Shi and Zuberi, Saba and Yi, Seung Eun and Volkovs, Maksims and Poutanen, Tomi and Krishnan, Rahul G.},
	month = aug,
	year = {2023},
	note = {arXiv:2304.13017 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/3574HIML/Labach et al. - 2023 - DuETT Dual Event Time Transformer for Electronic Health Records.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/VEYSGJQU/2304.html:text/html},
}

@article{contreras_apricot-mamba_2024-1,
	title = {{APRICOT}-{Mamba}: {Acuity} {Prediction} in {Intensive} {Care} {Unit} ({ICU}): {Development} and {Validation} of a {Stability}, {Transitions}, and {Life}-{Sustaining} {Therapies} {Prediction} {Model}},
	issn = {2693-5015},
	shorttitle = {{APRICOT}-{Mamba}},
	doi = {10.21203/rs.3.rs-4790824/v1},
	abstract = {On average, more than 5 million patients are admitted to intensive care units (ICUs) in the US, with mortality rates ranging from 10 to 29\%. The acuity state of patients in the ICU can quickly change from stable to unstable, sometimes leading to life-threatening conditions. Early detection of deteriorating conditions can assist in more timely interventions and improved survival rates. While Artificial Intelligence (AI)-based models show potential for assessing acuity in a more granular and automated manner, they typically use mortality as a proxy of acuity in the ICU. Furthermore, these methods do not determine the acuity state of a patient (i.e., stable or unstable), the transition between acuity states, or the need for life-sustaining therapies. In this study, we propose APRICOT-M (Acuity Prediction in Intensive Care Unit-Mamba), a 1M-parameter state space-based neural network to predict acuity state, transitions, and the need for life-sustaining therapies in real-time among ICU patients. The model integrates ICU data in the preceding four hours (including vital signs, laboratory results, assessment scores, and medications) and patient characteristics (age, sex, race, and comorbidities) to predict the acuity outcomes in the next four hours. Our state space-based model can process sparse and irregularly sampled data without manual imputation, thus reducing the noise in input data and increasing inference speed. The model was trained on data from 107,473 patients (142,062 ICU admissions) from 55 hospitals between 2014-2017 and validated externally on data from 74,901 patients (101,356 ICU admissions) from 143 hospitals. Additionally, it was validated temporally on data from 12,927 patients (15,940 ICU admissions) from one hospital in 2018-2019 and prospectively on data from 215 patients (369 ICU admissions) from one hospital in 2021-2023. Three datasets were used for training and evaluation: the University of Florida Health (UFH) dataset, the electronic ICU Collaborative Research Database (eICU), and the Medical Information Mart for Intensive Care (MIMIC)-IV dataset. APRICOT-M significantly outperforms the baseline acuity assessment, Sequential Organ Failure Assessment (SOFA), for mortality prediction in both external (AUROC 0.95 CI: 0.94-0.95 compared to 0.78 CI: 0.78-0.79) and prospective (AUROC 0.99 CI: 0.97-1.00 compared to 0.80 CI: 0.65-0.92) cohorts, as well as for instability prediction (external AUROC 0.75 CI: 0.74-0.75 compared to 0.51 CI: 0.51-0.51, and prospective AUROC 0.69 CI: 0.64-0.74 compared to 0.53 CI: 0.50-0.57). This tool has the potential to help clinicians make timely interventions by predicting the transition between acuity states and decision-making on life-sustaining within the next four hours in the ICU.},
	language = {eng},
	journal = {Research Square},
	author = {Contreras, Miguel and Silva, Brandon and Shickel, Benjamin and Davidson, Andrea and Ozrazgat-Baslanti, Tezcan and Ren, Yuanfang and Guan, Ziyuan and Balch, Jeremy and Zhang, Jiaqing and Bandyopadhyay, Sabyasachi and Loftus, Tyler and Khezeli, Kia and Nerella, Subhash and Bihorac, Azra and Rashidi, Parisa},
	month = aug,
	year = {2024},
	pmid = {39149454},
	pmcid = {PMC11326394},
	keywords = {acuity, intensive care unit, mortality, state space, transformers},
	pages = {rs.3.rs--4790824},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/LBAB7G8D/Contreras et al. - 2024 - APRICOT-Mamba Acuity Prediction in Intensive Care Unit (ICU) Development and Validation of a Stabi.pdf:application/pdf},
}

@article{liu_catnet_2022,
	title = {{CATNet}: {Cross}-event attention-based time-aware network for medical event prediction},
	volume = {134},
	issn = {0933-3657},
	shorttitle = {{CATNet}},
	url = {https://www.sciencedirect.com/science/article/pii/S0933365722001920},
	doi = {10.1016/j.artmed.2022.102440},
	abstract = {Medical event prediction (MEP) is a fundamental task in the healthcare domain, which needs to predict medical events, including medications, diagnosis codes, laboratory tests, procedures, outcomes, and so on, according to historical medical records of patients. Many researchers have tried to build MEP models to overcome the challenges caused by the heterogeneous and irregular temporal characteristics of EHR data. However, most of them consider the heterogenous and temporal medical events separately and ignore the correlations among different types of medical events, especially relations between heterogeneous historical medical events and target medical events. In this paper, we propose a novel neural network based on attention mechanism called Cross-event Attention-based Time-aware Network (CATNet) for MEP. It is a time-aware, event-aware and task-adaptive method with the following advantages: 1) modeling heterogeneous information and temporal information in a unified way and considering irregular temporal characteristics locally and globally respectively, 2) taking full advantage of correlations among different types of events via cross-event attention. Experiments on two public datasets (MIMIC-III and eICU) show CATNet outperforms other state-of-the-art methods on various MEP tasks. The source code of CATNet is released at https://github.com/sherry6247/CATNet.git.},
	urldate = {2025-02-12},
	journal = {Artificial Intelligence in Medicine},
	author = {Liu, Sicen and Wang, Xiaolong and Xiang, Yang and Xu, Hui and Wang, Hui and Tang, Buzhou},
	month = dec,
	year = {2022},
	keywords = {Cross-attention, Event-aware, Medical event prediction, Task-adaptive, Time-aware},
	pages = {102440},
	file = {ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/QAIWPJG3/S0933365722001920.html:text/html;Submitted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/83JIWMLU/Liu et al. - 2022 - CATNet Cross-event attention-based time-aware network for medical event prediction.pdf:application/pdf},
}

@article{qiu_interpretable_2022,
	title = {Interpretable machine learning prediction of all-cause mortality},
	volume = {2},
	copyright = {2022 The Author(s)},
	issn = {2730-664X},
	url = {https://www.nature.com/articles/s43856-022-00180-x},
	doi = {10.1038/s43856-022-00180-x},
	abstract = {Unlike linear models which are traditionally used to study all-cause mortality, complex machine learning models can capture non-linear interrelations and provide opportunities to identify unexplored risk factors. Explainable artificial intelligence can improve prediction accuracy over linear models and reveal great insights into outcomes like mortality. This paper comprehensively analyzes all-cause mortality by explaining complex machine learning models.},
	language = {en},
	number = {1},
	urldate = {2025-02-04},
	journal = {Communications Medicine},
	author = {Qiu, Wei and Chen, Hugh and Dincer, Ayse Berceste and Lundberg, Scott and Kaeberlein, Matt and Lee, Su-In},
	month = oct,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Epidemiology, Computational biology and bioinformatics, Prognostic markers},
	pages = {1--15},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/28UR63K2/Qiu et al. - 2022 - Interpretable machine learning prediction of all-cause mortality.pdf:application/pdf},
}

@article{knaus_apache_1991,
	title = {The {APACHE} {III} prognostic system. {Risk} prediction of hospital mortality for critically ill hospitalized adults},
	volume = {100},
	issn = {0012-3692},
	doi = {10.1378/chest.100.6.1619},
	abstract = {The objective of this study was to refine the APACHE (Acute Physiology, Age, Chronic Health Evaluation) methodology in order to more accurately predict hospital mortality risk for critically ill hospitalized adults. We prospectively collected data on 17,440 unselected adult medical/surgical intensive care unit (ICU) admissions at 40 US hospitals (14 volunteer tertiary-care institutions and 26 hospitals randomly chosen to represent intensive care services nationwide). We analyzed the relationship between the patient's likelihood of surviving to hospital discharge and the following predictive variables: major medical and surgical disease categories, acute physiologic abnormalities, age, preexisting functional limitations, major comorbidities, and treatment location immediately prior to ICU admission. The APACHE III prognostic system consists of two options: (1) an APACHE III score, which can provide initial risk stratification for severely ill hospitalized patients within independently defined patient groups; and (2) an APACHE III predictive equation, which uses APACHE III score and reference data on major disease categories and treatment location immediately prior to ICU admission to provide risk estimates for hospital mortality for individual ICU patients. A five-point increase in APACHE III score (range, 0 to 299) is independently associated with a statistically significant increase in the relative risk of hospital death (odds ratio, 1.10 to 1.78) within each of 78 major medical and surgical disease categories. The overall predictive accuracy of the first-day APACHE III equation was such that, within 24 h of ICU admission, 95 percent of ICU admissions could be given a risk estimate for hospital death that was within 3 percent of that actually observed (r2 = 0.41; receiver operating characteristic = 0.90). Recording changes in the APACHE III score on each subsequent day of ICU therapy provided daily updates in these risk estimates. When applied across the individual ICUs, the first-day APACHE III equation accounted for the majority of variation in observed death rates (r2 = 0.90, p less than 0.0001).},
	language = {eng},
	number = {6},
	journal = {Chest},
	author = {Knaus, W. A. and Wagner, D. P. and Draper, E. A. and Zimmerman, J. E. and Bergner, M. and Bastos, P. G. and Sirio, C. A. and Murphy, D. J. and Lotring, T. and Damiano, A.},
	month = dec,
	year = {1991},
	pmid = {1959406},
	keywords = {Prognosis, Aged, Female, Humans, Male, Middle Aged, Age Factors, Aged, 80 and over, Critical Illness, Intensive Care Units, Odds Ratio, Risk Factors, Severity of Illness Index},
	pages = {1619--1636},
}

@misc{noauthor_critical_nodate,
	title = {Critical {Care} {Medicine}},
	url = {https://journals.lww.com/ccmjournal/abstract/1981/08000/APACHE_acute_physiology_and_chronic_health.8.aspx.},
	urldate = {2025-02-04},
	file = {Critical Care Medicine:/home/extasia/snap/zotero-snap/common/Zotero/storage/YFUHLUXS/APACHE_acute_physiology_and_chronic_health.8.aspx..html:text/html},
}

@article{lee_validation_2014,
	title = {Validation of the {APACHE} {IV} model and its comparison with the {APACHE} {II}, {SAPS} 3, and {Korean} {SAPS} 3 models for the prediction of hospital mortality in a {Korean} surgical intensive care unit},
	volume = {67},
	issn = {2005-6419},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4166383/},
	doi = {10.4097/kjae.2014.67.2.115},
	abstract = {Background
The Acute Physiology and Chronic Health Evaluation (APACHE) IV model has not yet been validated in Korea. The aim of this study was to compare the ability of the APACHE IV with those of APACHE II, Simplified Acute Physiology Score (SAPS) 3, and Korean SAPS 3 in predicting hospital mortality in a surgical intensive care unit (SICU) population.

Methods
We retrospectively reviewed electronic medical records for patients admitted to the SICU from March 2011 to February 2012 in a university hospital. Measurements of discrimination and calibration were performed using the area under the receiver operating characteristic curve (AUC) and the Hosmer-Lemeshow test, respectively. We calculated the standardized mortality ratio (SMR, actual mortality predicted mortality) for the four models.

Results
The study included 1,314 patients. The hospital mortality rate was 3.3\%. The discriminative powers of all models were similar and very reliable. The AUCs were 0.80 for APACHE IV, 0.85 for APACHE II, 0.86 for SAPS 3, and 0.86 for Korean SAPS 3. Hosmer and Lemeshow C and H statistics showed poor calibration for all of the models (P {\textless} 0.05). The SMRs of APACHE IV, APACHE II, SAPS 3, and Korean SAPS 3 were 0.21, 0.11 0.23, 0.34, and 0.25, respectively.

Conclusions
The APACHE IV revealed good discrimination but poor calibration. The overall discrimination and calibration of APACHE IV were similar to those of APACHE II, SAPS 3, and Korean SAPS 3 in this study. A high level of customization is required to improve calibration in this study setting.},
	number = {2},
	urldate = {2025-02-04},
	journal = {Korean Journal of Anesthesiology},
	author = {Lee, Hannah and Shon, Yoon-Jung and Kim, Hyerim and Paik, Hyesun and Park, Hee-Pyoung},
	month = aug,
	year = {2014},
	pmid = {25237448},
	pmcid = {PMC4166383},
	pages = {115--122},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/4L42BBKX/Lee et al. - 2014 - Validation of the APACHE IV model and its comparison with the APACHE II, SAPS 3, and Korean SAPS 3 m.pdf:application/pdf},
}

@article{shann_mortality_2000,
	title = {Mortality prediction model is preferable to {APACHE}},
	volume = {320},
	issn = {0959-8138},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1117722/},
	number = {7236},
	urldate = {2025-02-04},
	journal = {BMJ : British Medical Journal},
	author = {Shann, Frank},
	month = mar,
	year = {2000},
	pmid = {10710593},
	pmcid = {PMC1117722},
	pages = {714},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/VHTS4LKV/Shann - 2000 - Mortality prediction model is preferable to APACHE.pdf:application/pdf},
}

@article{weng_prediction_2019,
	title = {Prediction of premature all-cause mortality: {A} prospective general population cohort study comparing machine-learning and standard epidemiological approaches},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {Prediction of premature all-cause mortality},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0214365},
	doi = {10.1371/journal.pone.0214365},
	abstract = {Background Prognostic modelling using standard methods is well-established, particularly for predicting risk of single diseases. Machine-learning may offer potential to explore outcomes of even greater complexity, such as premature death. This study aimed to develop novel prediction algorithms using machine-learning, in addition to standard survival modelling, to predict premature all-cause mortality. Methods A prospective population cohort of 502,628 participants aged 40–69 years were recruited to the UK Biobank from 2006–2010 and followed-up until 2016. Participants were assessed on a range of demographic, biometric, clinical and lifestyle factors. Mortality data by ICD-10 were obtained from linkage to Office of National Statistics. Models were developed using deep learning, random forest and Cox regression. Calibration was assessed by comparing observed to predicted risks; and discrimination by area under the ‘receiver operating curve’ (AUC). Findings 14,418 deaths (2.9\%) occurred over a total follow-up time of 3,508,454 person-years. A simple age and gender Cox model was the least predictive (AUC 0.689, 95\% CI 0.681–0.699). A multivariate Cox regression model significantly improved discrimination by 6.2\% (AUC 0.751, 95\% CI 0.748–0.767). The application of machine-learning algorithms further improved discrimination by 3.2\% using random forest (AUC 0.783, 95\% CI 0.776–0.791) and 3.9\% using deep learning (AUC 0.790, 95\% CI 0.783–0.797). These ML algorithms improved discrimination by 9.4\% and 10.1\% respectively from a simple age and gender Cox regression model. Random forest and deep learning achieved similar levels of discrimination with no significant difference. Machine-learning algorithms were well-calibrated, while Cox regression models consistently over-predicted risk. Conclusions Machine-learning significantly improved accuracy of prediction of premature all-cause mortality in this middle-aged population, compared to standard methods. This study illustrates the value of machine-learning for risk prediction within a traditional epidemiological study design, and how this approach might be reported to assist scientific verification.},
	language = {en},
	number = {3},
	urldate = {2025-02-04},
	journal = {PLOS ONE},
	author = {Weng, Stephen F. and Vaz, Luis and Qureshi, Nadeem and Kai, Joe},
	month = mar,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Machine learning, Algorithms, Deep learning, Blood pressure, Cancer detection and diagnosis, Cancer risk factors, Medical risk factors, Neural networks},
	pages = {e0214365},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/33T655E9/Weng et al. - 2019 - Prediction of premature all-cause mortality A prospective general population cohort study comparing.pdf:application/pdf},
}

@article{huang_geographically_2010,
	title = {Geographically and temporally weighted regression for modeling spatio-temporal variation in house prices},
	volume = {24},
	issn = {1365-8816},
	url = {https://doi.org/10.1080/13658810802672469},
	doi = {10.1080/13658810802672469},
	abstract = {By incorporating temporal effects into the geographically weighted regression (GWR) model, an extended GWR model, geographically and temporally weighted regression (GTWR), has been developed to deal with both spatial and temporal nonstationarity simultaneously in real estate market data. Unlike the standard GWR model, GTWR integrates both temporal and spatial information in the weighting matrices to capture spatial and temporal heterogeneity. The GTWR design embodies a local weighting scheme wherein GWR and temporally weighted regression (TWR) become special cases of GTWR. In order to test its improved performance, GTWR was compared with global ordinary least squares, TWR, and GWR in terms of goodness-of-fit and other statistical measures using a case study of residential housing sales in the city of Calgary, Canada, from 2002 to 2004. The results showed that there were substantial benefits in modeling both spatial and temporal nonstationarity simultaneously. In the test sample, the TWR, GWR, and GTWR models, respectively, reduced absolute errors by 3.5\%, 31.5\%, and 46.4\% relative to a global ordinary least squares model. More impressively, the GTWR model demonstrated a better goodness-of-fit (0.9282) than the TWR model (0.7794) and the GWR model (0.8897). McNamara's test supported the hypothesis that the improvements made by GTWR over the TWR and GWR models are statistically significant for the sample data.},
	number = {3},
	urldate = {2025-01-30},
	journal = {International Journal of Geographical Information Science},
	author = {Huang, Bo and Wu, Bo and Barry, Michael},
	month = mar,
	year = {2010},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/13658810802672469},
	pages = {383--401},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/Z3L38HC7/Huang et al. - 2010 - Geographically and temporally weighted regression for modeling spatio-temporal variation in house pr.pdf:application/pdf},
}

@misc{noauthor_querylibrary_nodate,
	title = {{QueryLibrary}},
	url = {https://data.ohdsi.org/QueryLibrary/},
	urldate = {2025-01-27},
	file = {QueryLibrary:/home/extasia/snap/zotero-snap/common/Zotero/storage/F8J7ICJJ/QueryLibrary.html:text/html},
}

@misc{deepseek-ai_deepseek-r1_2025,
	title = {{DeepSeek}-{R1}: {Incentivizing} {Reasoning} {Capability} in {LLMs} via {Reinforcement} {Learning}},
	shorttitle = {{DeepSeek}-{R1}},
	url = {http://arxiv.org/abs/2501.12948},
	doi = {10.48550/arXiv.2501.12948},
	abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
	urldate = {2025-01-27},
	publisher = {arXiv},
	author = {DeepSeek-AI and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
	month = jan,
	year = {2025},
	note = {arXiv:2501.12948 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/TMSQ22X8/2501.html:text/html},
}

@article{oufattole_meds-torch_nodate,
	title = {{MEDS}-{Torch}: {An} {ML} {Pipeline} for {Inductive} {Experiments} for {EHR} {Medical} {Foundation} {Models}},
	abstract = {We introduce MEDS-Torch, a scalable and extensible pipeline for inductive experiments with sequence models on medical datasets adhering to the MEDS format—a universal schema for medical time series data. Using this pipeline, we systematically compare three tokenization methods (Everything In Code, Triplet, and Text Code) and evaluate five transfer learning techniques, including autoregressive generative modeling and contrastive learning variations, across multiple predictive tasks on the MIMIC-IV EHR dataset. Our empirical analysis provides actionable insights into the effectiveness of each method, demonstrating significant performance differences among tokenization and pretraining combinations. By benchmarking these approaches against fully supervised learning models, we offer practical recommendations for selecting appropriate modeling strategies in diverse healthcare settings. MEDS-Torch streamlines the process of running controlled experiments on medical datasets and promotes reproducibility and standardization in EHR research through its exclusive dependence on the MEDS schema, facilitating more effective machine learning experiments in healthcare without reliance on dataset-specific nuances.},
	language = {en},
	author = {Oufattole, Nassim and Bergamaschi, Teya and Renc, Pawel and Kolo, Aleksia and McDermott, Matthew B A and Stultz, Collin},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/SRW464J5/Oufattole et al. - MEDS-Torch An ML Pipeline for Inductive Experiments for EHR Medical Foundation Models.pdf:application/pdf},
}

@article{tipirneni_self-supervised_2022,
	title = {Self-{Supervised} {Transformer} for {Sparse} and {Irregularly} {Sampled} {Multivariate} {Clinical} {Time}-{Series}},
	volume = {16},
	issn = {1556-4681},
	url = {https://dl.acm.org/doi/10.1145/3516367},
	doi = {10.1145/3516367},
	abstract = {Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at .},
	number = {6},
	urldate = {2025-01-21},
	journal = {ACM Trans. Knowl. Discov. Data},
	author = {Tipirneni, Sindhu and Reddy, Chandan K.},
	month = jul,
	year = {2022},
	pages = {105:1--105:17},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/83LPV8SB/Tipirneni and Reddy - 2022 - Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series.pdf:application/pdf},
}

@article{chi_advanced_2023,
	title = {Advanced {Care} {Planning} for {Hospitalized} {Patients} {Following} {Clinician} {Notification} of {Patient} {Mortality} by a {Machine} {Learning} {Algorithm}},
	volume = {6},
	issn = {2574-3805},
	url = {https://doi.org/10.1001/jamanetworkopen.2023.8795},
	doi = {10.1001/jamanetworkopen.2023.8795},
	abstract = {Goal-concordant care is an ongoing challenge in hospital settings. Identification of high mortality risk within 30 days may call attention to the need to have serious illness conversations, including the documentation of patient goals of care.To examine goals of care discussions (GOCDs) in a community hospital setting with patients identified as having a high risk of mortality by a machine learning mortality prediction algorithm.This cohort study took place at community hospitals within 1 health care system. Participants included adult patients with a high risk of 30-day mortality who were admitted to 1 of 4 hospitals between January 2 and July 15, 2021. Patient encounters of inpatients in the intervention hospital where physicians were notified of the computed high risk mortality score were compared with patient encounters of inpatients in 3 community hospitals without the intervention (ie, matched control).Physicians of patients with a high risk of mortality within 30 days received notification and were encouraged to arrange for GOCDs.The primary outcome was the percentage change of documented GOCDs prior to discharge. Propensity-score matching was completed on a preintervention and postintervention period using age, sex, race, COVID-19 status, and machine learning-predicted mortality risk scores. A difference-in-difference analysis validated the results.Overall, 537 patients were included in this study with 201 in the preintervention period (94 in the intervention group; 104 in the control group) and 336 patients in the postintervention period. The intervention and control groups included 168 patients per group and were well-balanced in age (mean [SD], 79.3 [9.60] vs 79.6 [9.21] years; standardized mean difference [SMD], 0.03), sex (female, 85 [51\%] vs 85 [51\%]; SMD, 0), race (White patients, 145 [86\%] vs 144 [86\%]; SMD 0.006), and Charlson comorbidities (median [range], 8.00 [2.00-15.0] vs 9.00 [2.00 to 19.0]; SMD, 0.34). Patients in the intervention group from preintervention to postintervention period were associated with being 5 times more likely to have documented GOCDs (OR, 5.11 [95\% CI, 1.93 to 13.42]; P = .001) by discharge compared with matched controls, and GOCD occurred significantly earlier in the hospitalization in the intervention patients as compared with matched controls (median, 4 [95\% CI, 3 to 6] days vs 16 [95\% CI, 15 to not applicable] days; P \&lt; .001). Similar findings were observed for Black patient and White patient subgroups.In this cohort study, patients whose physicians had knowledge of high-risk predictions from machine learning mortality algorithms were associated with being 5 times more likely to have documented GOCDs than matched controls. Additional external validation is needed to determine if similar interventions would be helpful at other institutions.},
	number = {4},
	urldate = {2025-01-21},
	journal = {JAMA Network Open},
	author = {Chi, Stephen and Kim, Seunghwan and Reuter, Matthew and Ponzillo, Katharine and Oliver, Debra Parker and Foraker, Randi and Heard, Kevin and Liu, Jingxia and Pitzer, Kyle and White, Patrick and Moore, Nathan},
	month = apr,
	year = {2023},
	pages = {e238795},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/8Y5EUISU/Chi et al. - 2023 - Advanced Care Planning for Hospitalized Patients Following Clinician Notification of Patient Mortali.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/YGR4NJML/2803939.html:text/html},
}

@article{chamberlin_early_2012,
	title = {Early {History} of {SQL}},
	volume = {34},
	issn = {1934-1547},
	url = {https://ieeexplore.ieee.org/abstract/document/6359709},
	doi = {10.1109/MAHC.2012.61},
	abstract = {In this Anecdotes department article, Don Chamberlin details his early work with Ray Boyce designing the relational language SQL. After meeting E.F. (Ted) Codd at a symposium at the IBM T.J. Watson Research Center in Yorktown Heights, New York, in 1972, Boyce and Chamberlin believed that it should be possible to design a relational language that would be accessible to users without formal training in mathematics or computer programming. Their early work on the Sequel language at IBM eventually evolved into the SQL international standard.},
	number = {4},
	urldate = {2025-01-21},
	journal = {IEEE Annals of the History of Computing},
	author = {Chamberlin, Donald D.},
	month = oct,
	year = {2012},
	note = {Conference Name: IEEE Annals of the History of Computing},
	keywords = {Computer languages, History, history of computing, IBM, Ray Boyce, relational data model, Relational databases, Sequel, SQL, SQL standard, Ted Codd},
	pages = {78--82},
	file = {IEEE Xplore Abstract Record:/home/extasia/snap/zotero-snap/common/Zotero/storage/5L62S735/6359709.html:text/html},
}

@article{schlick_timing_2019,
	title = {Timing of palliative care: {When} to call for a palliative care consult},
	volume = {120},
	issn = {1096-9098},
	shorttitle = {Timing of palliative care},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jso.25499},
	doi = {10.1002/jso.25499},
	abstract = {Palliative care, unlike hospice, can be utilized concurrently with disease-modifying or curative therapies. Some of the benefits of palliative care include improved quality of life, less end-of-life treatment, and decreased medical costs. Furthermore, palliative care can help guide treatment decisions to be in line with patients’ physical, psychological, and spiritual needs. On the basis of these benefits, we advocate for palliative care involvement early in the course of advanced malignancy and other terminal diagnoses.},
	language = {en},
	number = {1},
	urldate = {2024-12-23},
	journal = {Journal of Surgical Oncology},
	author = {Schlick, Cary Jo R. and Bentrem, David J.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jso.25499},
	keywords = {end-of-life care, hospice, metastatic cancer, palliative medicine},
	pages = {30--34},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/PIT248VX/jso.html:text/html},
}

@article{roberts_home_2021,
	title = {Home {Based} {Palliative} {Care}: {Known} {Benefits} and {Future} {Directions}},
	volume = {10},
	issn = {2196-7865},
	shorttitle = {Home {Based} {Palliative} {Care}},
	url = {https://doi.org/10.1007/s13670-021-00372-8},
	doi = {10.1007/s13670-021-00372-8},
	abstract = {To summarize key recent evidence regarding the impact of Home-Based Palliative Care (HBPalC) and to highlight opportunities for future study.},
	language = {en},
	number = {4},
	urldate = {2024-12-23},
	journal = {Current Geriatrics Reports},
	author = {Roberts, Benjamin and Robertson, Mariah and Ojukwu, Ekene I. and Wu, David Shih},
	month = dec,
	year = {2021},
	keywords = {Palliative care, HBPalC, Home based palliative care, Home care},
	pages = {141--147},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/UNXBB35M/Roberts et al. - 2021 - Home Based Palliative Care Known Benefits and Fut.pdf:application/pdf},
}

@article{khan_validity_2010,
	title = {Validity of diagnostic coding within the {General} {Practice} {Research} {Database}: a systematic review},
	volume = {60},
	copyright = {© British Journal of General Practice, 2010.},
	issn = {0960-1643, 1478-5242},
	shorttitle = {Validity of diagnostic coding within the {General} {Practice} {Research} {Database}},
	url = {https://bjgp.org/content/60/572/e128},
	doi = {10.3399/bjgp10X483562},
	abstract = {Background The UK-based General Practice Research Database (GPRD) is a valuable source of longitudinal primary care records and is increasingly used for epidemiological research.
Aim To conduct a systematic review of the literature on accuracy and completeness of diagnostic coding in the GPRD.
Design of study Systematic review.
Method Six electronic databases were searched using search terms relating to the GPRD, in association with terms synonymous with validity, accuracy, concordance, and recording. A positive predictive value was calculated for each diagnosis that considered a comparison with a gold standard. Studies were also considered that compared the GPRD with other databases and national statistics.
Results A total of 49 papers are included in this review. Forty papers conducted validation of a clinical diagnosis in the GPRD. When assessed against a gold standard (validation using GP questionnaire, primary care medical records, or hospital correspondence), most of the diagnoses were accurately recorded in the patient electronic record. Acute conditions were not as well recorded, with positive predictive values lower than 50\%. Twelve papers compared prevalence or consultation rates in the GPRD against other primary care databases or national statistics. Generally, there was good agreement between disease prevalence and consultation rates between the GPRD and other datasets; however, rates of diabetes and musculoskeletal conditions were underestimated in the GPRD.
Conclusion Most of the diagnoses coded in the GPRD are well recorded. Researchers using the GPRD may want to consider how well the disease of interest is recorded before planning research, and consider how to optimise the identification of clinical events.},
	language = {en},
	number = {572},
	urldate = {2024-12-23},
	journal = {British Journal of General Practice},
	author = {Khan, Nada F. and Harrison, Sian E. and Rose, Peter W.},
	month = mar,
	year = {2010},
	pmid = {20202356},
	note = {Publisher: British Journal of General Practice
Section: Systematic Review},
	keywords = {database management systems, meta-analysis, sensitivity and specificity, systematic review},
	pages = {e128--e136},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/XG3ZW9UG/Khan et al. - 2010 - Validity of diagnostic coding within the General P.pdf:application/pdf},
}

@inproceedings{schank_scripts_1975,
	address = {San Francisco, CA, USA},
	series = {{IJCAI}'75},
	title = {Scripts, plans, and knowledge},
	abstract = {We describe a theoretical system intended to facilitate the use of knowledge In an understanding system. The notion of script is introduced to account for knowledge about mundane situations. A program, SAM, is capable of using scripts to understand. The notion of plans is introduced to account for general knowledge about novel situations.},
	urldate = {2024-12-13},
	booktitle = {Proceedings of the 4th international joint conference on {Artificial} intelligence - {Volume} 1},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Schank, Roger C. and Abelson, Robert P.},
	month = sep,
	year = {1975},
	pages = {151--157},
}

@misc{jiang_survey_2024,
	title = {A {Survey} on {Large} {Language} {Models} for {Code} {Generation}},
	url = {http://arxiv.org/abs/2406.00515},
	doi = {10.48550/arXiv.2406.00515},
	abstract = {Large Language Models (LLMs) have garnered remarkable advancements across diverse code-related tasks, known as Code LLMs, particularly in code generation that generates source code with LLM from natural language descriptions. This burgeoning field has captured significant interest from both academic researchers and industry professionals due to its practical significance in software development, e.g., GitHub Copilot. Despite the active exploration of LLMs for a variety of code tasks, either from the perspective of natural language processing (NLP) or software engineering (SE) or both, there is a noticeable absence of a comprehensive and up-to-date literature review dedicated to LLM for code generation. In this survey, we aim to bridge this gap by providing a systematic literature review that serves as a valuable reference for researchers investigating the cutting-edge progress in LLMs for code generation. We introduce a taxonomy to categorize and discuss the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, ethical implications, environmental impact, and real-world applications. In addition, we present a historical overview of the evolution of LLMs for code generation and offer an empirical comparison using the HumanEval, MBPP, and BigCodeBench benchmarks across various levels of difficulty and types of programming tasks to highlight the progressive enhancements in LLM capabilities for code generation. We identify critical challenges and promising opportunities regarding the gap between academia and practical development. Furthermore, we have established a dedicated resource GitHub page (https://github.com/juyongjiang/CodeLLMSurvey) to continuously document and disseminate the most recent advances in the field.},
	urldate = {2024-12-13},
	publisher = {arXiv},
	author = {Jiang, Juyong and Wang, Fan and Shen, Jiasi and Kim, Sungju and Kim, Sunghun},
	month = nov,
	year = {2024},
	note = {arXiv:2406.00515 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MJTPRUK2/Jiang et al. - 2024 - A Survey on Large Language Models for Code Generat.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/G98L5DZL/2406.html:text/html},
}

@misc{sivasubramaniam_sm3-text--query_2024,
	title = {{SM3}-{Text}-to-{Query}: {Synthetic} {Multi}-{Model} {Medical} {Text}-to-{Query} {Benchmark}},
	shorttitle = {{SM3}-{Text}-to-{Query}},
	url = {http://arxiv.org/abs/2411.05521},
	doi = {10.48550/arXiv.2411.05521},
	abstract = {Electronic health records (EHRs) are stored in various database systems with different database models on heterogeneous storage architectures, such as relational databases, document stores, or graph databases. These different database models have a big impact on query complexity and performance. While this has been a known fact in database research, its implications for the growing number of Text-to-Query systems have surprisingly not been investigated so far. In this paper, we present SM3-Text-to-Query, the first multi-model medical Text-to-Query benchmark based on synthetic patient data from Synthea, following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology covering medical terminology. SM3-Text-to-Query provides data representations for relational databases (PostgreSQL), document stores (MongoDB), and graph databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically and manually develop 408 template questions, which we augment to construct a benchmark of 10K diverse natural language question/query pairs for these four query languages (40K pairs overall). On our dataset, we evaluate several common in-context-learning (ICL) approaches for a set of representative closed and open-source LLMs. Our evaluation sheds light on the trade-offs between database models and query languages for different ICL strategies and LLMs. Last, SM3-Text-to-Query is easily extendable to additional query languages or real, standard-based patient databases.},
	urldate = {2024-12-09},
	publisher = {arXiv},
	author = {Sivasubramaniam, Sithursan and Osei-Akoto, Cedric and Zhang, Yi and Stockinger, Kurt and Fuerst, Jonathan},
	month = nov,
	year = {2024},
	note = {arXiv:2411.05521 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/HWG5WVWV/Sivasubramaniam et al. - 2024 - SM3-Text-to-Query Synthetic Multi-Model Medical Text-to-Query Benchmark.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ZN4HJM7J/2411.html:text/html},
}

@book{perkins_recommended_2022,
	address = {Southampton (UK)},
	series = {Health and {Social} {Care} {Delivery} {Research}},
	title = {Recommended summary plan for emergency care and treatment: {ReSPECT} a mixed-methods study},
	copyright = {Copyright © 2022 Perkins et al. This work was produced by Perkins et al. under the terms of a commissioning contract issued by the Secretary of State for Health and Social Care. This is an Open Access publication distributed under the terms of the Creative Commons Attribution CC BY 4.0 licence, which permits unrestricted use, distribution, reproduction and adaption in any medium and for any purpose provided that it is properly attributed. See: https://creativecommons.org/licenses/by/4.0/. For attribution the title, original author(s), the publication source – NIHR Journals Library, and the DOI of the publication must be cited.},
	shorttitle = {Recommended summary plan for emergency care and treatment},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK587914/},
	abstract = {Do not attempt cardiopulmonary resuscitation decisions have been widely criticised. The Recommended Summary Plan for Emergency Care and Treatment (ReSPECT) process was developed to facilitate shared decisions between patients and clinicians in relation to emergency treatments, including cardiopulmonary resuscitation., To explore how, when and why ReSPECT plans are made and what effects the plans have on patient outcomes., A mixed-methods evaluation, comprising (1) a qualitative study of ReSPECT decision-making processes, (2) an interrupted time series examining process and survival outcomes following in-hospital cardiac arrest and (3) a retrospective observational study examining factors associated with ReSPECT recommendations and patient outcomes., NHS acute hospitals and primary care and community services in England (2017–2020)., Hospital doctors, general practitioners, nurses, patients and families., The following sources were used: (1) observations of ReSPECT conversations at six hospitals and conversations with clinicians, patient, families and general practitioners, (2) survey and freedom of information data from hospitals participating in the National Cardiac Arrest Audit and (3) a review of inpatient medical records, ReSPECT forms and NHS Safety Thermometer data., By December 2019, the ReSPECT process was being used in 40 of 186 (22\%) acute hospitals. In total, 792 of 3439 (23\%) inpatients, usually those identified at risk of deterioration, had a ReSPECT form. Involvement of the patient and/or family was recorded on 513 of 706 (73\%) ReSPECT forms reviewed. Clinicians said that lack of time prevented more conversations. Observed conversations focused on resuscitation, but also included other treatments and the patient’s values and preferences. Conversation types included open-ended conversations, with clinicians actively eliciting the patients’ wishes and preferences, a persuasive approach, swaying the conversation towards a decision aligned with medical opinion, and simply informing the patient/relative about a medical decision that had already been made. The frequency of harms reported on the NHS Safety Thermometer was similar among patients with or without a ReSPECT form. Hospital doctors and general practitioners gave different views on the purpose of the ReSPECT process and the type of recommendations they would record., The research was undertaken within the first 2 years following the implementation of ReSPECT. Local policies meant that doctors led these conversations. Most patients were seriously ill, which limited opportunities for interviews. Incomplete adoption of the ReSPECT process and problems associated with the NHS Safety Thermometer tool affected the evaluation on clinical outcomes., Patients and families were involved in most ReSPECT conversations. Conversations focused on resuscitation, but also included other emergency treatments. Respect for patient autonomy and duty to protect from harm informed clinicians’ approach to varying degrees, depending on the clinical situation and their views of ReSPECT as a shared decision-making process. The complexity of these conversations and the clinical, emotional and organisational barriers observed suggest that a nuanced and multifaceted approach will be necessary to support good ReSPECT processes., Further research is needed to understand the advantages and disadvantages to the adoption of a national emergency care and treatment plan system, the most effective national and local implementation approaches, and whether or not shared decision-making approaches in the context of emergency care and treatment plans could further enhance patient and family engagement., This study is registered as ISRCTN11112933., This project was funded by the National Institute for Health and Care Research (NIHR) Health and Social Care Delivery Research programme and will be published in full in Health and Social Care Delivery Research; Vol. 10, No. 40. See the NIHR Journals Library website for further project information.},
	language = {eng},
	urldate = {2024-11-27},
	publisher = {National Institute for Health and Care Research},
	author = {Perkins, Gavin D. and Hawkes, Claire A. and Eli, Karin and Griffin, James and Jacques, Claire and Huxley, Caroline J. and Couper, Keith and Ochieng, Cynthia and Fuld, Jonathan and Fritz, Zoe and George, Rob and Gould, Doug and Lilford, Richard and Underwood, Martin and Baldock, Catherine and Bassford, Chris and Fortune, Peter-Marc and Speakman, John and Wilkinson, Anna and Ewings, Bob and Warwick, Jane and Griffiths, Frances and Slowther, Anne-Marie},
	year = {2022},
	pmid = {36548453},
}

@article{boyle_population_nodate,
	title = {A {Population} {Health} {Approach} to {Identifying} {Patients} for {End} of {Life} {Care}},
	abstract = {Objective: Palliative care (PC) in the community reduces hospitalisations, distress, and healthcare costs. However, opportunities for palliative interventions are often missed. We aim to develop a digital tool which analyses EHR data to proactively identify patients for end of life care. Materials and Methods: Prospective analysis was conducted on coded EHR data for the 1,402,251 patients registered with NHS Nottinghamshire. We created a digital implementation of the latest Supportive and Palliative Care Indicators Tool (SPICTTM) 1, which we term AutoSPICT. AutoSPICTpositive patients were then assigned a probability by a logistic regression model trained to estimate 12-month mortality. Finally, clinicians manually reviewed the 20 patients with highest probabilities on XX/XX/XXXX at each of n practices to decide suitability for the palliative care register.
Results: The first two automatic stages of our pipeline were assessed against observed mortality over the 12-month period 02/08/23-01/08/24. AutoSPICT has superior PPV but lower sensitivity than Mason et al.'s earlier digital SPICT implementation (PPV 17.13 ± 0.17 versus 10.02 ± 0.17 and sensitivity 42.26 ± 0.47 versus 54.97 ± 0.60). Logistic Regression and Gradient Boosted Machine classifiers performed similarly at predicting mortality for the AutoSPICT-positive patients (n=3,685) with (PPV 73.85 ± 0.76 versus 76.83 ± 0.55 and sensitivity 47.68 ± versus 48.20 ± 0.64) The clinical review was conducted via a customised GUI, in which 80\% of the 20 top-ranked patients were deemed appropriate to add to the end-of-life register. Discussion: Our pipeline prioritised clinical interpretability and top-K precision in order to maximise review efficiency for time-pressured clinicians. Performance might be improved with the addition of temporal information.
Conclusion: Our pipeline achieved both high predictive accuracy and clinical acceptability. We make our curated AutoSPICT codesets (ICD-10, SNOMED-CT and Read codes) available at: .},
	language = {en},
	author = {Boyle, Joseph S and O'Neil, Mike and Liakata, Maria and O'Neil, Alison Q},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/33QJDMVK/Boyle et al. - A Population Health Approach to Identifying Patients for End of Life Care.pdf:application/pdf},
}

@misc{noauthor_population_nodate,
	title = {A {Population} {Health} {Approach} to {Identifying} {Patients} for {End} of {Life} {Care}},
	url = {https://www.overleaf.com/project/66fd18572f49f70ac66d4cfa},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2024-11-27},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/XFIATXVZ/66fd18572f49f70ac66d4cfa.html:text/html},
}

@misc{noauthor_auto-spict_nodate,
	title = {Auto-{SPICT} {JAMIA} template},
	url = {https://www.overleaf.com/project/66fd18572f49f70ac66d4cfa},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2024-11-27},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/6CZ55Q28/66fd18572f49f70ac66d4cfa.html:text/html},
}

@article{muschelli_roc_2020,
	title = {{ROC} and {AUC} with a {Binary} {Predictor}: a {Potentially} {Misleading} {Metric}},
	volume = {37},
	issn = {0176-4268},
	shorttitle = {{ROC} and {AUC} with a {Binary} {Predictor}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7695228/},
	doi = {10.1007/s00357-019-09345-1},
	abstract = {In analysis of binary outcomes, the receiver operator characteristic (ROC) curve is heavily used to show the performance of a model or algorithm. The ROC curve is informative about the performance over a series of thresholds and can be summarized by the area under the curve (AUC), a single number. When a predictor is categorical, the ROC curve has one less than number of categories as potential thresholds; when the predictor is binary there is only one threshold. As the AUC may be used in decision-making processes on determining the best model, it important to discuss how it agrees with the intuition from the ROC curve. We discuss how the interpolation of the curve between thresholds with binary predictors can largely change the AUC. Overall, we show using a linear interpolation from the ROC curve with binary predictors corresponds to the estimated AUC, which is most commonly done in software, which we believe can lead to misleading results. We compare R, Python, Stata, and SAS software implementations. We recommend using reporting the interpolation used and discuss the merit of using the step function interpolator, also referred to as the “pessimistic” approach by .},
	number = {3},
	urldate = {2024-11-25},
	journal = {Journal of classification},
	author = {Muschelli, John},
	month = oct,
	year = {2020},
	pmid = {33250548},
	pmcid = {PMC7695228},
	pages = {696--708},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JJGPACCE/Muschelli - 2020 - ROC and AUC with a Binary Predictor a Potentially.pdf:application/pdf},
}

@article{luta_healthcare_2024,
	title = {Healthcare trajectories and costs in the last year of life: a retrospective primary care and hospital analysis},
	volume = {14},
	copyright = {© Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {2045-435X, 2045-4368},
	shorttitle = {Healthcare trajectories and costs in the last year of life},
	url = {https://spcare.bmj.com/content/14/e1/e807},
	doi = {10.1136/bmjspcare-2020-002630},
	abstract = {Objectives To analyse healthcare utilisation and costs in the last year of life in England, and to study variation by cause of death, region of patient residence and socioeconomic status.
Methods This is a retrospective cohort study. Individuals aged 60 years and over (N=108 510) who died in England between 2010 and 2017 were included in the study.
Results Healthcare utilisation and costs in the last year of life increased with proximity to death, particularly in the last month of life. The mean total costs were higher among males (£8089) compared with females (£6898) and declined with age at death (£9164 at age 60–69 to £5228 at age 90+) with inpatient care accounting for over 60\% of total costs. Costs decline with age at death (0.92, 95\% CI 0.88 to 0.95, p{\textless}0.0001 for age group 90+ compared with to the reference category age group 60–69) and were lower among females (0.91, 95\% CI 0.90 to 0.92, p{\textless}0.0001 compared with males). Costs were higher (1.09, 95\% CI 1.01 to 1.14, p{\textless}0.0001) in London compared with other regions.
Conclusions Healthcare utilisation and costs in the last year of life increase with proximity to death, particularly in the last month of life. Finer geographical data and information on healthcare supply would allow further investigating whether people receiving more planned care by primary care and or specialist palliative care towards the end of life require less acute care.},
	language = {en},
	number = {e1},
	urldate = {2024-11-18},
	journal = {BMJ Supportive \& Palliative Care},
	author = {Luta, Xhyljeta and Diernberger, Katharina and Bowden, Joanna and Droney, Joanne and Howdon, Daniel and Schmidlin, Kurt and Rodwin, Victor and Hall, Peter and Marti, Joachim},
	month = may,
	year = {2024},
	pmid = {33268473},
	note = {Publisher: British Medical Journal Publishing Group
Section: Original research},
	keywords = {end of life care},
	pages = {e807--e815},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CUQ4Z6FG/Luta et al. - 2024 - Healthcare trajectories and costs in the last year.pdf:application/pdf},
}

@article{diernberger_healthcare_2024,
	title = {Healthcare use and costs in the last year of life: a national population data linkage study},
	volume = {14},
	copyright = {© Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
	issn = {2045-435X, 2045-4368},
	shorttitle = {Healthcare use and costs in the last year of life},
	url = {https://spcare.bmj.com/content/14/e1/e885},
	doi = {10.1136/bmjspcare-2020-002708},
	abstract = {Background People who are nearing the end of life are high users of healthcare. The cost to providers is high and the value of care is uncertain.
Objectives To describe the pattern, trajectory and drivers of secondary care use and cost by people in Scotland in their last year of life.
Methods Retrospective whole-population secondary care administrative data linkage study of Scottish decedents of 60 years and over between 2012 and 2017 (N=274 048).
Results Secondary care use was high in the last year of life with a sharp rise in inpatient admissions in the last 3 months. The mean cost was £10 000. Cause of death was associated with differing patterns of healthcare use: dying of cancer was preceded by the greatest number of hospital admissions and dementia the least. Greater age was associated with lower admission rates and cost. There was higher resource use in the urban areas. No difference was observed by deprivation.
Conclusions Hospitalisation near the end of life was least frequent for older people and those living rurally, although length of stay for both groups, when they were admitted, was longer. Research is required to understand if variation in hospitalisation is due to variation in the quantity or quality of end-of-life care available, varying community support, patient preferences or an inevitable consequence of disease-specific needs.},
	language = {en},
	number = {e1},
	urldate = {2024-11-18},
	journal = {BMJ Supportive \& Palliative Care},
	author = {Diernberger, Katharina and Luta, Xhyljeta and Bowden, Joanna and Fallon, Marie and Droney, Joanne and Lemmon, Elizabeth and Gray, Ewan and Marti, Joachim and Hall, Peter},
	month = may,
	year = {2024},
	pmid = {33579797},
	note = {Publisher: British Medical Journal Publishing Group
Section: Original research},
	keywords = {terminal care, hospital care, service evaluation, supportive care},
	pages = {e885--e892},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/IFPEURCX/Diernberger et al. - 2024 - Healthcare use and costs in the last year of life.pdf:application/pdf},
}

@book{deisenroth_mathematics_2020,
	title = {Mathematics for {Machine} {Learning}},
	isbn = {978-1-108-47004-9},
	abstract = {The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts. Every chapter includes worked examples and exercises to test understanding. Programming tutorials are offered on the book's web site.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
	month = apr,
	year = {2020},
	note = {Google-Books-ID: pFjPDwAAQBAJ},
	keywords = {Computers / Artificial Intelligence / Computer Vision \& Pattern Recognition, Computers / Artificial Intelligence / General, Computers / Optical Data Processing, Mathematics / Applied, Mathematics / Probability \& Statistics / General, Science / General},
}

@misc{noauthor_auto-spict_nodate-1,
	title = {Auto-{SPICT} {JAMIA} template},
	url = {https://www.overleaf.com/project/66fd18572f49f70ac66d4cfa},
	abstract = {An online LaTeX editor that’s easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
	language = {en},
	urldate = {2024-11-15},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/9PXXXTQE/66fd18572f49f70ac66d4cfa.html:text/html},
}

@misc{li_exploring_2024,
	title = {Exploring {LLM} {Multi}-{Agents} for {ICD} {Coding}},
	url = {http://arxiv.org/abs/2406.15363},
	doi = {10.48550/arXiv.2406.15363},
	abstract = {To address the limitations of Large Language Models (LLMs) in the International Classification of Diseases (ICD) coding task, where they often produce inaccurate and incomplete prediction results due to the high-dimensional and skewed distribution of the ICD codes, and often lack interpretability and reliability as well. We introduce an innovative multi-agent approach for ICD coding which mimics the ICD coding assignment procedure in real-world settings, comprising five distinct agents: the patient, physician, coder, reviewer, and adjuster. Each agent utilizes an LLM-based model tailored to their specific role within the coding process. We also integrate the system with Electronic Health Record (HER)'s SOAP (subjective, objective, assessment and plan) structure to boost the performances. We compare our method with a system of agents designed solely by LLMs and other strong baselines and evaluate it using the Medical Information Mart for Intensive Care III (MIMIC-III) dataset. Our multi-agent coding framework significantly outperforms Zero-shot Chain of Thought (CoT) prompting and self-consistency with CoT (CoT-SC) in coding common and rare ICD codes. An ablation study validates the effectiveness of the designated agent roles. it also outperforms the LLM-designed agent system. Moreover, our method achieves comparable results to state-of-the-art ICD coding methods that require extensive pre-training or fine-tuning, and outperforms them in rare code accuracy, and explainability. Additionally, we demonstrate the method's practical applicability by presenting its performance in scenarios not limited by the common or rare ICD code constraints.The proposed multi-agent method for ICD coding effectively mimics the real-world coding process and improves performance on both common and rare codes.},
	urldate = {2024-11-12},
	publisher = {arXiv},
	author = {Li, Rumeng and Wang, Xun and Yu, Hong},
	month = aug,
	year = {2024},
	note = {arXiv:2406.15363},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/8NID63CB/Li et al. - 2024 - Exploring LLM Multi-Agents for ICD Coding.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DK3FD75V/2406.html:text/html},
}

@misc{sun_is_2023,
	title = {Is {ChatGPT} {Good} at {Search}? {Investigating} {Large} {Language} {Models} as {Re}-{Ranking} {Agents}},
	shorttitle = {Is {ChatGPT} {Good} at {Search}?},
	url = {http://arxiv.org/abs/2304.09542},
	doi = {10.48550/arXiv.2304.09542},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge. In this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. Furthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the model's ability to rank unknown knowledge. Finally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme. Our evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark. The code to reproduce our results is available at www.github.com/sunnweiwei/RankGPT.},
	urldate = {2024-11-12},
	publisher = {arXiv},
	author = {Sun, Weiwei and Yan, Lingyong and Ma, Xinyu and Wang, Shuaiqiang and Ren, Pengjie and Chen, Zhumin and Yin, Dawei and Ren, Zhaochun},
	month = oct,
	year = {2023},
	note = {arXiv:2304.09542},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
}

@misc{sun_is_2023-1,
	title = {Is {ChatGPT} {Good} at {Search}? {Investigating} {Large} {Language} {Models} as {Re}-{Ranking} {Agents}},
	shorttitle = {Is {ChatGPT} {Good} at {Search}?},
	url = {http://arxiv.org/abs/2304.09542},
	doi = {10.48550/arXiv.2304.09542},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge. In this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. Furthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the model's ability to rank unknown knowledge. Finally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme. Our evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark. The code to reproduce our results is available at www.github.com/sunnweiwei/RankGPT.},
	urldate = {2024-11-12},
	publisher = {arXiv},
	author = {Sun, Weiwei and Yan, Lingyong and Ma, Xinyu and Wang, Shuaiqiang and Ren, Pengjie and Chen, Zhumin and Yin, Dawei and Ren, Zhaochun},
	month = oct,
	year = {2023},
	note = {arXiv:2304.09542},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/9FHP8D5J/Sun et al. - 2023 - Is ChatGPT Good at Search Investigating Large Lan.pdf:application/pdf},
}

@article{wegier_mhomr_2019,
	title = {{mHOMR}: a feasibility study of an automated system for identifying inpatients having an elevated risk of 1-year mortality},
	volume = {28},
	copyright = {© Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and permissions. Published by BMJ.},
	issn = {2044-5415, 2044-5423},
	shorttitle = {{mHOMR}},
	url = {https://qualitysafety.bmj.com/content/28/12/971},
	doi = {10.1136/bmjqs-2018-009285},
	abstract = {Objective The need for clinical staff to reliably identify patients with a shortened life expectancy is an obstacle to improving palliative and end-of-life care. We developed and evaluated the feasibility of an automated tool to identify patients with a high risk of death in the next year to prompt treating physicians to consider a palliative approach and reduce the identification burden faced by clinical staff.
Methods Two-phase feasibility study conducted at two quaternary healthcare facilities in Toronto, Canada. We modified the Hospitalised-patient One-year Mortality Risk (HOMR) score, which identifies patients having an elevated 1-year mortality risk, to use only data available at the time of admission. An application prompted the admitting team when patients had an elevated mortality risk and suggested a palliative approach. The incidences of goals of care discussions and/or palliative care consultation were abstracted from medical records.
Results Our model (C-statistic=0.89) was found to be similarly accurate to the original HOMR score and identified 15.8\% and 12.2\% of admitted patients at Sites 1 and 2, respectively. Of 400 patients included, the most common indications for admission included a frailty condition (219, 55\%), chronic organ failure (91, 23\%) and cancer (78, 20\%). At Site 1 (integrated notification), patients with the notification were significantly more likely to have a discussion about goals of care and/or palliative care consultation (35\% vs 20\%, p = 0.016). At Site 2 (electronic mail), there was no significant difference (45\% vs 53\%, p = 0.322).
Conclusions Our application is an accurate, feasible and timely identification tool for patients at elevated risk of death in the next year and may be effective for improving palliative and end-of-life care.},
	language = {en},
	number = {12},
	urldate = {2024-11-11},
	journal = {BMJ Quality \& Safety},
	author = {Wegier, Pete and Koo, Ellen and Ansari, Shahin and Kobewka, Daniel and O'Connor, Erin and Wu, Peter and Steinberg, Leah and Bell, Chaim and Walton, Tara and Walraven, Carl van and Embuldeniya, Gayathri and Costello, Judy and Downar, James},
	month = dec,
	year = {2019},
	pmid = {31253736},
	note = {Publisher: BMJ Publishing Group Ltd
Section: Original research},
	keywords = {decision support, computerized, healthcare quality improvement, trigger tools},
	pages = {971--979},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/FMXT4FY2/Wegier et al. - 2019 - mHOMR a feasibility study of an automated system .pdf:application/pdf},
}

@article{saunders_mhomr_2021,
	title = {{mHOMR}: the acceptability of an automated mortality prediction model for timely identification of patients for palliative care},
	volume = {30},
	issn = {2044-5415, 2044-5423},
	shorttitle = {{mHOMR}},
	url = {https://qualitysafety.bmj.com/lookup/doi/10.1136/bmjqs-2020-012461},
	doi = {10.1136/bmjqs-2020-012461},
	language = {en},
	number = {10},
	urldate = {2024-11-11},
	journal = {BMJ Quality \& Safety},
	author = {Saunders, Stephanie and Downar, James and Subramaniam, Saranjah and Embuldeniya, Gaya and Van Walraven, Carl and Wegier, Pete},
	month = oct,
	year = {2021},
	pages = {837--840},
	file = {Saunders et al. - 2021 - mHOMR the acceptability of an automated mortality.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/8DKMVAPM/Saunders et al. - 2021 - mHOMR the acceptability of an automated mortality.pdf:application/pdf},
}

@misc{wu_beyond_2024,
	title = {Beyond {Label} {Attention}: {Transparency} in {Language} {Models} for {Automated} {Medical} {Coding} via {Dictionary} {Learning}},
	shorttitle = {Beyond {Label} {Attention}},
	url = {http://arxiv.org/abs/2411.00173},
	abstract = {Medical coding, the translation of unstructured clinical text into standardized medical codes, is a crucial but time-consuming healthcare practice. Though large language models (LLM) could automate the coding process and improve the efficiency of such tasks, interpretability remains paramount for maintaining patient trust. Current efforts in interpretability of medical coding applications rely heavily on label attention mechanisms, which often leads to the highlighting of extraneous tokens irrelevant to the ICD code. To facilitate accurate interpretability in medical language models, this paper leverages dictionary learning that can efficiently extract sparsely activated representations from dense language model embeddings in superposition. Compared with common label attention mechanisms, our model goes beyond token-level representations by building an interpretable dictionary which enhances the mechanistic-based explanations for each ICD code prediction, even when the highlighted tokens are medically irrelevant. We show that dictionary features can steer model behavior, elucidate the hidden meanings of upwards of 90\% of medically irrelevant tokens, and are human interpretable.},
	urldate = {2024-11-11},
	publisher = {arXiv},
	author = {Wu, John and Wu, David and Sun, Jimeng},
	month = oct,
	year = {2024},
	note = {arXiv:2411.00173},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/D5CT3HWW/Wu et al. - 2024 - Beyond Label Attention Transparency in Language M.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/LZMRX4VB/2411.html:text/html},
}

@article{hua_estimates_2014,
	title = {Estimates of the {Need} for {Palliative} {Care} {Consultation} across {United} {States} {Intensive} {Care} {Units} {Using} a {Trigger}-based {Model}},
	volume = {189},
	issn = {1073-449X},
	url = {https://www.atsjournals.org/doi/full/10.1164/rccm.201307-1229OC},
	doi = {10.1164/rccm.201307-1229OC},
	abstract = {Rationale: Use of triggers for palliative care consultation has been advocated in intensive care units (ICUs) to ensure appropriate specialist involvement for patients at high risk of unmet palliative care needs. The volume of patients meeting these triggers, and thus the potential workload for providers, is unknown. Objectives: To estimate the prevalence of ICU admissions who met criteria for palliative care consultation using different sets of triggers. Methods: Retrospective cohort study of ICU admissions from Project IMPACT for 2001–2008. We assessed the prevalence of ICU admissions meeting one or more primary palliative care triggers, and prevalence meeting any of multiple sets of triggers. Measurements and Main Results: Overall, 53,124 (13.8\%) ICU admissions met one or more primary triggers for palliative care consultation. Variation in prevalence was minimal across different types of units (mean 13.3\% in medical ICUs to 15.8\% in trauma/burn ICUs; P = 0.41) and individual units (mean 13.8\%, median 13.0\%, interquartile range, 10.2–16.5\%). A comprehensive model combining multiple sets of triggers identified a total of 75,923 (19.7\%) ICU admissions requiring palliative care consultation; of them, 85.4\% were captured by five triggers: (1) ICU admission after hospital stay greater than or equal to 10 days, (2) multisystem organ failure greater than or equal to three systems, (3) stage IV malignancy, (4) status post cardiac arrest, and (5) intracerebral hemorrhage requiring mechanical ventilation. Conclusions: Approximately one in seven ICU admissions met triggers for palliative care consultation using a single set of triggers, with an upper estimate of one in five patients using multiple sets of triggers; these estimates were consistent across different types of ICUs and individual units. These results may inform staffing requirements for providers to ensure delivery of specialized palliative care to ICU patients nationally.},
	number = {4},
	urldate = {2024-11-08},
	journal = {American Journal of Respiratory and Critical Care Medicine},
	author = {Hua, May S. and Li, Guohua and Blinderman, Craig D. and Wunsch, Hannah},
	month = feb,
	year = {2014},
	note = {Publisher: American Thoracic Society - AJRCCM},
	keywords = {end-of-life care, palliative medicine, critical care},
	pages = {428--436},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MBNNC3IN/Hua et al. - 2014 - Estimates of the Need for Palliative Care Consulta.pdf:application/pdf},
}

@article{bush_systematic_2018,
	title = {A systematic review of the use of the electronic health record for patient identification, communication, and clinical support in palliative care},
	volume = {1},
	issn = {2574-2531},
	url = {https://doi.org/10.1093/jamiaopen/ooy028},
	doi = {10.1093/jamiaopen/ooy028},
	abstract = {Globally, healthcare systems are using the electronic health record (EHR) and elements of clinical decision support (CDS) to facilitate palliative care (PC). Examination of published results is needed to determine if the EHR is successfully supporting the multidisciplinary nature and complexity of PC by identifying applications, methodology, outcomes, and barriers of active incorporation of the EHR in PC clinical workflow.A systematic review using Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The data sources PubMed, CINAL, EBSCOhost, and Academic Search Premier were used to identify literature published 1999–2017 of human subject peer-reviewed articles in English containing original research about the EHR and PC.The search returned 433 articles, 30 of which met inclusion criteria. Most studies were feasibility studies or retrospective cohort analyses; one study incorporated prospective longitudinal mixed methods. Twenty-three of 30 (77\%) were published after 2014. The review identified five major areas in which the EHR is used to support PC. Studies focused on CDS to: identify individuals who could benefit from PC; electronic advanced care planning (ACP) documentation; patient-reported outcome measures (PROMs) such as rapid, real-time pain feedback; to augment EHR PC data capture capabilities; and to enhance interdisciplinary communication and care.Beginning in 2015, there was a proliferation of articles about PC and EHRs, suggesting increasing incorporation of and research about the EHR with PC. This review indicates the EHR is underutilized for PC CDS, facilitating PROMs, and capturing ACPs.},
	number = {2},
	urldate = {2024-11-08},
	journal = {JAMIA Open},
	author = {Bush, Ruth A and Pérez, Alexa and Baum, Tanja and Etland, Caroline and Connelly, Cynthia D},
	month = oct,
	year = {2018},
	pages = {294--303},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/Y3S4WW2A/Bush et al. - 2018 - A systematic review of the use of the electronic h.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/RKEUU38H/5057586.html:text/html},
}

@article{gordon_sex_2017,
	title = {Sex differences in frailty: {A} systematic review and meta-analysis},
	volume = {89},
	issn = {0531-5565},
	shorttitle = {Sex differences in frailty},
	url = {https://www.sciencedirect.com/science/article/pii/S0531556516304442},
	doi = {10.1016/j.exger.2016.12.021},
	abstract = {Background
It is a well-described clinical phenomenon that females live longer than males, yet tend to experience greater levels of co-morbidity and disability. Females can therefore be considered both more frail (because they have poorer health status) and less frail (because they have a lower risk of mortality). This systematic review aimed to determine whether this ageing paradox is demonstrated when the Frailty Index (FI) is used to measure frailty.
Methods
Medline, EMBASE and CINAHL databases were searched for observational studies that measured FI and mortality in community-dwellers over 65years of age. In five-year age groups, meta-analysis determined the sex differences in mean FI (MD=mean FIfemale−mean FImale) and mortality rate.
Results
Of 6482 articles screened, seven articles were included. Meta-analysis of data from five studies (37,426 participants) found that MD values were positive (p{\textless}0.001; MD range=0.02–0.06) in all age groups, indicating that females had higher FI scores than males at all ages. This finding was consistent across individual studies. Heterogeneity was high (I2=72.7\%), reflecting methodological differences. Meta-analysis of mortality data (13,127 participants) showed that male mortality rates exceeded female mortality rates up until the 90 to 94-years age group. Individual studies reported higher mortality for males at each level of FI, and higher risk of death for males when controlling for age and FI.
Conclusions
The pattern of sex differences in the FI and mortality of older adults was consistent across populations and confirmed a ‘male-female health-survival paradox’.},
	urldate = {2024-11-06},
	journal = {Experimental Gerontology},
	author = {Gordon, E. H. and Peel, N. M. and Samanta, M. and Theou, O. and Howlett, S. E. and Hubbard, R. E.},
	month = mar,
	year = {2017},
	keywords = {Systematic review, Frailty, Frailty Index, Meta-analysis, Sex differences},
	pages = {30--40},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/7XEULYH6/Gordon et al. - 2017 - Sex differences in frailty A systematic review and meta-analysis.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/HIUQCILB/S0531556516304442.html:text/html},
}

@article{bernstein_4chan_2011,
	title = {4chan and /b/: {An} {Analysis} of {Anonymity} and {Ephemerality} in a {Large} {Online} {Community}},
	volume = {5},
	copyright = {Copyright (c) 2021 Proceedings of the International AAAI Conference on Web and Social Media},
	issn = {2334-0770},
	shorttitle = {4chan and /b/},
	url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14134},
	doi = {10.1609/icwsm.v5i1.14134},
	abstract = {We present two studies of online ephemerality and anonymity based on the popular discussion board /b/ at 4chan.org: a website with over 7 million users that plays an influential role in Internet culture. Although researchers and practitioners often assume that user identity and data permanence are central tools in the design of online communities, we explore how /b/ succeeds despite being almost entirely anonymous and extremely ephemeral. We begin by describing /b/ and performing a content analysis that suggests the community is dominated by playful exchanges of images and links. Our first study uses a large dataset of more than five million posts to quantify ephemerality in /b/. We find that most threads spend just five seconds on the first page and less than five minutes on the site before expiring. Our second study is an analysis of identity signals on 4chan, finding that over 90\% of posts are made by fully anonymous users, with other identity signals adopted and discarded at will. We describe alternative mechanisms that /b/ participants use to establish status and frame their interactions.},
	language = {en},
	number = {1},
	urldate = {2024-11-04},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Bernstein, Michael and Monroy-Hernández, Andrés and Harry, Drew and André, Paul and Panovich, Katrina and Vargas, Greg},
	year = {2011},
	note = {Number: 1},
	pages = {50--57},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/NZYJYFYN/Bernstein et al. - 2011 - 4chan and b An Analysis of Anonymity and Epheme.pdf:application/pdf},
}

@article{friedman_greedy_2001,
	title = {Greedy function approximation: {A} gradient boosting machine.},
	volume = {29},
	issn = {0090-5364, 2168-8966},
	shorttitle = {Greedy function approximation},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.full},
	doi = {10.1214/aos/1013203451},
	abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent “boosting” paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such “TreeBoost” models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
	number = {5},
	urldate = {2024-11-01},
	journal = {The Annals of Statistics},
	author = {Friedman, Jerome H.},
	month = oct,
	year = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62-02, 62-07, 62-08, 62G08, 62H30, 68T10, boosting, decision trees, Function estimation, robust nonparametric regression},
	pages = {1189--1232},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/C36PVPI8/Friedman - 2001 - Greedy function approximation A gradient boosting.pdf:application/pdf},
}

@article{wasserstein_moving_2019,
	title = {Moving to a {World} {Beyond} “p {\textless} 0.05”},
	volume = {73},
	issn = {0003-1305},
	url = {https://doi.org/10.1080/00031305.2019.1583913},
	doi = {10.1080/00031305.2019.1583913},
	number = {sup1},
	urldate = {2024-11-01},
	journal = {The American Statistician},
	author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
	month = mar,
	year = {2019},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/00031305.2019.1583913},
	pages = {1--19},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/VNYP2M7U/Wasserstein et al. - 2019 - Moving to a World Beyond “p  0.05”.pdf:application/pdf},
}

@article{coling_edge-free_nodate,
	title = {Edge-free but {Structure}-aware: {Prototype}-{Guided} {Knowledge} {Distillation} from {GNNs} to {MLPs}},
	language = {en},
	author = {Coling, Anonymous},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GHF6XDNK/Coling - Edge-free but Structure-aware Prototype-Guided Knowledge Distillation from GNNs to MLPs.pdf:application/pdf},
}

@article{noauthor_figure_nodate,
	title = {Figure 3 {\textbar} {Scientific} {Reports}},
	url = {https://www.nature.com/articles/s41598-024-56706-x/figures/3},
	language = {en},
	urldate = {2024-10-29},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/7AMYYPTS/3.html:text/html},
}

@article{noauthor_leveraging_nodate,
	title = {Leveraging {Deep} {AUC} {Maximization} for {Enhanced} {Active} {Learning} in {Named} {Entity} {Recognition}},
	file = {Leveraging Deep AUC Maximization for Enhanced Acti.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/NXWFU364/Leveraging Deep AUC Maximization for Enhanced Acti.pdf:application/pdf},
}

@article{wang_development_2019,
	title = {Development and {Validation} of a {Deep} {Learning} {Algorithm} for {Mortality} {Prediction} in {Selecting} {Patients} {With} {Dementia} for {Earlier} {Palliative} {Care} {Interventions}},
	volume = {2},
	issn = {2574-3805},
	url = {https://doi.org/10.1001/jamanetworkopen.2019.6972},
	doi = {10.1001/jamanetworkopen.2019.6972},
	abstract = {Early palliative care interventions drive high-value care but currently are underused. Health care professionals face challenges in identifying patients who may benefit from palliative care.To develop a deep learning algorithm using longitudinal electronic health records to predict mortality risk as a proxy indicator for identifying patients with dementia who may benefit from palliative care.In this retrospective cohort study, 6-month, 1-year, and 2-year mortality prediction models with recurrent neural networks used patient demographic information and topics generated from clinical notes within Partners HealthCare System, an integrated health care delivery system in Boston, Massachusetts. This study included 26 921 adult patients with dementia who visited the health care system from January 1, 2011, through December 31, 2017. The models were trained using a data set of 24 229 patients and validated using another data set of 2692 patients. Data were analyzed from September 18, 2018, to May 15, 2019.The area under the receiver operating characteristic curve (AUC) for 6-month and 1- and 2-year mortality prediction models and the factors contributing to the predictions.The study cohort included 26 921 patients (16 263 women [60.4\%]; mean [SD] age, 74.6 [13.5] years). For the 24 229 patients in the training data set, mean (SD) age was 74.8 (13.2) years and 14 632 (60.4\%) were women. For the 2692 patients in the validation data set, mean (SD) age was 75.0 (12.6) years and 1631 (60.6\%) were women. The 6-month model reached an AUC of 0.978 (95\% CI, 0.977-0.978); the 1-year model, 0.956 (95\% CI, 0.955-0.956); and the 2-year model, 0.943 (95\% CI, 0.942-0.944). The top-ranked latent topics associated with 6-month and 1- and 2-year mortality in patients with dementia include palliative and end-of-life care, cognitive function, delirium, testing of cholesterol levels, cancer, pain, use of health care services, arthritis, nutritional status, skin care, family meeting, shock, respiratory failure, and swallowing function.A deep learning algorithm based on patient demographic information and longitudinal clinical notes appeared to show promising results in predicting mortality among patients with dementia in different time frames. Further research is necessary to determine the feasibility of applying this algorithm in clinical settings for identifying unmet palliative care needs earlier.},
	number = {7},
	urldate = {2024-10-27},
	journal = {JAMA Network Open},
	author = {Wang, Liqin and Sha, Long and Lakin, Joshua R. and Bynum, Julie and Bates, David W. and Hong, Pengyu and Zhou, Li},
	month = jul,
	year = {2019},
	pages = {e196972},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/NSCESSJB/Wang et al. - 2019 - Development and Validation of a Deep Learning Algorithm for Mortality Prediction in Selecting Patien.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/KLQ3SQ4Q/2737901.html:text/html},
}

@article{secunda_evaluation_2021,
	title = {Evaluation of automated specialty palliative care in the intensive care unit: {A} retrospective cohort study},
	volume = {16},
	issn = {1932-6203},
	shorttitle = {Evaluation of automated specialty palliative care in the intensive care unit},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0255989},
	doi = {10.1371/journal.pone.0255989},
	abstract = {Introduction Automated specialty palliative care consultation (SPC) has been proposed as an intervention to improve patient-centered care in the intensive care unit (ICU). Existing automated SPC trigger criteria are designed to identify patients at highest risk of in-hospital death. We sought to evaluate common mortality-based SPC triggers and determine whether these triggers reflect actual use of SPC consultation. We additionally aimed to characterize the population of patients who receive SPC without meeting mortality-based triggers. Methods We conducted a retrospective cohort study of all adult ICU admissions from 2012–2017 at an academic medical center with five subspecialty ICUs to determine the sensitivity and specificity of the five most common SPC triggers for predicting receipt of SPC. Among ICU admissions receiving SPC, we assessed differences in patients who met any SPC trigger compared to those who met none. Results Of 48,744 eligible admissions, 1,965 (4.03\%) received SPC; 979 (49.82\%) of consultations met at least 1 trigger. The sensitivity and specificity for any trigger predicting SPC was 49.82\% and 79.61\%, respectively. Patients who met no triggers but received SPC were younger (62.71 years vs 66.58 years, mean difference (MD) 3.87 years (95\% confidence interval (CI) 2.44–5.30) p{\textless}0.001), had longer ICU length of stay (11.43 days vs 8.42 days, MD -3.01 days (95\% CI -4.30 –-1.72) p{\textless}0.001), and had a lower rate of in-hospital death (48.68\% vs 58.12\%, p{\textless}0.001). Conclusion Mortality-based triggers for specialty palliative care poorly reflect actual use of SPC in the ICU. Reliance on such triggers may unintentionally overlook an important population of patients with clinician-identified palliative care needs.},
	language = {en},
	number = {8},
	urldate = {2024-10-27},
	journal = {PLOS ONE},
	author = {Secunda, Katharine E. and Krolikowski, Kristyn A. and Savage, Madeline F. and Kruser, Jacqueline M.},
	month = aug,
	year = {2021},
	note = {Publisher: Public Library of Science},
	keywords = {Electronic medical records, Palliative care, Medical risk factors, Cardiology, Cohort studies, Health care facilities, Hospitals, Intensive care units},
	pages = {e0255989},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/BLDBYLZL/Secunda et al. - 2021 - Evaluation of automated specialty palliative care in the intensive care unit A retrospective cohort.pdf:application/pdf},
}

@misc{baksi_medcoder_2024,
	title = {{MedCodER}: {A} {Generative} {AI} {Assistant} for {Medical} {Coding}},
	shorttitle = {{MedCodER}},
	url = {http://arxiv.org/abs/2409.15368},
	abstract = {Medical coding is essential for standardizing clinical data and communication but is often time-consuming and prone to errors. Traditional Natural Language Processing (NLP) methods struggle with automating coding due to the large label space, lengthy text inputs, and the absence of supporting evidence annotations that justify code selection. Recent advancements in Generative Artificial Intelligence (AI) offer promising solutions to these challenges. In this work, we introduce MedCodER, a Generative AI framework for automatic medical coding that leverages extraction, retrieval, and re-ranking techniques as core components. MedCodER achieves a micro-F1 score of 0.60 on International Classification of Diseases (ICD) code prediction, significantly outperforming state-of-the-art methods. Additionally, we present a new dataset containing medical records annotated with disease diagnoses, ICD codes, and supporting evidence texts (https://doi.org/10.5281/zenodo.13308316). Ablation tests confirm that MedCodER's performance depends on the integration of each of its aforementioned components, as performance declines when these components are evaluated in isolation.},
	urldate = {2024-10-24},
	publisher = {arXiv},
	author = {Baksi, Krishanu Das and Soba, Elijah and Higgins, John J. and Saini, Ravi and Wood, Jaden and Cook, Jane and Scott, Jack and Pudota, Nirmala and Weninger, Tim and Bowen, Edward and Bhattacharya, Sanmitra},
	month = sep,
	year = {2024},
	note = {arXiv:2409.15368},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Emerging Technologies},
	file = {2409.15368v1.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/TWJBQLYW/2409.15368v1.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/FWXXJL36/2409.html:text/html},
}

@article{yim_aci-bench_2023,
	title = {Aci-bench: a {Novel} {Ambient} {Clinical} {Intelligence} {Dataset} for {Benchmarking} {Automatic} {Visit} {Note} {Generation}},
	volume = {10},
	copyright = {2023 The Author(s)},
	issn = {2052-4463},
	shorttitle = {Aci-bench},
	url = {https://www.nature.com/articles/s41597-023-02487-3},
	doi = {10.1038/s41597-023-02487-3},
	abstract = {Recent immense breakthroughs in generative models such as in GPT4 have precipitated re-imagined ubiquitous usage of these models in all applications. One area that can benefit by improvements in artificial intelligence (AI) is healthcare. The note generation task from doctor-patient encounters, and its associated electronic medical record documentation, is one of the most arduous time-consuming tasks for physicians. It is also a natural prime potential beneficiary to advances in generative models. However with such advances, benchmarking is more critical than ever. Whether studying model weaknesses or developing new evaluation metrics, shared open datasets are an imperative part of understanding the current state-of-the-art. Unfortunately as clinic encounter conversations are not routinely recorded and are difficult to ethically share due to patient confidentiality, there are no sufficiently large clinic dialogue-note datasets to benchmark this task. Here we present the Ambient Clinical Intelligence Benchmark (aci-bench) corpus, the largest dataset to date tackling the problem of AI-assisted note generation from visit dialogue. We also present the benchmark performances of several common state-of-the-art approaches.},
	language = {en},
	number = {1},
	urldate = {2024-10-24},
	journal = {Scientific Data},
	author = {Yim, Wen-wai and Fu, Yujuan and Ben Abacha, Asma and Snider, Neal and Lin, Thomas and Yetisgen, Meliha},
	month = sep,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Health care, Research data, Technology},
	pages = {586},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PQJ6A97G/Yim et al. - 2023 - Aci-bench a Novel Ambient Clinical Intelligence Dataset for Benchmarking Automatic Visit Note Gener.pdf:application/pdf},
}

@article{fawcett_introduction_2006,
	title = {An introduction to {ROC} analysis},
	volume = {27},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016786550500303X},
	doi = {10.1016/j.patrec.2005.10.010},
	abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classiﬁers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
	language = {en},
	number = {8},
	urldate = {2024-10-24},
	journal = {Pattern Recognition Letters},
	author = {Fawcett, Tom},
	month = jun,
	year = {2006},
	pages = {861--874},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/ML2QYBUY/Fawcett - 2006 - An introduction to ROC analysis.pdf:application/pdf},
}

@article{wilson_effect_2023,
	title = {Effect of an {Artificial} {Intelligence} {Decision} {Support} {Tool} on {Palliative} {Care} {Referral} in {Hospitalized} {Patients}: {A} {Randomized} {Clinical} {Trial}},
	volume = {66},
	issn = {0885-3924},
	shorttitle = {Effect of an {Artificial} {Intelligence} {Decision} {Support} {Tool} on {Palliative} {Care} {Referral} in {Hospitalized} {Patients}},
	url = {https://www.sciencedirect.com/science/article/pii/S0885392423003974},
	doi = {10.1016/j.jpainsymman.2023.02.317},
	abstract = {Context
Palliative care services are commonly provided to hospitalized patients, but accurately predicting who needs them remains a challenge.
Objectives
To assess the effectiveness on clinical outcomes of an artificial intelligence (AI)/machine learning (ML) decision support tool for predicting patient need for palliative care services in the hospital.
Methods
The study design was a pragmatic, cluster-randomized, stepped-wedge clinical trial in 12 nursing units at two hospitals over a 15-month period between August 19, 2019, and November 17, 2020. Eligible patients were randomly assigned to either a medical service consultation recommendation triggered by an AI/ML tool predicting the need for palliative care services or usual care. The primary outcome was palliative care consultation note. Secondary outcomes included: hospital readmissions, length of stay, transfer to intensive care and palliative care consultation note by unit.
Results
A total of 3183 patient hospitalizations were enrolled. Of eligible patients, A total of 2544 patients were randomized to the decision support tool (1212; 48\%) and usual care (1332; 52\%). Of these, 1717 patients (67\%) were retained for analyses. Patients randomized to the intervention had a statistically significant higher incidence rate of palliative care consultation compared to the control group (IRR, 1.44 [95\% CI, 1.11–1.92]). Exploratory evidence suggested that the decision support tool group reduced 60-day and 90-day hospital readmissions (OR, 0.75 [95\% CI, 0.57, 0.97]) and (OR, 0.72 [95\% CI, 0.55–0.93]) respectively.
Conclusion
A decision support tool integrated into palliative care practice and leveraging AI/ML demonstrated an increased palliative care consultation rate among hospitalized patients and reductions in hospitalizations.},
	number = {1},
	urldate = {2024-10-17},
	journal = {Journal of Pain and Symptom Management},
	author = {Wilson, Patrick M. and Ramar, Priya and Philpot, Lindsey M. and Soleimani, Jalal and Ebbert, Jon O. and Storlie, Curtis B. and Morgan, Alisha A. and Schaeferle, Gavin M. and Asai, Shusaku W. and Herasevich, Vitaly and Pickering, Brian W. and Tiong, Ing C. and Olson, Emily A. and Karow, Jordan C. and Pinevich, Yuliya and Strand, Jacob},
	month = jul,
	year = {2023},
	keywords = {Artificial intelligence (AI), EHR, Inpatient palliative care, Machine learning (ML), Pragmatic clinical trials},
	pages = {24--32},
	file = {1-s2.0-S0885392423003974-main.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/V7HIMUUF/1-s2.0-S0885392423003974-main.pdf:application/pdf;PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JA8X5J44/Wilson et al. - 2023 - Effect of an Artificial Intelligence Decision Support Tool on Palliative Care Referral in Hospitaliz.pdf:application/pdf;ScienceDirect Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/2DUGKGBS/S0885392423003974.html:text/html},
}

@article{chi_advanced_2023-1,
	title = {Advanced {Care} {Planning} for {Hospitalized} {Patients} {Following} {Clinician} {Notification} of {Patient} {Mortality} by a {Machine} {Learning} {Algorithm}},
	volume = {6},
	issn = {2574-3805},
	url = {https://doi.org/10.1001/jamanetworkopen.2023.8795},
	doi = {10.1001/jamanetworkopen.2023.8795},
	abstract = {Goal-concordant care is an ongoing challenge in hospital settings. Identification of high mortality risk within 30 days may call attention to the need to have serious illness conversations, including the documentation of patient goals of care.To examine goals of care discussions (GOCDs) in a community hospital setting with patients identified as having a high risk of mortality by a machine learning mortality prediction algorithm.This cohort study took place at community hospitals within 1 health care system. Participants included adult patients with a high risk of 30-day mortality who were admitted to 1 of 4 hospitals between January 2 and July 15, 2021. Patient encounters of inpatients in the intervention hospital where physicians were notified of the computed high risk mortality score were compared with patient encounters of inpatients in 3 community hospitals without the intervention (ie, matched control).Physicians of patients with a high risk of mortality within 30 days received notification and were encouraged to arrange for GOCDs.The primary outcome was the percentage change of documented GOCDs prior to discharge. Propensity-score matching was completed on a preintervention and postintervention period using age, sex, race, COVID-19 status, and machine learning-predicted mortality risk scores. A difference-in-difference analysis validated the results.Overall, 537 patients were included in this study with 201 in the preintervention period (94 in the intervention group; 104 in the control group) and 336 patients in the postintervention period. The intervention and control groups included 168 patients per group and were well-balanced in age (mean [SD], 79.3 [9.60] vs 79.6 [9.21] years; standardized mean difference [SMD], 0.03), sex (female, 85 [51\%] vs 85 [51\%]; SMD, 0), race (White patients, 145 [86\%] vs 144 [86\%]; SMD 0.006), and Charlson comorbidities (median [range], 8.00 [2.00-15.0] vs 9.00 [2.00 to 19.0]; SMD, 0.34). Patients in the intervention group from preintervention to postintervention period were associated with being 5 times more likely to have documented GOCDs (OR, 5.11 [95\% CI, 1.93 to 13.42]; P = .001) by discharge compared with matched controls, and GOCD occurred significantly earlier in the hospitalization in the intervention patients as compared with matched controls (median, 4 [95\% CI, 3 to 6] days vs 16 [95\% CI, 15 to not applicable] days; P \&lt; .001). Similar findings were observed for Black patient and White patient subgroups.In this cohort study, patients whose physicians had knowledge of high-risk predictions from machine learning mortality algorithms were associated with being 5 times more likely to have documented GOCDs than matched controls. Additional external validation is needed to determine if similar interventions would be helpful at other institutions.},
	number = {4},
	urldate = {2024-10-17},
	journal = {JAMA Network Open},
	author = {Chi, Stephen and Kim, Seunghwan and Reuter, Matthew and Ponzillo, Katharine and Oliver, Debra Parker and Foraker, Randi and Heard, Kevin and Liu, Jingxia and Pitzer, Kyle and White, Patrick and Moore, Nathan},
	month = apr,
	year = {2023},
	pages = {e238795},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/77C6K42B/Chi et al. - 2023 - Advanced Care Planning for Hospitalized Patients Following Clinician Notification of Patient Mortali.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/TE72LJR4/2803939.html:text/html},
}

@misc{schlichtkrull_generating_2024,
	title = {Generating {Media} {Background} {Checks} for {Automated} {Source} {Critical} {Reasoning}},
	url = {http://arxiv.org/abs/2409.00781},
	abstract = {Not everything on the internet is true. This unfortunate fact requires both humans and models to perform complex reasoning about credibility when working with retrieved information. In NLP, this problem has seen little attention. Indeed, retrieval-augmented models are not typically expected to distrust retrieved documents. Human experts overcome the challenge by gathering signals about the context, reliability, and tendency of source documents - that is, they perform source criticism. We propose a novel NLP task focused on finding and summarising such signals. We introduce a new dataset of 6,709 "media background checks" derived from Media Bias / Fact Check, a volunteer-run website documenting media bias. We test open-source and closed-source LLM baselines with and without retrieval on this dataset, finding that retrieval greatly improves performance. We furthermore carry out human evaluation, demonstrating that 1) media background checks are helpful for humans, and 2) media background checks are helpful for retrieval-augmented models.},
	urldate = {2024-10-10},
	publisher = {arXiv},
	author = {Schlichtkrull, Michael},
	month = sep,
	year = {2024},
	note = {arXiv:2409.00781},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/4ZTGFD5E/Schlichtkrull - 2024 - Generating Media Background Checks for Automated S.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/WDX74WE9/2409.html:text/html},
}

@article{murphree_improving_2021,
	title = {Improving the delivery of palliative care through predictive modeling and healthcare informatics},
	volume = {28},
	issn = {1527-974X},
	url = {https://doi.org/10.1093/jamia/ocaa211},
	doi = {10.1093/jamia/ocaa211},
	abstract = {Access to palliative care (PC) is important for many patients with uncontrolled symptom burden from serious or complex illness. However, many patients who could benefit from PC do not receive it early enough or at all. We sought to address this problem by building a predictive model into a comprehensive clinical framework with the aims to (i) identify in-hospital patients likely to benefit from a PC consult, and (ii) intervene on such patients by contacting their care team.Electronic health record data for 68 349 inpatient encounters in 2017 at a large hospital were used to train a model to predict the need for PC consult. This model was published as a web service, connected to institutional data pipelines, and consumed by a downstream display application monitored by the PC team. For those patients that the PC team deems appropriate, a team member then contacts the patient’s corresponding care team.Training performance AUC based on a 20\% holdout validation set was 0.90. The most influential variables were previous palliative care, hospital unit, Albumin, Troponin, and metastatic cancer. The model has been successfully integrated into the clinical workflow making real-time predictions on hundreds of patients per day. The model had an “in-production” AUC of 0.91. A clinical trial is currently underway to assess the effect on clinical outcomes.A machine learning model can effectively predict the need for an inpatient PC consult and has been successfully integrated into practice to refer new patients to PC.},
	number = {6},
	urldate = {2024-10-01},
	journal = {Journal of the American Medical Informatics Association},
	author = {Murphree, Dennis H and Wilson, Patrick M and Asai, Shusaku W and Quest, Daniel J and Lin, Yaxiong and Mukherjee, Piyush and Chhugani, Nirmal and Strand, Jacob J and Demuth, Gabriel and Mead, David and Wright, Brian and Harrison, Andrew and Soleimani, Jalal and Herasevich, Vitaly and Pickering, Brian W and Storlie, Curtis B},
	month = jun,
	year = {2021},
	pages = {1065--1073},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/D4YFXS6T/Murphree et al. - 2021 - Improving the delivery of palliative care through .pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DCPRSTXK/6145883.html:text/html},
}

@article{murray_global_2020,
	title = {Global burden of 87 risk factors in 204 countries and territories, 1990–2019: a systematic analysis for the {Global} {Burden} of {Disease} {Study} 2019},
	volume = {396},
	issn = {0140-6736, 1474-547X},
	shorttitle = {Global burden of 87 risk factors in 204 countries and territories, 1990–2019},
	url = {https://www.thelancet.com/journals/lancet/article/piis0140-6736(20)30752-2/fulltext},
	doi = {10.1016/S0140-6736(20)30752-2},
	language = {English},
	number = {10258},
	urldate = {2024-09-16},
	journal = {The Lancet},
	author = {Murray, Christopher J. L. and Aravkin, Aleksandr Y. and Zheng, Peng and Abbafati, Cristiana and Abbas, Kaja M. and Abbasi-Kangevari, Mohsen and Abd-Allah, Foad and Abdelalim, Ahmed and Abdollahi, Mohammad and Abdollahpour, Ibrahim and Abegaz, Kedir Hussein and Abolhassani, Hassan and Aboyans, Victor and Abreu, Lucas Guimarães and Abrigo, Michael R. M. and Abualhasan, Ahmed and Abu-Raddad, Laith Jamal and Abushouk, Abdelrahman I. and Adabi, Maryam and Adekanmbi, Victor and Adeoye, Abiodun Moshood and Adetokunboh, Olatunji O. and Adham, Davoud and Advani, Shailesh M. and Agarwal, Gina and Aghamir, Seyed Mohammad Kazem and Agrawal, Anurag and Ahmad, Tauseef and Ahmadi, Keivan and Ahmadi, Mehdi and Ahmadieh, Hamid and Ahmed, Muktar Beshir and Akalu, Temesgen Yihunie and Akinyemi, Rufus Olusola and Akinyemiju, Tomi and Akombi, Blessing and Akunna, Chisom Joyqueenet and Alahdab, Fares and Al-Aly, Ziyad and Alam, Khurshid and Alam, Samiah and Alam, Tahiya and Alanezi, Fahad Mashhour and Alanzi, Turki M. and Alemu, Biresaw wassihun and Alhabib, Khalid F. and Ali, Muhammad and Ali, Saqib and Alicandro, Gianfranco and Alinia, Cyrus and Alipour, Vahid and Alizade, Hesam and Aljunid, Syed Mohamed and Alla, François and Allebeck, Peter and Almasi-Hashiani, Amir and Al-Mekhlafi, Hesham M. and Alonso, Jordi and Altirkawi, Khalid A. and Amini-Rarani, Mostafa and Amiri, Fatemeh and Amugsi, Dickson A. and Ancuceanu, Robert and Anderlini, Deanna and Anderson, Jason A. and Andrei, Catalina Liliana and Andrei, Tudorel and Angus, Colin and Anjomshoa, Mina and Ansari, Fereshteh and Ansari-Moghaddam, Alireza and Antonazzo, Ippazio Cosimo and Antonio, Carl Abelardo T. and Antony, Catherine M. and Antriyandarti, Ernoiz and Anvari, Davood and Anwer, Razique and Appiah, Seth Christopher Yaw and Arabloo, Jalal and Arab-Zozani, Morteza and Ariani, Filippo and Armoon, Bahram and Ärnlöv, Johan and Arzani, Afsaneh and Asadi-Aliabadi, Mehran and Asadi-Pooya, Ali A. and Ashbaugh, Charlie and Assmus, Michael and Atafar, Zahra and Atnafu, Desta Debalkie and Atout, Maha Moh'd Wahbi and Ausloos, Floriane and Ausloos, Marcel and Quintanilla, Beatriz Paulina Ayala and Ayano, Getinet and Ayanore, Martin Amogre and Azari, Samad and Azarian, Ghasem and Azene, Zelalem Nigussie and Badawi, Alaa and Badiye, Ashish D. and Bahrami, Mohammad Amin and Bakhshaei, Mohammad Hossein and Bakhtiari, Ahad and Bakkannavar, Shankar M. and Baldasseroni, Alberto and Ball, Kylie and Ballew, Shoshana H. and Balzi, Daniela and Banach, Maciej and Banerjee, Srikanta K. and Bante, Agegnehu Bante and Baraki, Adhanom Gebreegziabher and Barker-Collo, Suzanne Lyn and Bärnighausen, Till Winfried and Barrero, Lope H. and Barthelemy, Celine M. and Barua, Lingkan and Basu, Sanjay and Baune, Bernhard T. and Bayati, Mohsen and Becker, Jacob S. and Bedi, Neeraj and Beghi, Ettore and Béjot, Yannick and Bell, Michellr L. and Bennitt, Fiona B. and Bensenor, Isabela M. and Berhe, Kidanemaryam and Berman, Adam E. and Bhagavathula, Akshaya Srikanth and Bhageerathy, Reshmi and Bhala, Neeraj and Bhandari, Dinesh and Bhattacharyya, Krittika and Bhutta, Zulfiqar A. and Bijani, Ali and Bikbov, Boris and Sayeed, Muhammad Shahdaat Bin and Biondi, Antonio and Birihane, Binyam Minuye and Bisignano, Catherine and Biswas, Raaj Kishore and Bitew, Helen and Bohlouli, Somayeh and Bohluli, Mehdi and Boon-Dooley, Alexandra S. and Borges, Guilherme and Borzì, Antonio Maria and Borzouei, Shiva and Bosetti, Cristina and Boufous, Soufiane and Braithwaite, Dejana and Breitborde, Nicholas J. K. and Breitner, Susanne and Brenner, Hermann and Briant, Paul Svitil and Briko, Andrey Nikolaevich and Briko, Nikolay Ivanovich and Britton, Gabrielle B. and Bryazka, Dana and Bumgarner, Blair R. and Burkart, Katrin and Burnett, Richard Thomas and Nagaraja, Sharath Burugina and Butt, Zahid A. and Santos, Florentino Luciano Caetano dos and Cahill, Leah E. and Cámera, Luis LA Alberto and Campos-Nonato, Ismael R. and Cárdenas, Rosario and Carreras, Giulia and Carrero, Juan J. and Carvalho, Felix and Castaldelli-Maia, Joao Mauricio and Castañeda-Orjuela, Carlos A. and Castelpietra, Giulio and Castro, Franz and Causey, Kate and Cederroth, Christopher R. and Cercy, Kelly M. and Cerin, Ester and Chandan, Joht Singh and Chang, Kai-Lan and Charlson, Fiona J. and Chattu, Vijay Kumar and Chaturvedi, Sarika and Cherbuin, Nicolas and Chimed-Ochir, Odgerel and Cho, Daniel Youngwhan and Choi, Jee-Young Jasmine and Christensen, Hanne and Chu, Dinh-Toi and Chung, Michael T. and Chung, Sheng-Chia and Cicuttini, Flavia M. and Ciobanu, Liliana G. and Cirillo, Massimo and Classen, Thomas Khaled Dwayne and Cohen, Aaron J. and Compton, Kelly and Cooper, Owen R. and Costa, Vera Marisa and Cousin, Ewerton and Cowden, Richard G. and Cross, Di H. and Cruz, Jessica A. and Dahlawi, Saad M. A. and Damasceno, Albertino Antonio Moura and Damiani, Giovanni and Dandona, Lalit and Dandona, Rakhi and Dangel, William James and Danielsson, Anna-Karin and Dargan, Paul I. and Darwesh, Aso Mohammad and Daryani, Ahmad and Das, Jai K. and Gupta, Rajat Das and Neves, José das and Dávila-Cervantes, Claudio Alberto and Davitoiu, Dragos Virgil and Leo, Diego De and Degenhardt, Louisa and DeLang, Marissa and Dellavalle, Robert Paul and Demeke, Feleke Mekonnen and Demoz, Gebre Teklemariam and Demsie, Desalegn Getnet and Denova-Gutiérrez, Edgar and Dervenis, Nikolaos and Dhungana, Govinda Prasad and Dianatinasab, Mostafa and Silva, Diana Dias da and Diaz, Daniel and Forooshani, Zahra Sadat Dibaji and Djalalinia, Shirin and Do, Hoa Thi and Dokova, Klara and Dorostkar, Fariba and Doshmangir, Leila and Driscoll, Tim Robert and Duncan, Bruce B. and Duraes, Andre Rodrigues and Eagan, Arielle Wilder and Edvardsson, David and Nahas, Nevine El and Sayed, Iman El and Tantawi, Maha El and Elbarazi, Iffat and Elgendy, Islam Y. and El-Jaafary, Shaimaa I. and Elyazar, Iqbal RF and Emmons-Bell, Sophia and Erskine, Holly E. and Eskandarieh, Sharareh and Esmaeilnejad, Saman and Esteghamati, Alireza and Estep, Kara and Etemadi, Arash and Etisso, Atkilt Esaiyas and Fanzo, Jessica and Farahmand, Mohammad and Fareed, Mohammad and Faridnia, Roghiyeh and Farioli, Andrea and Faro, Andre and Faruque, Mithila and Farzadfar, Farshad and Fattahi, Nazir and Fazlzadeh, Mehdi and Feigin, Valery L. and Feldman, Rachel and Fereshtehnejad, Seyed-Mohammad and Fernandes, Eduarda and Ferrara, Giannina and Ferrari, Alize J. and Ferreira, Manuela L. and Filip, Irina and Fischer, Florian and Fisher, James L. and Flor, Luisa Sorio and Foigt, Nataliya A. and Folayan, Morenike Oluwatoyin and Fomenkov, Artem Alekseevich and Force, Lisa M. and Foroutan, Masoud and Franklin, Richard Charles and Freitas, Marisa and Fu, Weijia and Fukumoto, Takeshi and Furtado, João M. and Gad, Mohamed M. and Gakidou, Emmanuela and Gallus, Silvano and Garcia-Basteiro, Alberto L. and Gardner, William M. and Geberemariyam, Biniyam Sahiledengle and Gebreslassie, Assefa Ayalew Ayalew Ayalew and Geremew, Abraham and Hayoon, Anna Gershberg and Gething, Peter W. and Ghadimi, Maryam and Ghadiri, Keyghobad and Ghaffarifar, Fatemeh and Ghafourifard, Mansour and Ghamari, Farhad and Ghashghaee, Ahmad and Ghiasvand, Hesam and Ghith, Nermin and Gholamian, Asadollah and Ghosh, Rakesh and Gill, Paramjit Singh and Ginindza, Themba G. G. and Giussani, Giorgia and Gnedovskaya, Elena V. and Goharinezhad, Salime and Gopalani, Sameer Vali and Gorini, Giuseppe and Goudarzi, Houman and Goulart, Alessandra C. and Greaves, Felix and Grivna, Michal and Grosso, Giuseppe and Gubari, Mohammed Ibrahim Mohialdeen and Gugnani, Harish Chander and Guimarães, Rafael Alves and Guled, Rashid Abdi and Guo, Gaorui and Guo, Yuming and Gupta, Rajeev and Gupta, Tarun and Haddock, Beatrix and Hafezi-Nejad, Nima and Hafiz, Abdul and Haj-Mirzaian, Arvin and Haj-Mirzaian, Arya and Hall, Brian J. and Halvaei, Iman and Hamadeh, Randah R. and Hamidi, Samer and Hammer, Melanie S. and Hankey, Graeme J. and Haririan, Hamidreza and Haro, Josep Maria and Hasaballah, Ahmed I. and Hasan, Md Mehedi and Hasanpoor, Edris and Hashi, Abdiwahab and Hassanipour, Soheil and Hassankhani, Hadi and Havmoeller, Rasmus J. and Hay, Simon I. and Hayat, Khezar and Heidari, Golnaz and Heidari-Soureshjani, Reza and Henrikson, Hannah J. and Herbert, Molly E. and Herteliu, Claudiu and Heydarpour, Fatemeh and Hird, Thomas R. and Hoek, Hans W. and Holla, Ramesh and Hoogar, Praveen and Hosgood, H. Dean and Hossain, Naznin and Hosseini, Mostafa and Hosseinzadeh, Mehdi and Hostiuc, Mihaela and Hostiuc, Sorin and Househ, Mowafa and Hsairi, Mohamed and Hsieh, Vivian Chia-rong and Hu, Guoqing and Hu, Kejia and Huda, Tanvir M. and Humayun, Ayesha and Huynh, Chantal K. and Hwang, Bing-Fang and Iannucci, Vincent C. and Ibitoye, Segun Emmanuel and Ikeda, Nayu and Ikuta, Kevin S. and Ilesanmi, Olayinka Stephen and Ilic, Irena M. and Ilic, Milena D. and Inbaraj, Leeberk Raja and Ippolito, Helen and Iqbal, Usman and Irvani, Seyed Sina Naghibi and Irvine, Caleb Mackay Salpeter and Islam, M. Mofizul and Islam, Sheikh Mohammed Shariful and Iso, Hiroyasu and Ivers, Rebecca Q. and Iwu, Chidozie C. D. and Iwu, Chinwe Juliana and Iyamu, Ihoghosa Osamuyi and Jaafari, Jalil and Jacobsen, Kathryn H. and Jafari, Hussain and Jafarinia, Morteza and Jahani, Mohammad Ali and Jakovljevic, Mihajlo and Jalilian, Farzad and James, Spencer L. and Janjani, Hosna and Javaheri, Tahereh and Javidnia, Javad and Jeemon, Panniyammakal and Jenabi, Ensiyeh and Jha, Ravi Prakash and Jha, Vivekanand and Ji, John S. and Johansson, Lars and John, Oommen and John-Akinola, Yetunde O. and Johnson, Catherine Owens and Jonas, Jost B. and Joukar, Farahnaz and Jozwiak, Jacek Jerzy and Jürisson, Mikk and Kabir, Ali and Kabir, Zubair and Kalani, Hamed and Kalani, Rizwan and Kalankesh, Leila R. and Kalhor, Rohollah and Kanchan, Tanuj and Kapoor, Neeti and Matin, Behzad Karami and Karch, André and Karim, Mohd Anisul and Kassa, Getachew Mullu and Katikireddi, Srinivasa Vittal and Kayode, Gbenga A. and Karyani, Ali Kazemi and Keiyoro, Peter Njenga and Keller, Cathleen and Kemmer, Laura and Kendrick, Parkes J. and Khalid, Nauman and Khammarnia, Mohammad and Khan, Ejaz Ahmad and Khan, Maseer and Khatab, Khaled and Khater, Mona M. and Khatib, Mahalaqua Nazli and Khayamzadeh, Maryam and Khazaei, Salman and Kieling, Christian and Kim, Yun Jin and Kimokoti, Ruth W. and Kisa, Adnan and Kisa, Sezer and Kivimäki, Mika and Knibbs, Luke D. and Knudsen, Ann Kristin Skrindo and Kocarnik, Jonathan M. and Kochhar, Sonali and Kopec, Jacek A. and Korshunov, Vladimir Andreevich and Koul, Parvaiz A. and Koyanagi, Ai and Kraemer, Moritz U. G. and Krishan, Kewal and Krohn, Kris J. and Kromhout, Hans and Defo, Barthelemy Kuate and Kumar, G. Anil and Kumar, Vivek and Kurmi, Om P. and Kusuma, Dian and Vecchia, Carlo La and Lacey, Ben and Lal, Dharmesh Kumar and Lalloo, Ratilal and Lallukka, Tea and Lami, Faris Hasan and Landires, Iván and Lang, Justin J. and Langan, Sinéad M. and Larsson, Anders O. and Lasrado, Savita and Lauriola, Paolo and Lazarus, Jeffrey V. and Lee, Paul H. and Lee, Shaun Wen Huey and LeGrand, Kate E. and Leigh, James and Leonardi, Matilde and Lescinsky, Haley and Leung, Janni and Levi, Miriam and Li, Shanshan and Lim, Lee-Ling and Linn, Shai and Liu, Shiwei and Liu, Simin and Liu, Yang and Lo, Justin and Lopez, Alan D. and Lopez, Jaifred Christian F. and Lopukhov, Platon D. and Lorkowski, Stefan and Lotufo, Paulo A. and Lu, Alton and Lugo, Alessandra and Maddison, Emilie R. and Mahasha, Phetole Walter and Mahdavi, Mokhtar Mahdavi and Mahmoudi, Morteza and Majeed, Azeem and Maleki, Afshin and Maleki, Shokofeh and Malekzadeh, Reza and Malta, Deborah Carvalho and Mamun, Abdullah A. and Manda, Ana Laura and Manguerra, Helena and Mansour-Ghanaei, Fariborz and Mansouri, Borhan and Mansournia, Mohammad Ali and Herrera, Ana M. Mantilla and Maravilla, Joemer C. and Marks, Ashley and Martin, Randall V. and Martini, Santi and Martins-Melo, Francisco Rogerlândio and Masaka, Anthony and Masoumi, Seyedeh Zahra and Mathur, Manu Raj and Matsushita, Kunihiro and Maulik, Pallab K. and McAlinden, Colm and McGrath, John J. and McKee, Martin and Mehndiratta, Man Mohan and Mehri, Fereshteh and Mehta, Kala M. and Memish, Ziad A. and Mendoza, Walter and Menezes, Ritesh G. and Mengesha, Endalkachew Worku and Mereke, Alibek and Mereta, Seid Tiku and Meretoja, Atte and Meretoja, Tuomo J. and Mestrovic, Tomislav and Miazgowski, Bartosz and Miazgowski, Tomasz and Michalek, Irmina Maria and Miller, Ted R. and Mills, Edward J. and Mini, G. K. and Miri, Mohammad and Mirica, Andreea and Mirrakhimov, Erkin M. and Mirzaei, Hamed and Mirzaei, Maryam and Mirzaei, Roya and Mirzaei-Alavijeh, Mehdi and Misganaw, Awoke Temesgen and Mithra, Prasanna and Moazen, Babak and Mohammad, Dara K. and Mohammad, Yousef and Mezerji, Naser Mohammad Gholi and Mohammadian-Hafshejani, Abdollah and Mohammadifard, Noushin and Mohammadpourhodki, Reza and Mohammed, Ammas Siraj and Mohammed, Hussen and Mohammed, Jemal Abdu and Mohammed, Shafiu and Mokdad, Ali H. and Molokhia, Mariam and Monasta, Lorenzo and Mooney, Meghan D. and Moradi, Ghobad and Moradi, Masoud and Moradi-Lakeh, Maziar and Moradzadeh, Rahmatollah and Moraga, Paula and Morawska, Lidia and Morgado-da-Costa, Joana and Morrison, Shane Douglas and Mosapour, Abbas and Mosser, Jonathan F. and Mouodi, Simin and Mousavi, Seyyed Meysam and Khaneghah, Amin Mousavi and Mueller, Ulrich Otto and Mukhopadhyay, Satinath and Mullany, Erin C. and Musa, Kamarul Imran and Muthupandian, Saravanan and Nabhan, Ashraf F. and Naderi, Mehdi and Nagarajan, Ahamarshan Jayaraman and Nagel, Gabriele and Naghavi, Mohsen and Naghshtabrizi, Behshad and Naimzada, Mukhammad David and Najafi, Farid and Nangia, Vinay and Nansseu, Jobert Richie and Naserbakht, Morteza and Nayak, Vinod C. and Negoi, Ionut and Ngunjiri, Josephine W. and Nguyen, Cuong Tat and Nguyen, Huong Lan Thi and Nguyen, Minh and Nigatu, Yeshambel T. and Nikbakhsh, Rajan and Nixon, Molly R. and Nnaji, Chukwudi A. and Nomura, Shuhei and Norrving, Bo and Noubiap, Jean Jacques and Nowak, Christoph and Nunez-Samudio, Virginia and Oţoiu, Adrian and Oancea, Bogdan and Odell, Christopher M. and Ogbo, Felix Akpojene and Oh, In-Hwan and Okunga, Emmanuel Wandera and Oladnabi, Morteza and Olagunju, Andrew T. and Olusanya, Bolajoko Olubukunola and Olusanya, Jacob Olusegun and Omer, Muktar Omer and Ong, Kanyin L. and Onwujekwe, Obinna E. and Orpana, Heather M. and Ortiz, Alberto and Osarenotor, Osayomwanbo and Osei, Frank B. and Ostroff, Samuel M. and Otstavnov, Nikita and Otstavnov, Stanislav S. and Øverland, Simon and Owolabi, Mayowa O. and A, Mahesh P. and Padubidri, Jagadish Rao and Palladino, Raffaele and Panda-Jonas, Songhomitra and Pandey, Anamika and Parry, Charles D. H. and Pasovic, Maja and Pasupula, Deepak Kumar and Patel, Sangram Kishor and Pathak, Mona and Patten, Scott B. and Patton, George C. and Toroudi, Hamidreza Pazoki and Peden, Amy E. and Pennini, Alyssa and Pepito, Veincent Christian Filipino and Peprah, Emmanuel K. and Pereira, David M. and Pesudovs, Konrad and Pham, Hai Quang and Phillips, Michael R. and Piccinelli, Cristiano and Pilz, Tessa M. and Piradov, Michael A. and Pirsaheb, Meghdad and Plass, Dietrich and Polinder, Suzanne and Polkinghorne, Kevan R. and Pond, Constance Dimity and Postma, Maarten J. and Pourjafar, Hadi and Pourmalek, Farshad and Poznańska, Anna and Prada, Sergio I. and Prakash, V. and Pribadi, Dimas Ria Angga and Pupillo, Elisabetta and Syed, Zahiruddin Quazi and Rabiee, Mohammad and Rabiee, Navid and Radfar, Amir and Rafiee, Ata and Raggi, Alberto and Rahman, Muhammad Aziz and Rajabpour-Sanati, Ali and Rajati, Fatemeh and Rakovac, Ivo and Ram, Pradhum and Ramezanzadeh, Kiana and Ranabhat, Chhabi Lal and Rao, Puja C. and Rao, Sowmya J. and Rashedi, Vahid and Rathi, Priya and Rawaf, David Laith and Rawaf, Salman and Rawal, Lal and Rawassizadeh, Reza and Rawat, Ramu and Razo, Christian and Redford, Sofia Boston and Reiner, Robert C. and Reitsma, Marissa Bettay and Remuzzi, Giuseppe and Renjith, Vishnu and Renzaho, Andre M. N. and Resnikoff, Serge and Rezaei, Negar and Rezaei, Nima and Rezapour, Aziz and Rhinehart, Phoebe-Anne and Riahi, Seyed Mohammad and Ribeiro, Daniel Cury and Ribeiro, Daniela and Rickard, Jennifer and Rivera, Juan A. and Roberts, Nicholas L. S. and Rodríguez-Ramírez, Sonia and Roever, Leonardo and Ronfani, Luca and Room, Robin and Roshandel, Gholamreza and Roth, Gregory A. and Rothenbacher, Dietrich and Rubagotti, Enrico and Rwegerera, Godfrey M. and Sabour, Siamak and Sachdev, Perminder S. and Saddik, Basema and Sadeghi, Ehsan and Sadeghi, Masoumeh and Saeedi, Reza and Moghaddam, Sahar Saeedi and Safari, Yahya and Safi, Sare and Safiri, Saeid and Sagar, Rajesh and Sahebkar, Amirhossein and Sajadi, S. Mohammad and Salam, Nasir and Salamati, Payman and Salem, Hosni and Salem, Marwa R. Rashad and Salimzadeh, Hamideh and Salman, Omar Mukhtar and Salomon, Joshua A. and Samad, Zainab and Kafil, Hossein Samadi and Sambala, Evanson Zondani and Samy, Abdallah M. and Sanabria, Juan and Sánchez-Pimienta, Tania G. and Santomauro, Damian Francesco and Santos, Itamar S. and Santos, João Vasco and Santric-Milicevic, Milena M. and Saraswathy, Sivan Yegnanarayana Iyer and Sarmiento-Suárez, Rodrigo and Sarrafzadegan, Nizal and Sartorius, Benn and Sarveazad, Arash and Sathian, Brijesh and Sathish, Thirunavukkarasu and Sattin, Davide and Saxena, Sonia and Schaeffer, Lauren E. and Schiavolin, Silvia and Schlaich, Markus P. and Schmidt, Maria Inês and Schutte, Aletta Elisabeth and Schwebel, David C. and Schwendicke, Falk and Senbeta, Anbissa Muleta and Senthilkumaran, Subramanian and Sepanlou, Sadaf G. and Serdar, Berrin and Serre, Marc L. and Shadid, Jamileh and Shafaat, Omid and Shahabi, Saeed and Shaheen, Amira A. and Shaikh, Masood Ali and Shalash, Ali S. and Shams-Beyranvand, Mehran and Shamsizadeh, Morteza and Sharafi, Kiomars and Sheikh, Aziz and Sheikhtaheri, Abbas and Shibuya, Kenji and Shield, Kevin David and Shigematsu, Mika and Shin, Jae Il and Shin, Min-Jeong and Shiri, Rahman and Shirkoohi, Reza and Shuval, Kerem and Siabani, Soraya and Sierpinski, Radoslaw and Sigfusdottir, Inga Dora and Sigurvinsdottir, Rannveig and Silva, João Pedro and Simpson, Kyle E. and Singh, Jasvinder A. and Singh, Pushpendra and Skiadaresi, Eirini and Skou, Søren T. and Skryabin, Valentin Yurievich and Smith, Emma U. R. and Soheili, Amin and Soltani, Shahin and Soofi, Moslem and Sorensen, Reed J. D. and Soriano, Joan B. and Sorrie, Muluken Bekele and Soshnikov, Sergey and Soyiri, Ireneous N. and Spencer, Cory N. and Spotin, Adel and Sreeramareddy, Chandrashekhar T. and Srinivasan, Vinay and Stanaway, Jeffrey D. and Stein, Caroline and Stein, Dan J. and Steiner, Caitlyn and Stockfelt, Leo and Stokes, Mark A. and Straif, Kurt and Stubbs, Jacob L. and Sufiyan, Mu'awiyyah Babale and Suleria, Hafiz Ansar Rasul and Abdulkader, Rizwan Suliankatchi and Sulo, Gerhard and Sultan, Iyad and Szumowski, Łukasz and Tabarés-Seisdedos, Rafael and Tabb, Karen M. and Tabuchi, Takahiro and Taherkhani, Amir and Tajdini, Masih and Takahashi, Ken and Takala, Jukka S. and Tamiru, Animut Tagele and Taveira, Nuno and Tehrani-Banihashemi, Arash and Temsah, Mohamad-Hani and Tesema, Getayeneh Antehunegn and Tessema, Zemenu Tadesse and Thurston, George D. and Titova, Mariya Vladimirovna and Tohidinik, Hamid Reza and Tonelli, Marcello and Topor-Madry, Roman and Topouzis, Fotis and Torre, Anna E. and Touvier, Mathilde and Tovani-Palone, Marcos Roberto Roberto and Tran, Bach Xuan and Travillian, Ravensara and Tsatsakis, Aristidis and Car, Lorainne Tudor and Tyrovolas, Stefanos and Uddin, Riaz and Umeokonkwo, Chukwuma David and Unnikrishnan, Bhaskaran and Upadhyay, Era and Vacante, Marco and Valdez, Pascual R. and Donkelaar, Aaron van and Vasankari, Tommi Juhani and Vasseghian, Yasser and Veisani, Yousef and Venketasubramanian, Narayanaswamy and Violante, Francesco S. and Vlassov, Vasily and Vollset, Stein Emil and Vos, Theo and Vukovic, Rade and Waheed, Yasir and Wallin, Mitchell Taylor and Wang, Yafeng and Wang, Yuan-Pang and Watson, Alexandrea and Wei, Jingkai and Wei, Melissa Y. Wei and Weintraub, Robert G. and Weiss, Jordan and Werdecker, Andrea and West, J. Jason and Westerman, Ronny and Whisnant, Joanna L. and Whiteford, Harvey A. and Wiens, Kirsten E. and Wolfe, Charles D. A. and Wozniak, Sarah S. and Wu, Ai-Min and Wu, Junjie and Hanson, Sarah Wulf and Xu, Gelin and Xu, Rixing and Yadgir, Simon and Jabbari, Seyed Hossein Yahyazadeh and Yamagishi, Kazumasa and Yaminfirooz, Mousa and Yano, Yuichiro and Yaya, Sanni and Yazdi-Feyzabadi, Vahid and Yeheyis, Tomas Y. and Yilgwan, Christopher Sabo and Yilma, Mekdes Tigistu and Yip, Paul and Yonemoto, Naohiro and Younis, Mustafa Z. and Younker, Theodore Patrick and Yousefi, Bahman and Yousefi, Zabihollah and Yousefinezhadi, Taraneh and Yousuf, Abdilahi Yousuf and Yu, Chuanhua and Yusefzadeh, Hasan and Moghadam, Telma Zahirian and Zamani, Mohammad and Zamanian, Maryam and Zandian, Hamed and Zastrozhin, Mikhail Sergeevich and Zhang, Yunquan and Zhang, Zhi-Jiang and Zhao, Jeff T. and Zhao, Xiu-Ju George and Zhao, Yingxi and Zhou, Maigeng and Ziapour, Arash and Zimsen, Stephanie R. M. and Brauer, Michael and Afshin, Ashkan and Lim, Stephen S.},
	month = oct,
	year = {2020},
	pmid = {33069327},
	note = {Publisher: Elsevier},
	pages = {1223--1249},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/YE6W88LX/Murray et al. - 2020 - Global burden of 87 risk factors in 204 countries .pdf:application/pdf},
}

@inproceedings{cooper_probabilistic_1992,
	address = {Copenhagen, Denmark},
	title = {Probabilistic retrieval based on staged logistic regression},
	isbn = {978-0-89791-523-6},
	url = {http://portal.acm.org/citation.cfm?doid=133160.133199},
	doi = {10.1145/133160.133199},
	language = {en},
	urldate = {2024-09-16},
	booktitle = {Proceedings of the 15th annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval  - {SIGIR} '92},
	publisher = {ACM Press},
	author = {Cooper, William S. and Gey, Fredric C. and Dabney, Daniel P.},
	year = {1992},
	pages = {198--210},
	file = {Cooper et al. - 1992 - Probabilistic retrieval based on staged logistic r.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/83YPI4F9/Cooper et al. - 1992 - Probabilistic retrieval based on staged logistic r.pdf:application/pdf},
}

@incollection{hurd_predictors_2001,
	title = {Predictors of {Mortality} among the {Elderly}},
	url = {https://www.nber.org/books-and-chapters/themes-economics-aging/predictors-mortality-among-elderly},
	urldate = {2024-09-16},
	booktitle = {Themes in the {Economics} of {Aging}},
	publisher = {University of Chicago Press},
	author = {Hurd, Michael D. and McFadden, Daniel and Merrill, Angela},
	month = jan,
	year = {2001},
	pages = {171--198},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/FQVNFRVM/Hurd et al. - 2001 - Predictors of Mortality among the Elderly.pdf:application/pdf},
}

@article{van_geloven_prediction_2020,
	title = {Prediction meets causal inference: the role of treatment in clinical prediction models},
	volume = {35},
	issn = {1573-7284},
	shorttitle = {Prediction meets causal inference},
	url = {https://doi.org/10.1007/s10654-020-00636-1},
	doi = {10.1007/s10654-020-00636-1},
	abstract = {In this paper we study approaches for dealing with treatment when developing a clinical prediction model. Analogous to the estimand framework recently proposed by the European Medicines Agency for clinical trials, we propose a ‘predictimand’ framework of different questions that may be of interest when predicting risk in relation to treatment started after baseline. We provide a formal definition of the estimands matching these questions, give examples of settings in which each is useful and discuss appropriate estimators including their assumptions. We illustrate the impact of the predictimand choice in a dataset of patients with end-stage kidney disease. We argue that clearly defining the estimand is equally important in prediction research as in causal inference.},
	language = {en},
	number = {7},
	urldate = {2024-09-16},
	journal = {European Journal of Epidemiology},
	author = {van Geloven, Nan and Swanson, Sonja A. and Ramspek, Chava L. and Luijken, Kim and van Diepen, Merel and Morris, Tim P. and Groenwold, Rolf H. H. and van Houwelingen, Hans C. and Putter, Hein and le Cessie, Saskia},
	month = jul,
	year = {2020},
	keywords = {Censoring, Clinical prediction model, Estimands, Predictimands, Treatment},
	pages = {619--630},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GF8M5VGW/van Geloven et al. - 2020 - Prediction meets causal inference the role of tre.pdf:application/pdf},
}

@article{hegde_feature_2015,
	title = {Feature {Selection} {Using} {Fisher}'s {Ratio} {Technique} for {Automatic} {Speech} {Recognition}},
	volume = {4},
	issn = {23208430, 2277548X},
	url = {http://www.airccse.org/journal/ijci/papers/4215ijci04.pdf},
	doi = {10.5121/ijci.2015.4204},
	abstract = {Automatic Speech Recognition (ASR) involves mainly two steps; feature extraction and classification (pattern recognition). Mel Frequency Cepstral Coefficient (MFCC) is used as one of the prominent feature extraction techniques in ASR. Usually, the set of all 12 MFCC coefficients is used as the feature vector in the classification step. But the question is whether the same or improved classification accuracy can be achieved by using a subset of 12 MFCC as feature vector. In this paper, Fisher’s ratio technique is used for selecting a subset of 12 MFCC coefficients that contribute more in discriminating a pattern. The selected coefficients are used in classification with Hidden Markov Model (HMM) algorithm. The classification accuracies that we get by using 12 coefficients and by using the selected coefficients are compared.},
	language = {en},
	number = {2},
	urldate = {2024-09-11},
	journal = {International Journal on Cybernetics \& Informatics},
	author = {Hegde, Sarika and K.K, Achary and Shetty, Surendra},
	month = apr,
	year = {2015},
	pages = {45--52},
	file = {Hegde et al. - 2015 - Feature Selection Using Fisher's Ratio Technique f.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/PE2DFC82/Hegde et al. - 2015 - Feature Selection Using Fisher's Ratio Technique f.pdf:application/pdf},
}

@article{hegde_feature_2015-1,
	title = {Feature {Selection} {Using} {Fisher}'s {Ratio} {Technique} for {Automatic} {Speech} {Recognition}},
	volume = {4},
	issn = {23208430, 2277548X},
	url = {http://www.airccse.org/journal/ijci/papers/4215ijci04.pdf},
	doi = {10.5121/ijci.2015.4204},
	abstract = {Automatic Speech Recognition (ASR) involves mainly two steps; feature extraction and classification (pattern recognition). Mel Frequency Cepstral Coefficient (MFCC) is used as one of the prominent feature extraction techniques in ASR. Usually, the set of all 12 MFCC coefficients is used as the feature vector in the classification step. But the question is whether the same or improved classification accuracy can be achieved by using a subset of 12 MFCC as feature vector. In this paper, Fisher’s ratio technique is used for selecting a subset of 12 MFCC coefficients that contribute more in discriminating a pattern. The selected coefficients are used in classification with Hidden Markov Model (HMM) algorithm. The classification accuracies that we get by using 12 coefficients and by using the selected coefficients are compared.},
	language = {en},
	number = {2},
	urldate = {2024-09-11},
	journal = {International Journal on Cybernetics \& Informatics},
	author = {Hegde, Sarika and K.K, Achary and Shetty, Surendra},
	month = apr,
	year = {2015},
	pages = {45--52},
	file = {Hegde et al. - 2015 - Feature Selection Using Fisher's Ratio Technique f.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/5C6IDGRE/Hegde et al. - 2015 - Feature Selection Using Fisher's Ratio Technique f.pdf:application/pdf},
}

@misc{noauthor_ranking_2023,
	title = {Ranking {SVM}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Ranking_SVM&oldid=1189347791},
	abstract = {In machine learning, a ranking SVM is a variant of the support vector machine algorithm, which is used to solve certain ranking problems (via learning to rank). The ranking SVM algorithm was published by Thorsten Joachims in 2002. 
The original purpose of the algorithm was to improve the performance of an internet search engine. However, it was found that ranking SVM also can be used to solve other problems such as Rank SIFT.},
	language = {en},
	urldate = {2024-09-11},
	journal = {Wikipedia},
	month = dec,
	year = {2023},
	note = {Page Version ID: 1189347791},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/8IQQJG7K/Ranking_SVM.html:text/html},
}

@article{entringer_extracting_2022,
	title = {Extracting {Agency} and {Communion} {From} the {Big} {Five}: {A} {Four}-{Way} {Competition}},
	volume = {29},
	issn = {1073-1911},
	shorttitle = {Extracting {Agency} and {Communion} {From} the {Big} {Five}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9301169/},
	doi = {10.1177/10731911211003978},
	abstract = {Agency and communion are the two fundamental content dimensions in psychology.
The two dimensions figure prominently in many psychological realms (personality,
social, self, motivational, cross-cultural, etc.). In contemporary research,
however, personality is most commonly measured within the Big Five framework. We
developed novel agency and communion scales based on the items from the most
popular nonpropriety measure of the Big Five—the Big Five Inventory. We compared
four alternative scale-construction methods: expert rating,
target scale, ant colony, and
brute force. Across three samples
(Ntotal = 942), all methods yielded reliable and
valid agency and communion scales. Our research provides two main contributions.
For psychometric theory, it extends knowledge on the four scale-construction
methods and their relative convergence. For psychometric practice, it enables
researchers to examine agency and communion hypotheses with extant Big Five
Inventory data sets, including those collected in their own labs as well as
openly accessible, large-scale data sets.},
	number = {6},
	urldate = {2024-08-19},
	journal = {Assessment},
	author = {Entringer, Theresa M. and Gebauer, Jochen E. and Paulhus, Delroy L.},
	month = sep,
	year = {2022},
	pmid = {33813905},
	pmcid = {PMC9301169},
	pages = {1216--1235},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/4LUR4K5V/Entringer et al. - 2022 - Extracting Agency and Communion From the Big Five.pdf:application/pdf},
}

@article{silver_mastering_2016,
	title = {Mastering the game of {Go} with deep neural networks and tree search},
	volume = {529},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	language = {en},
	number = {7587},
	urldate = {2024-08-07},
	journal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	month = jan,
	year = {2016},
	pages = {484--489},
	file = {Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/9ZLDRMU8/Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf:application/pdf},
}

@misc{amugongo_retrieval_2024,
	title = {Retrieval {Augmented} {Generation} for {Large} {Language} {Models} in {Healthcare}: {A} {Systematic} {Review}},
	shorttitle = {Retrieval {Augmented} {Generation} for {Large} {Language} {Models} in {Healthcare}},
	url = {https://www.preprints.org/manuscript/202407.0876/v1},
	doi = {10.20944/preprints202407.0876.v1},
	abstract = {Large Language Models (LLMs) have demonstrated promising capabilities to solve complex tasks in critical sectors such as healthcare. However, LLMs are limited by their training data which is often outdated, the tendency to generate inaccurate ("hallucinated") content and a lack of transparency in the content they generate. To address these limitations, retrieval augmented generation (RAG) grounds the responses of LLMs by exposing them to external knowledge sources. However, in the healthcare domain there is currently a lack of systematic understanding of which datasets, RAG methodologies and evaluation frameworks are available. This review aims to bridge this gap by assessing RAG-based approaches employed by LLMs in healthcare, focusing on the different steps of retrieval, augmentation and generation. Additionally, we identify the limitations, strengths and gaps in the existing literature. Our synthesis shows that proprietary models such as GPT-3.5/4 are the most used for RAG applications in healthcare. Also, there is a lack of standardized evaluation frameworks for RAG-based applications. In addition, the majority of the studies do not assess or address ethical considerations related to RAG in healthcare. It is important to account for ethical challenges that are inherent when AI systems are implemented in the clinical setting. Lastly, we highlight the need for further research and development to ensure responsible and effective adoption of RAG in the medical domain.},
	language = {en},
	urldate = {2024-08-02},
	publisher = {Preprints},
	author = {Amugongo, Lameck Mbangula and Mascheroni, Pietro and Brooks, Steven Geoffrey and Doering, Stefan and Seidel, Jan},
	month = jul,
	year = {2024},
	keywords = {AI ethics, Evaluation, Healthcare, Large Language Models, Retrieval Augmented Generation},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CF9HRLMP/Amugongo et al. - 2024 - Retrieval Augmented Generation for Large Language .pdf:application/pdf},
}

@article{turrillas_necpal_2021,
	title = {{NECPAL} prognostic tool: a palliative medicine retrospective cohort study},
	issn = {2045-4368},
	shorttitle = {{NECPAL} prognostic tool},
	doi = {10.1136/bmjspcare-2020-002567},
	abstract = {OBJECTIVE: To develop and validate a prognostic model to assess mortality risk at 24 months in patients with advanced chronic conditions.
METHODS: Retrospective design based on a previous population cohort study with 789 adults who were identified with the surprise question and NECPAL tool from primary and intermediate care centres, nursing homes and one acute hospital of Spain. A Cox regression model was used to derive a mortality predictive model based on patients' age and six previously selected NECPAL prognostic factors (palliative care need identified by healthcare professionals, functional decline, nutritional decline, multimorbidity, use of resources, disease-specific criteria of severity/progression). Patients were split into derivation/validation cohorts, and four steps were followed: descriptive analysis, predictors' assessment, model estimation and model assessment.
RESULTS: All predictive variables were independently associated with increased risk of mortality at 24 months. Performance model including age was good; discrimination power by area under the curve (AUC) was 0.72/0.67 in the derivation/validation cohorts, and correlation between expected and observed (E/O) mortality ratio was 0.74/0.70. The model showed similar performance across settings (AUC 0.65-0.74, E/O 1.00-1.01), the best performance in oncological patients (AUC 0.78, E/O 0.76) and the worst in dementia patients (AUC 0.58, E/O 0.85). Based on the number of factors affected, three prognostic stages with significant differences and a median survival of 38, 17.2 and 3.6 months (p{\textless}0.001) were defined.
CONCLUSION: The NECPAL prognostic tool is accurate and eventually useful at the clinical practice. Stratification in risk groups may enable early intervention and enhance policy-making and service planning.},
	language = {eng},
	journal = {BMJ supportive \& palliative care},
	author = {Turrillas, Pamela and Peñafiel, Judith and Tebé, Cristian and Amblàs-Novellas, Jordi and Gómez-Batiste, Xavier},
	month = feb,
	year = {2021},
	pmid = {33593868},
	keywords = {prognosis},
	pages = {bmjspcare--2020--002567},
}

@article{turrillas_necpal_2021-1,
	title = {{NECPAL} prognostic tool: a palliative medicine retrospective cohort study},
	issn = {2045-435X, 2045-4368},
	shorttitle = {{NECPAL} prognostic tool},
	url = {https://spcare.bmj.com/lookup/doi/10.1136/bmjspcare-2020-002567},
	doi = {10.1136/bmjspcare-2020-002567},
	abstract = {Objective  To develop and validate a prognostic model to assess mortality risk at 24 months in patients with advanced chronic conditions.
Methods  Retrospective design based on a previous population cohort study with 789 adults who were identified with the surprise question and NECPAL tool from primary and intermediate care centres, nursing homes and one acute hospital of Spain. A Cox regression model was used to derive a mortality predictive model based on patients’ age and six previously selected NECPAL prognostic factors (palliative care need identified by healthcare professionals, functional decline, nutritional decline, multimorbidity, use of resources, disease-­specific criteria of severity/ progression). Patients were split into derivation/ validation cohorts, and four steps were followed: descriptive analysis, predictors’ assessment, model estimation and model assessment.
Results  All predictive variables were independently associated with increased risk of mortality at 24 months. Performance model including age was good; discrimination power by area under the curve (AUC) was 0.72/0.67 in the derivation/validation cohorts, and correlation between expected and observed (E/O) mortality ratio was 0.74/0.70. The model showed similar performance across settings (AUC 0.65–0.74, E/O 1.00–1.01), the best performance in oncological patients (AUC 0.78, E/O 0.76) and the worst in dementia patients (AUC 0.58, E/O 0.85). Based on the number of factors affected, three prognostic stages with significant differences and a median survival of 38, 17.2 and 3.6 months (p{\textless}0.001) were defined.
Conclusion  The NECPAL prognostic tool is accurate and eventually useful at the clinical practice. Stratification in risk groups may enable early intervention and enhance policy-­making and service planning.},
	language = {en},
	urldate = {2024-08-01},
	journal = {BMJ Supportive \& Palliative Care},
	author = {Turrillas, Pamela and Peñafiel, Judith and Tebé, Cristian and Amblàs-Novellas, Jordi and Gómez-Batiste, Xavier},
	month = feb,
	year = {2021},
	pages = {bmjspcare--2020--002567},
	file = {Turrillas et al. - 2021 - NECPAL prognostic tool a palliative medicine retr.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/6T9G4PQQ/Turrillas et al. - 2021 - NECPAL prognostic tool a palliative medicine retr.pdf:application/pdf},
}

@inproceedings{lee_recursion_2023,
	address = {Toronto, Canada},
	title = {Recursion of {Thought}: {A} {Divide}-and-{Conquer} {Approach} to {Multi}-{Context} {Reasoning} with {Language} {Models}},
	shorttitle = {Recursion of {Thought}},
	url = {https://aclanthology.org/2023.findings-acl.40},
	doi = {10.18653/v1/2023.findings-acl.40},
	language = {en},
	urldate = {2024-07-31},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Lee, Soochan and Kim, Gunhee},
	year = {2023},
	pages = {623--658},
	file = {Lee and Kim - 2023 - Recursion of Thought A Divide-and-Conquer Approac.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/3BGUXEHV/Lee and Kim - 2023 - Recursion of Thought A Divide-and-Conquer Approac.pdf:application/pdf;rot_poster:/home/extasia/snap/zotero-snap/common/Zotero/storage/WGTEYKS6/rot_poster.pdf:application/pdf},
}

@misc{lee_recursion_2023-1,
	title = {Recursion of {Thought}: {A} {Divide}-and-{Conquer} {Approach} to {Multi}-{Context} {Reasoning} with {Language} {Models}},
	shorttitle = {Recursion of {Thought}},
	url = {http://arxiv.org/abs/2306.06891},
	doi = {10.48550/arXiv.2306.06891},
	abstract = {Generating intermediate steps, or Chain of Thought (CoT), is an effective way to significantly improve language models' (LM) multi-step reasoning capability. However, the CoT lengths can grow rapidly with the problem complexity, easily exceeding the maximum context size. Instead of increasing the context limit, which has already been heavily investigated, we explore an orthogonal direction: making LMs divide a problem into multiple contexts. We propose a new inference framework, called Recursion of Thought (RoT), which introduces several special tokens that the models can output to trigger context-related operations. Extensive experiments with multiple architectures including GPT-3 show that RoT dramatically improves LMs' inference capability to solve problems, whose solution consists of hundreds of thousands of tokens.},
	urldate = {2024-07-31},
	publisher = {arXiv},
	author = {Lee, Soochan and Kim, Gunhee},
	month = jun,
	year = {2023},
	note = {arXiv:2306.06891 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/URQ9CQ3Y/Lee and Kim - 2023 - Recursion of Thought A Divide-and-Conquer Approac.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/QBCMA38R/2306.html:text/html},
}

@inproceedings{jiang_xpert_2024,
	address = {New York, NY, USA},
	series = {{ICSE} '24},
	title = {Xpert: {Empowering} {Incident} {Management} with {Query} {Recommendations} via {Large} {Language} {Models}},
	isbn = {979-8-4007-0217-4},
	shorttitle = {Xpert},
	url = {https://doi.org/10.1145/3597503.3639081},
	doi = {10.1145/3597503.3639081},
	abstract = {Large-scale cloud systems play a pivotal role in modern IT infrastructure. However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience. To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data. However, writing these queries can be challenging and time-consuming. This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at Microsoft. The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management.Building upon these valuable insights, we introduce Xpert, an end-to-end machine learning framework that automates KQL recommendation process. By leveraging historical incident data and large language models, Xpert generates customized KQL queries tailored to new incidents. Furthermore, Xpert incorporates a novel performance metric called Xcore, enabling a thorough evaluation of query quality from three comprehensive perspectives. We conduct extensive evaluations of Xpert, demonstrating its effectiveness in offline settings. Notably, we deploy Xpert in the real production environment of a large-scale incident management system in Microsoft, validating its efficiency in supporting incident management. To the best of our knowledge, this paper represents the first empirical study of its kind, and Xpert stands as a pioneering DSL query recommendation framework designed for incident management.},
	urldate = {2024-07-29},
	booktitle = {Proceedings of the {IEEE}/{ACM} 46th {International} {Conference} on {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Yuxuan and Zhang, Chaoyun and He, Shilin and Yang, Zhihao and Ma, Minghua and Qin, Si and Kang, Yu and Dang, Yingnong and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
	month = apr,
	year = {2024},
	pages = {1--13},
	file = {Submitted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/AE3MRZ4E/Jiang et al. - 2024 - Xpert Empowering Incident Management with Query R.pdf:application/pdf},
}

@misc{wang_language_2020,
	title = {Language {Models} are {Open} {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2010.11967},
	doi = {10.48550/arXiv.2010.11967},
	abstract = {This paper shows how to construct knowledge graphs (KGs) from pre-trained language models (e.g., BERT, GPT-2/3), without human supervision. Popular KGs (e.g, Wikidata, NELL) are built in either a supervised or semi-supervised manner, requiring humans to create knowledge. Recent deep language models automatically acquire knowledge from large-scale corpora via pre-training. The stored knowledge has enabled the language models to improve downstream NLP tasks, e.g., answering questions, and writing code and articles. In this paper, we propose an unsupervised method to cast the knowledge contained within language models into KGs. We show that KGs are constructed with a single forward pass of the pre-trained language models (without fine-tuning) over the corpora. We demonstrate the quality of the constructed KGs by comparing to two KGs (Wikidata, TAC KBP) created by humans. Our KGs also provide open factual knowledge that is new in the existing KGs. Our code and KGs will be made publicly available.},
	urldate = {2024-07-26},
	publisher = {arXiv},
	author = {Wang, Chenguang and Liu, Xiao and Song, Dawn},
	month = oct,
	year = {2020},
	note = {arXiv:2010.11967 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KHMYFF3V/Wang et al. - 2020 - Language Models are Open Knowledge Graphs.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/37DBYCNK/2010.html:text/html},
}

@misc{alkhamissi_review_2022,
	title = {A {Review} on {Language} {Models} as {Knowledge} {Bases}},
	url = {http://arxiv.org/abs/2204.06031},
	abstract = {Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem a LM should have to fully act as a KB, and review the recent literature with respect to those aspects.},
	language = {en},
	urldate = {2024-07-26},
	publisher = {arXiv},
	author = {AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
	month = apr,
	year = {2022},
	note = {arXiv:2204.06031 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {AlKhamissi et al. - 2022 - A Review on Language Models as Knowledge Bases.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/CMEN9XFZ/AlKhamissi et al. - 2022 - A Review on Language Models as Knowledge Bases.pdf:application/pdf},
}

@misc{noauthor_llama_nodate,
	title = {Llama},
	url = {https://llama.meta.com/},
	abstract = {The open source AI model you can fine-tune, distill and deploy anywhere. Our latest models are available in 8B, 70B, and 405B variants.},
	language = {en},
	urldate = {2024-07-23},
	journal = {Meta Llama},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/6AU3B698/llama.meta.com.html:text/html},
}

@inproceedings{mekala_zerotop_2023,
	address = {Singapore},
	title = {{ZEROTOP}: {Zero}-{Shot} {Task}-{Oriented} {Semantic} {Parsing} using {Large} {Language} {Models}},
	shorttitle = {{ZEROTOP}},
	url = {https://aclanthology.org/2023.emnlp-main.354},
	doi = {10.18653/v1/2023.emnlp-main.354},
	abstract = {We explore the use of large language models (LLMs) for zero-shot semantic parsing. Semantic parsing involves mapping natural language utterances to task-specific meaning representations. LLMs are generally trained on publicly available text and code and cannot be expected to directly generalize to domain-specific parsing tasks in a zero-shot setting. In this work, we propose ZEROTOP, a zero-shot task-oriented parsing method that decomposes semantic parsing problem into a set of abstractive and extractive question-answering (QA) problems. For each utterance, we prompt the LLM with questions corresponding to its top-level intent and a set of slots and use the LLM generations to construct the target meaning representation. We observe that current LLMs fail to detect unanswerable questions; and as a result, cannot handle questions corresponding to missing slots. We address this by fine-tuning a language model on public QA datasets using synthetic negative samples. Experimental results show that our QA-based decomposition paired with the fine-tuned LLM can zero-shot parse {\textbackslash}approx 16\% of utterances in the MTOP dataset.},
	urldate = {2024-07-23},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Mekala, Dheeraj and Wolfe, Jason and Roy, Subhro},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	month = dec,
	year = {2023},
	pages = {5792--5799},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/4X5UBXK7/Mekala et al. - 2023 - ZEROTOP Zero-Shot Task-Oriented Semantic Parsing .pdf:application/pdf},
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1533-7928},
	shorttitle = {Scikit-learn},
	url = {http://jmlr.org/papers/v12/pedregosa11a.html},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and API consistency.  It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	number = {85},
	urldate = {2024-07-19},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	year = {2011},
	pages = {2825--2830},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EVX4C2YE/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@misc{noauthor_scikit-learn_nodate,
	title = {scikit-learn: machine learning in {Python} — scikit-learn 1.5.1 documentation},
	url = {https://scikit-learn.org/stable/},
	urldate = {2024-07-19},
	file = {scikit-learn\: machine learning in Python — scikit-learn 1.5.1 documentation:/home/extasia/snap/zotero-snap/common/Zotero/storage/HSMA94R4/stable.html:text/html},
}

@misc{noauthor_scikit-learn_nodate-1,
	title = {scikit-learn: machine learning in {Python} — scikit-learn 1.5.1 documentation},
	url = {https://scikit-learn.org/stable/},
	urldate = {2024-07-19},
	file = {scikit-learn\: machine learning in Python — scikit-learn 1.5.1 documentation:/home/extasia/snap/zotero-snap/common/Zotero/storage/8QIVFX63/stable.html:text/html},
}

@misc{schulhoff_prompt_2024,
	title = {The {Prompt} {Report}: {A} {Systematic} {Survey} of {Prompting} {Techniques}},
	shorttitle = {The {Prompt} {Report}},
	url = {http://arxiv.org/abs/2406.06608},
	doi = {10.48550/arXiv.2406.06608},
	abstract = {Generative Artificial Intelligence (GenAI) systems are being increasingly deployed across all parts of industry and research settings. Developers and end users interact with these systems through the use of prompting or prompt engineering. While prompting is a widespread and highly researched concept, there exists conflicting terminology and a poor ontological understanding of what constitutes a prompt due to the area's nascency. This paper establishes a structured understanding of prompts, by assembling a taxonomy of prompting techniques and analyzing their use. We present a comprehensive vocabulary of 33 vocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40 techniques for other modalities. We further present a meta-analysis of the entire literature on natural language prefix-prompting.},
	urldate = {2024-07-16},
	publisher = {arXiv},
	author = {Schulhoff, Sander and Ilie, Michael and Balepur, Nishant and Kahadze, Konstantine and Liu, Amanda and Si, Chenglei and Li, Yinheng and Gupta, Aayush and Han, HyoJung and Schulhoff, Sevien and Dulepet, Pranav Sandeep and Vidyadhara, Saurav and Ki, Dayeon and Agrawal, Sweta and Pham, Chau and Kroiz, Gerson and Li, Feileen and Tao, Hudson and Srivastava, Ashay and Da Costa, Hevander and Gupta, Saloni and Rogers, Megan L. and Goncearenco, Inna and Sarli, Giuseppe and Galynker, Igor and Peskoff, Denis and Carpuat, Marine and White, Jules and Anadkat, Shyamal and Hoyle, Alexander and Resnik, Philip},
	month = jun,
	year = {2024},
	note = {arXiv:2406.06608 [cs]
version: 1},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CTK7ZVYK/Schulhoff et al. - 2024 - The Prompt Report A Systematic Survey of Promptin.pdf:application/pdf;arXiv.org Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/E4Y97EAR/2406.html:text/html},
}

@misc{lewis_retrieval-augmented_2021,
	title = {Retrieval-{Augmented} {Generation} for {Knowledge}-{Intensive} {NLP} {Tasks}},
	url = {http://arxiv.org/abs/2005.11401},
	abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when ﬁne-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-speciﬁc architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pretrained models with a differentiable access mechanism to explicit non-parametric memory have so far been only investigated for extractive downstream tasks. We explore a general-purpose ﬁne-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, and another which can use different passages per token. We ﬁne-tune and evaluate our models on a wide range of knowledgeintensive NLP tasks and set the state of the art on three open domain QA tasks, outperforming parametric seq2seq models and task-speciﬁc retrieve-and-extract architectures. For language generation tasks, we ﬁnd that RAG models generate more speciﬁc, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
	language = {en},
	urldate = {2024-07-12},
	publisher = {arXiv},
	author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
	month = apr,
	year = {2021},
	note = {arXiv:2005.11401 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Inten.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/MPGTP3ZA/Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Inten.pdf:application/pdf},
}

@misc{yu_natural_2023,
	title = {Natural {Language} {Reasoning}, {A} {Survey}},
	url = {http://arxiv.org/abs/2303.14725},
	abstract = {This survey paper proposes a clearer view of natural language reasoning in the field of Natural Language Processing (NLP), both conceptually and practically. Conceptually, we provide a distinct definition for natural language reasoning in NLP, based on both philosophy and NLP scenarios, discuss what types of tasks require reasoning, and introduce a taxonomy of reasoning. Practically, we conduct a comprehensive literature review on natural language reasoning in NLP, mainly covering classical logical reasoning, natural language inference, multi-hop question answering, and commonsense reasoning. The paper also identifies and views backward reasoning, a powerful paradigm for multi-step reasoning, and introduces defeasible reasoning as one of the most important future directions in natural language reasoning research. We focus on single-modality unstructured natural language text, excluding neuro-symbolic techniques and mathematical reasoning.},
	language = {en},
	urldate = {2024-07-11},
	publisher = {arXiv},
	author = {Yu, Fei and Zhang, Hongbo and Tiwari, Prayag and Wang, Benyou},
	month = may,
	year = {2023},
	note = {arXiv:2303.14725 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Yu et al. - 2023 - Natural Language Reasoning, A Survey.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/SVNA5WIU/Yu et al. - 2023 - Natural Language Reasoning, A Survey.pdf:application/pdf},
}

@techreport{noble_english_nodate,
	title = {English {Indices} of {Deprivation} 2019 {Research} {Report}},
	institution = {Ministry of Housing, Communities and Local Development},
	author = {{Noble}},
	file = {Noble - English Indices of Deprivation 2019 research repo.pdf:/home/extasia/snap/zotero-snap/common/Zotero/storage/Z8ICN578/Noble - English Indices of Deprivation 2019 research repo.pdf:application/pdf},
}

@misc{deng_reforce_2025,
	title = {{ReFoRCE}: {A} {Text}-to-{SQL} {Agent} with {Self}-{Refinement}, {Format} {Restriction}, and {Column} {Exploration}},
	shorttitle = {{ReFoRCE}},
	url = {http://arxiv.org/abs/2502.00675},
	doi = {10.48550/arXiv.2502.00675},
	abstract = {Text-to-SQL systems have unlocked easier access to critical data insights by enabling natural language queries over structured databases. However, deploying such systems in enterprise environments remains challenging due to factors such as large, complex schemas ({\textgreater} 3000 columns), diverse SQL dialects (e.g., BigQuery, Snowflake) and sophisticated query requirements (e.g., transformation, analytics). Current state-of-the-art performance on the Spider 2.0 dataset -- a benchmark built to mimic such complex environments -- remains limited at 20\%. Key limitations include inadequate instruction-following, poor long-context comprehension, weak self-refinement, and insufficient dialect-specific knowledge. To address these gaps, we propose ReFoRCE (Self-Refinement Agent with Format Restriction and Column Exploration) which introduces (1) table compression to mitigate long-context limitations (2) format restriction to ensure accurate answer format, and (3) iterative column exploration for enhanced schema understanding. Additionally, it employs self-refinement pipeline consisting of (1) parallelized workflows with voting mechanisms and (2) a Common Table Expression (CTE) based refinement approach to handle unresolved cases. ReFoRCE achieves state-of-the-art results scoring 31.26 on the Spider 2.0-Snow and scoring 30.35 on the Spider 2.0-Lite tasks.},
	urldate = {2025-04-11},
	publisher = {arXiv},
	author = {Deng, Minghang and Ramachandran, Ashwin and Xu, Canwen and Hu, Lanxiang and Yao, Zhewei and Datta, Anupam and Zhang, Hao},
	month = feb,
	year = {2025},
	note = {arXiv:2502.00675 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/E5NET366/Deng et al. - 2025 - ReFoRCE A Text-to-SQL Agent with Self-Refinement, Format Restriction, and Column Exploration.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/PYNDSWZ7/2502.html:text/html},
}

@article{oeberst_toward_2023,
	title = {Toward {Parsimony} in {Bias} {Research}: {A} {Proposed} {Common} {Framework} of {Belief}-{Consistent} {Information} {Processing} for a {Set} of {Biases}},
	volume = {18},
	issn = {1745-6916},
	shorttitle = {Toward {Parsimony} in {Bias} {Research}},
	url = {https://doi.org/10.1177/17456916221148147},
	doi = {10.1177/17456916221148147},
	abstract = {One of the essential insights from psychological research is that people’s information processing is often biased. By now, a number of different biases have been identified and empirically demonstrated. Unfortunately, however, these biases have often been examined in separate lines of research, thereby precluding the recognition of shared principles. Here we argue that several—so far mostly unrelated—biases (e.g., bias blind spot, hostile media bias, egocentric/ethnocentric bias, outcome bias) can be traced back to the combination of a fundamental prior belief and humans’ tendency toward belief-consistent information processing. What varies between different biases is essentially the specific belief that guides information processing. More importantly, we propose that different biases even share the same underlying belief and differ only in the specific outcome of information processing that is assessed (i.e., the dependent variable), thus tapping into different manifestations of the same latent information processing. In other words, we propose for discussion a model that suffices to explain several different biases. We thereby suggest a more parsimonious approach compared with current theoretical explanations of these biases. We also generate novel hypotheses that follow directly from the integrative nature of our perspective.},
	language = {EN},
	number = {6},
	urldate = {2025-04-13},
	journal = {Perspectives on Psychological Science},
	author = {Oeberst, Aileen and Imhoff, Roland},
	month = nov,
	year = {2023},
	note = {Publisher: SAGE Publications Inc},
	pages = {1464--1487},
	file = {SAGE PDF Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/LVXMKBJP/Oeberst and Imhoff - 2023 - Toward Parsimony in Bias Research A Proposed Common Framework of Belief-Consistent Information Proc.pdf:application/pdf},
}

@inproceedings{alshahwan_automated_2024,
	address = {New York, NY, USA},
	series = {{FSE} 2024},
	title = {Automated {Unit} {Test} {Improvement} using {Large} {Language} {Models} at {Meta}},
	isbn = {979-8-4007-0658-5},
	url = {https://dl.acm.org/doi/10.1145/3663529.3663839},
	doi = {10.1145/3663529.3663839},
	abstract = {This paper describes Meta’s TestGen-LLM tool, which uses LLMs to automatically improve existing human-written tests.     TestGen-LLM verifies that its generated test classes successfully clear a set of filters that assure measurable improvement over the original test suite, thereby eliminating problems due to LLM hallucination.    We describe the deployment of TestGen-LLM at Meta test-a-thons for the Instagram and Facebook platforms.     In an evaluation on Reels and Stories products for Instagram,     75\% of TestGen-LLM’s test cases built correctly, 57\% passed reliably, and 25\% increased coverage.    During Meta’s Instagram and Facebook test-a-thons, it improved 11.5\% of all classes to which it was applied, with 73\% of its recommendations being accepted for production deployment by Meta software engineers.    We believe this is the first report on industrial scale deployment of LLM-generated code backed by such assurances of code improvement.},
	urldate = {2025-04-18},
	booktitle = {Companion {Proceedings} of the 32nd {ACM} {International} {Conference} on the {Foundations} of {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Alshahwan, Nadia and Chheda, Jubin and Finogenova, Anastasia and Gokkaya, Beliz and Harman, Mark and Harper, Inna and Marginean, Alexandru and Sengupta, Shubho and Wang, Eddy},
	month = jul,
	year = {2024},
	pages = {185--196},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KC8RBNDT/Alshahwan et al. - 2024 - Automated Unit Test Improvement using Large Language Models at Meta.pdf:application/pdf},
}

@misc{ziletti_generating_2025,
	title = {Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to-{SQL} generation},
	url = {http://arxiv.org/abs/2502.21107},
	doi = {10.48550/arXiv.2502.21107},
	abstract = {Clinical cohort definition is crucial for patient recruitment and observational studies, yet translating inclusion/exclusion criteria into SQL queries remains challenging and manual. We present an automated system utilizing large language models that combines criteria parsing, two-level retrieval augmented generation with specialized knowledge bases, medical concept standardization, and SQL generation to retrieve patient cohorts with patient funnels. The system achieves 0.75 F1-score in cohort identification on EHR data, effectively capturing complex temporal and logical relationships. These results demonstrate the feasibility of automated cohort generation for epidemiological research.},
	urldate = {2025-04-18},
	publisher = {arXiv},
	author = {Ziletti, Angelo and D'Ambrosi, Leonardo},
	month = feb,
	year = {2025},
	note = {arXiv:2502.21107 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/7AC4S5TZ/Ziletti and D'Ambrosi - 2025 - Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to.pdf:application/pdf;Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/82CNCUA8/Ziletti and D'Ambrosi - 2025 - Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/UWML95EX/2502.html:text/html},
}

@misc{noauthor_humanlayer12-factor-agents_2025,
	title = {humanlayer/12-factor-agents},
	url = {https://github.com/humanlayer/12-factor-agents},
	abstract = {What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?},
	urldate = {2025-04-16},
	publisher = {HumanLayer},
	month = apr,
	year = {2025},
	note = {original-date: 2025-03-30T22:10:39Z},
	keywords = {12-factor, 12-factor-agents, agents, ai, context-window, framework, llms, memory, orchestration, prompt-engineering, rag},
}

@misc{wu_autogen_2023,
	title = {{AutoGen}: {Enabling} {Next}-{Gen} {LLM} {Applications} via {Multi}-{Agent} {Conversation}},
	shorttitle = {{AutoGen}},
	url = {http://arxiv.org/abs/2308.08155},
	doi = {10.48550/arXiv.2308.08155},
	abstract = {AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.},
	urldate = {2025-04-15},
	publisher = {arXiv},
	author = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and Awadallah, Ahmed Hassan and White, Ryen W. and Burger, Doug and Wang, Chi},
	month = oct,
	year = {2023},
	note = {arXiv:2308.08155 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JGQ9E2LR/Wu et al. - 2023 - AutoGen Enabling Next-Gen LLM Applications via Multi-Agent Conversation.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/244FTV9I/2308.html:text/html},
}

@misc{noauthor_datatypes_nodate,
	title = {Datatypes {In} {SQLite}},
	url = {https://sqlite.org/datatype3.html#boolean_datatype},
	urldate = {2025-04-19},
	file = {Datatypes In SQLite:/home/extasia/snap/zotero-snap/common/Zotero/storage/VMV72TCL/datatype3.html:text/html},
}

@misc{ziletti_generating_2025-1,
	title = {Generating patient cohorts from electronic health records using two-step retrieval-augmented text-to-{SQL} generation},
	url = {http://arxiv.org/abs/2502.21107},
	doi = {10.48550/arXiv.2502.21107},
	abstract = {Clinical cohort definition is crucial for patient recruitment and observational studies, yet translating inclusion/exclusion criteria into SQL queries remains challenging and manual. We present an automated system utilizing large language models that combines criteria parsing, two-level retrieval augmented generation with specialized knowledge bases, medical concept standardization, and SQL generation to retrieve patient cohorts with patient funnels. The system achieves 0.75 F1-score in cohort identification on EHR data, effectively capturing complex temporal and logical relationships. These results demonstrate the feasibility of automated cohort generation for epidemiological research.},
	urldate = {2025-04-20},
	publisher = {arXiv},
	author = {Ziletti, Angelo and D'Ambrosi, Leonardo},
	month = feb,
	year = {2025},
	note = {arXiv:2502.21107 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/BAC8BICB/2502.html:text/html},
}

@misc{peters_deep_2018,
	title = {Deep contextualized word representations},
	url = {http://arxiv.org/abs/1802.05365},
	doi = {10.48550/arXiv.1802.05365},
	abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
	urldate = {2025-04-29},
	publisher = {arXiv},
	author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	month = mar,
	year = {2018},
	note = {arXiv:1802.05365 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PXKICA3B/Peters et al. - 2018 - Deep contextualized word representations.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/8JMHCVTZ/1802.html:text/html},
}

@misc{sennrich_neural_2016,
	title = {Neural {Machine} {Translation} of {Rare} {Words} with {Subword} {Units}},
	url = {http://arxiv.org/abs/1508.07909},
	doi = {10.48550/arXiv.1508.07909},
	abstract = {Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character n-gram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English-German and English-Russian by 1.1 and 1.3 BLEU, respectively.},
	urldate = {2025-04-29},
	publisher = {arXiv},
	author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
	month = jun,
	year = {2016},
	note = {arXiv:1508.07909 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/F4QCW8JU/Sennrich et al. - 2016 - Neural Machine Translation of Rare Words with Subword Units.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ETH3I736/1508.html:text/html},
}

@article{brass_semantic_2006,
	series = {Quality {Software}},
	title = {Semantic errors in {SQL} queries: {A} quite complete list},
	volume = {79},
	issn = {0164-1212},
	shorttitle = {Semantic errors in {SQL} queries},
	url = {https://www.sciencedirect.com/science/article/pii/S016412120500124X},
	doi = {10.1016/j.jss.2005.06.028},
	abstract = {We investigate classes of SQL queries which are syntactically correct, but certainly not intended, no matter for which task the query was written. For instance, queries that are contradictory, i.e. always return the empty set, are obviously not intended. However, current database management systems (DBMS) execute such queries without any warning. In this paper, we give an extensive list of conditions that are strong indications of semantic errors. Of course, questions like the satisfiability are in general undecidable, but a significant subset of SQL queries can actually be checked. We believe that future DBMS will perform such checks and that the generated warnings will help to develop application programs with fewer bugs in less time.},
	number = {5},
	urldate = {2025-05-01},
	journal = {Journal of Systems and Software},
	author = {Brass, Stefan and Goldberg, Christian},
	month = may,
	year = {2006},
	keywords = {Databases, SQL, Bugs, Database courses, Errors, Logical errors, Queries, Semantic errors, Software correctness, SQL exams, Static analysis, Teaching},
	pages = {630--644},
}

@misc{lewis_bart_2019,
	title = {{BART}: {Denoising} {Sequence}-to-{Sequence} {Pre}-training for {Natural} {Language} {Generation}, {Translation}, and {Comprehension}},
	shorttitle = {{BART}},
	url = {http://arxiv.org/abs/1910.13461},
	doi = {10.48550/arXiv.1910.13461},
	abstract = {We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and many other more recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of the original sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa with comparable training resources on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also report ablation experiments that replicate other pretraining schemes within the BART framework, to better measure which factors most influence end-task performance.},
	urldate = {2025-05-03},
	publisher = {arXiv},
	author = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
	month = oct,
	year = {2019},
	note = {arXiv:1910.13461 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Statistics - Machine Learning},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/J8E2XASP/Lewis et al. - 2019 - BART Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/IMZCGP6D/1910.html:text/html},
}

@misc{noauthor_hammerbench_nodate,
	title = {{HammerBench}: {Fine}-{Grained} {Function}-{Calling} {Evaluation} in {Real} {Mobile} {Assistant} {Scenarios}},
	url = {https://arxiv.org/html/2412.16516v2},
	urldate = {2025-05-12},
	file = {HammerBench\: Fine-Grained Function-Calling Evaluation in Real Mobile Assistant Scenarios:/home/extasia/snap/zotero-snap/common/Zotero/storage/396LDVRC/2412.html:text/html},
}

@misc{noauthor_stateflow_nodate,
	title = {{StateFlow}: {Enhancing} {LLM} {Task}-{Solving} through {State}-{Driven} {Workflows}},
	url = {https://arxiv.org/html/2403.11322v1},
	urldate = {2025-05-12},
	file = {StateFlow\: Enhancing LLM Task-Solving through State-Driven Workflows:/home/extasia/snap/zotero-snap/common/Zotero/storage/H66WDGKW/2403.html:text/html},
}

@misc{wu_stateflow_2024,
	title = {{StateFlow}: {Enhancing} {LLM} {Task}-{Solving} through {State}-{Driven} {Workflows}},
	shorttitle = {{StateFlow}},
	url = {http://arxiv.org/abs/2403.11322},
	doi = {10.48550/arXiv.2403.11322},
	abstract = {It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and environments. In this paper, we propose StateFlow, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines. With proper construction of states and definition of state transitions, StateFlow grounds the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process. Within each state, StateFlow allows execution of a series of actions, involving not only the generation of LLM's responses guided by a specific prompt, but also the utilization of external tools as needed. State transitions are controlled by specific rules or decisions made by the LLM, allowing for a dynamic and adaptive progression through the task's pre-defined StateFlow model. Evaluations on the InterCode SQL and Bash benchmarks show that StateFlow significantly enhances LLMs' efficiency.},
	urldate = {2025-05-12},
	publisher = {arXiv},
	author = {Wu, Yiran and Yue, Tianwei and Zhang, Shaokun and Wang, Chi and Wu, Qingyun},
	month = mar,
	year = {2024},
	note = {arXiv:2403.11322 [cs]
version: 1},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EQULZYY4/Wu et al. - 2024 - StateFlow Enhancing LLM Task-Solving through State-Driven Workflows.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/F54S6P2E/2403.html:text/html},
}

@article{schegloff_identification_nodate,
	title = {Identification and {Recog}- nition in {Telephone} {Con}- versation {Openings}},
	language = {en},
	author = {Schegloff, Emanuel A},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/FVG96LZD/Schegloff - Identification and Recog- nition in Telephone Con- versation Openings.pdf:application/pdf},
}

@misc{laban_llms_2025,
	title = {{LLMs} {Get} {Lost} {In} {Multi}-{Turn} {Conversation}},
	url = {http://arxiv.org/abs/2505.06120},
	doi = {10.48550/arXiv.2505.06120},
	abstract = {Large Language Models (LLMs) are conversational interfaces. As such, LLMs have the potential to assist their users not only when they can fully specify the task at hand, but also to help them define, explore, and refine what they need through multi-turn conversational exchange. Although analysis of LLM conversation logs has confirmed that underspecification occurs frequently in user instructions, LLM evaluation has predominantly focused on the single-turn, fully-specified instruction setting. In this work, we perform large-scale simulation experiments to compare LLM performance in single- and multi-turn settings. Our experiments confirm that all the top open- and closed-weight LLMs we test exhibit significantly lower performance in multi-turn conversations than single-turn, with an average drop of 39\% across six generation tasks. Analysis of 200,000+ simulated conversations decomposes the performance degradation into two components: a minor loss in aptitude and a significant increase in unreliability. We find that LLMs often make assumptions in early turns and prematurely attempt to generate final solutions, on which they overly rely. In simpler terms, we discover that *when LLMs take a wrong turn in a conversation, they get lost and do not recover*.},
	urldate = {2025-05-15},
	publisher = {arXiv},
	author = {Laban, Philippe and Hayashi, Hiroaki and Zhou, Yingbo and Neville, Jennifer},
	month = may,
	year = {2025},
	note = {arXiv:2505.06120 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MUKWJ7V4/Laban et al. - 2025 - LLMs Get Lost In Multi-Turn Conversation.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/95M26VZZ/2505.html:text/html},
}

@misc{laban_llms_2025-1,
	title = {{LLMs} {Get} {Lost} {In} {Multi}-{Turn} {Conversation}},
	url = {http://arxiv.org/abs/2505.06120},
	doi = {10.48550/arXiv.2505.06120},
	abstract = {Large Language Models (LLMs) are conversational interfaces. As such, LLMs have the potential to assist their users not only when they can fully specify the task at hand, but also to help them define, explore, and refine what they need through multi-turn conversational exchange. Although analysis of LLM conversation logs has confirmed that underspecification occurs frequently in user instructions, LLM evaluation has predominantly focused on the single-turn, fully-specified instruction setting. In this work, we perform large-scale simulation experiments to compare LLM performance in single- and multi-turn settings. Our experiments confirm that all the top open- and closed-weight LLMs we test exhibit significantly lower performance in multi-turn conversations than single-turn, with an average drop of 39\% across six generation tasks. Analysis of 200,000+ simulated conversations decomposes the performance degradation into two components: a minor loss in aptitude and a significant increase in unreliability. We find that LLMs often make assumptions in early turns and prematurely attempt to generate final solutions, on which they overly rely. In simpler terms, we discover that *when LLMs take a wrong turn in a conversation, they get lost and do not recover*.},
	urldate = {2025-05-15},
	publisher = {arXiv},
	author = {Laban, Philippe and Hayashi, Hiroaki and Zhou, Yingbo and Neville, Jennifer},
	month = may,
	year = {2025},
	note = {arXiv:2505.06120 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
}

@misc{chung_scaling_2022,
	title = {Scaling {Instruction}-{Finetuned} {Language} {Models}},
	url = {http://arxiv.org/abs/2210.11416},
	doi = {10.48550/arXiv.2210.11416},
	abstract = {Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM 540B by a large margin (+9.4\% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2\% on five-shot MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.},
	urldate = {2025-05-16},
	publisher = {arXiv},
	author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
	month = dec,
	year = {2022},
	note = {arXiv:2210.11416 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/3MIXNAB9/Chung et al. - 2022 - Scaling Instruction-Finetuned Language Models.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DXEL3YSX/2210.html:text/html},
}

@misc{noauthor_llm4fin_nodate,
	title = {{LLM4Fin}: {Fully} {Automating} {LLM}-{Powered} {Test} {Case} {Generation} for {FinTech} {Software} {Acceptance} {Testing} {\textbar} {Proceedings} of the 33rd {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	url = {https://dl.acm.org/doi/abs/10.1145/3650212.3680388},
	urldate = {2025-05-26},
	file = {LLM4Fin\: Fully Automating LLM-Powered Test Case Generation for FinTech Software Acceptance Testing | Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis:/home/extasia/snap/zotero-snap/common/Zotero/storage/BJY75984/3650212.html:text/html},
}

@inproceedings{xue_llm4fin_2024,
	address = {New York, NY, USA},
	series = {{ISSTA} 2024},
	title = {{LLM4Fin}: {Fully} {Automating} {LLM}-{Powered} {Test} {Case} {Generation} for {FinTech} {Software} {Acceptance} {Testing}},
	isbn = {979-8-4007-0612-7},
	shorttitle = {{LLM4Fin}},
	url = {https://dl.acm.org/doi/10.1145/3650212.3680388},
	doi = {10.1145/3650212.3680388},
	abstract = {FinTech software, crucial for both safety and timely market deployment, presents a compelling case for automated acceptance testing against regulatory business rules. However, the inherent challenges of comprehending unstructured natural language descriptions of these rules and crafting comprehensive test cases demand human intelligence. The emergence of Large Language Models (LLMs) holds promise for automated test case generation, leveraging their natural language processing capabilities. Yet, their dependence on human intervention for effective prompting hampers efficiency.    In response, we introduce a groundbreaking, fully automated approach for generating high-coverage test cases from natural language business rules. Our methodology seamlessly integrates the versatility of LLMs with the predictability of algorithmic methods. We fine-tune pre-trained LLMs for improved information extraction accuracy and algorithmically generate comprehensive testable scenarios for the extracted business rules.	Our prototype, LLM4Fin, is designed for testing real-world stock-trading software. Experimental results demonstrate LLM4Fin’s superiority over both state-of-the-art LLM, such as ChatGPT, and skilled testing engineers. We achieve remarkable performance, with up to 98.18\% and an average of 20\%−110\% improvement on business scenario coverage, and up to 93.72\% on code coverage, while reducing the time cost from 20 minutes to a mere 7 seconds. These results provide robust evidence of the framework’s practical applicability and efficiency, marking a significant advancement in FinTech software testing.},
	urldate = {2025-05-26},
	booktitle = {Proceedings of the 33rd {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {Association for Computing Machinery},
	author = {Xue, Zhiyi and Li, Liangguo and Tian, Senyue and Chen, Xiaohong and Li, Pingping and Chen, Liangyu and Jiang, Tingting and Zhang, Min},
	month = sep,
	year = {2024},
	pages = {1643--1655},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/W2ZMKQG2/Xue et al. - 2024 - LLM4Fin Fully Automating LLM-Powered Test Case Generation for FinTech Software Acceptance Testing.pdf:application/pdf},
}

@inproceedings{yuan_user_2020,
	address = {New York, NY, USA},
	series = {{CUI} '20},
	title = {User {Preference} and {Categories} for {Error} {Responses} in {Conversational} {User} {Interfaces}},
	isbn = {978-1-4503-7544-3},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406126},
	doi = {10.1145/3405755.3406126},
	abstract = {Error messages are frequent in interactions with Conversational User Interfaces (CUI). Smart speakers respond to about every third user request with an error message. Errors can heavily affect user experience (UX) in interaction with CUI. However, there is limited research on how error responses should be formulated. In this paper, we present a system to study how people classify different categories (acknowledgement of user sentiment, acknowledgement of error and apology) of error messages, and evaluate peoples' preference of error responses with clear categories. The results indicate that if an error response has only one element (i.e. neutral acknowledgement of error, apology or sentiment), responses that acknowledge errors neutrally are preferred by participants. Moreover, we find that when interviewed, participants like error messages to include an apology, an explanation of what went wrong, and a suggestion how to fix the problem in addition to a neutral acknowledgement of an error. Our study has two main contributions: (1) our results inform about the design of error messages and (2) we present a framework for error response categorization and validation.},
	urldate = {2025-05-26},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {Association for Computing Machinery},
	author = {Yuan, Sihan and Brüggemeier, Birgit and Hillmann, Stefan and Michael, Thilo},
	month = jul,
	year = {2020},
	pages = {1--8},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/U8YDM2BN/Yuan et al. - 2020 - User Preference and Categories for Error Responses in Conversational User Interfaces.pdf:application/pdf},
}

@article{wu_mapping_2019,
	title = {Mapping {ICD}-10 and {ICD}-10-{CM} {Codes} to {Phecodes}: {Workflow} {Development} and {Initial} {Evaluation}},
	volume = {7},
	issn = {2291-9694},
	shorttitle = {Mapping {ICD}-10 and {ICD}-10-{CM} {Codes} to {Phecodes}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6911227/},
	doi = {10.2196/14325},
	abstract = {Background
The phecode system was built upon the International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) for phenome-wide association studies (PheWAS) using the electronic health record (EHR).

Objective
The goal of this paper was to develop and perform an initial evaluation of maps from the International Classification of Diseases, 10th Revision (ICD-10) and the International Classification of Diseases, 10th Revision, Clinical Modification (ICD-10-CM) codes to phecodes.

Methods
We mapped ICD-10 and ICD-10-CM codes to phecodes using a number of methods and resources, such as concept relationships and explicit mappings from the Centers for Medicare \& Medicaid Services, the Unified Medical Language System, Observational Health Data Sciences and Informatics, Systematized Nomenclature of Medicine-Clinical Terms, and the National Library of Medicine. We assessed the coverage of the maps in two databases: Vanderbilt University Medical Center (VUMC) using ICD-10-CM and the UK Biobank (UKBB) using ICD-10. We assessed the fidelity of the ICD-10-CM map in comparison to the gold-standard ICD-9-CM phecode map by investigating phenotype reproducibility and conducting a PheWAS.

Results
We mapped {\textgreater}75\% of ICD-10 and ICD-10-CM codes to phecodes. Of the unique codes observed in the UKBB (ICD-10) and VUMC (ICD-10-CM) cohorts, {\textgreater}90\% were mapped to phecodes. We observed 70-75\% reproducibility for chronic diseases and {\textless}10\% for an acute disease for phenotypes sourced from the ICD-10-CM phecode map. Using the ICD-9-CM and ICD-10-CM maps, we conducted a PheWAS with a Lipoprotein(a) genetic variant, rs10455872, which replicated two known genotype-phenotype associations with similar effect sizes: coronary atherosclerosis (ICD-9-CM: P{\textless}.001; odds ratio (OR) 1.60 [95\% CI 1.43-1.80] vs ICD-10-CM: P{\textless}.001; OR 1.60 [95\% CI 1.43-1.80]) and chronic ischemic heart disease (ICD-9-CM: P{\textless}.001; OR 1.56 [95\% CI 1.35-1.79] vs ICD-10-CM: P{\textless}.001; OR 1.47 [95\% CI 1.22-1.77]).

Conclusions
This study introduces the beta versions of ICD-10 and ICD-10-CM to phecode maps that enable researchers to leverage accumulated ICD-10 and ICD-10-CM data for PheWAS in the EHR.},
	number = {4},
	urldate = {2025-05-27},
	journal = {JMIR Medical Informatics},
	author = {Wu, Patrick and Gifford, Aliya and Meng, Xiangrui and Li, Xue and Campbell, Harry and Varley, Tim and Zhao, Juan and Carroll, Robert and Bastarache, Lisa and Denny, Joshua C and Theodoratou, Evropi and Wei, Wei-Qi},
	month = nov,
	year = {2019},
	pmid = {31553307},
	pmcid = {PMC6911227},
	pages = {e14325},
	file = {Accepted Version:/home/extasia/snap/zotero-snap/common/Zotero/storage/7CCUD576/Wu et al. - 2019 - Mapping ICD-10 and ICD-10-CM Codes to Phecodes Workflow Development and Initial Evaluation.pdf:application/pdf},
}

@article{bengio_neural_nodate,
	title = {A {Neural} {Probabilistic} {Language} {Model}},
	abstract = {A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difﬁcult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to ﬁght the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a signiﬁcant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach signiﬁcantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.},
	language = {en},
	author = {Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and Jauvin, Christian},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/A4BTD9Z7/Bengio et al. - A Neural Probabilistic Language Model.pdf:application/pdf},
}

@misc{ganin_unsupervised_2015,
	title = {Unsupervised {Domain} {Adaptation} by {Backpropagation}},
	url = {http://arxiv.org/abs/1409.7495},
	doi = {10.48550/arXiv.1409.7495},
	abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of "deep" features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation. Overall, the approach can be implemented with little effort using any of the deep-learning packages. The method performs very well in a series of image classification experiments, achieving adaptation effect in the presence of big domain shifts and outperforming previous state-of-the-art on Office datasets.},
	urldate = {2025-06-07},
	publisher = {arXiv},
	author = {Ganin, Yaroslav and Lempitsky, Victor},
	month = feb,
	year = {2015},
	note = {arXiv:1409.7495 [stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/X9UKS4CH/Ganin and Lempitsky - 2015 - Unsupervised Domain Adaptation by Backpropagation.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/5AD7SSKA/1409.html:text/html},
}

@inproceedings{wang_colacare_2025,
	title = {{ColaCare}: {Enhancing} {Electronic} {Health} {Record} {Modeling} through {Large} {Language} {Model}-{Driven} {Multi}-{Agent} {Collaboration}},
	shorttitle = {{ColaCare}},
	url = {http://arxiv.org/abs/2410.02551},
	doi = {10.1145/3696410.3714877},
	abstract = {We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. All code, case studies and a questionnaire are available at the project website: https://colacare.netlify.app.},
	urldate = {2025-06-23},
	booktitle = {Proceedings of the {ACM} on {Web} {Conference} 2025},
	author = {Wang, Zixiang and Zhu, Yinghao and Zhao, Huiya and Zheng, Xiaochen and Sui, Dehao and Wang, Tianlong and Tang, Wen and Wang, Yasha and Harrison, Ewen and Pan, Chengwei and Gao, Junyi and Ma, Liantao},
	month = apr,
	year = {2025},
	note = {arXiv:2410.02551 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	pages = {2250--2261},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/HMK2F7WX/Wang et al. - 2025 - ColaCare Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agen.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/B875BTTX/2410.html:text/html},
}

@inproceedings{jin_instructor_2023,
	address = {Singapore},
	title = {{InstructoR}: {Instructing} {Unsupervised} {Conversational} {Dense} {Retrieval} with {Large} {Language} {Models}},
	shorttitle = {{InstructoR}},
	url = {https://aclanthology.org/2023.findings-emnlp.443/},
	doi = {10.18653/v1/2023.findings-emnlp.443},
	abstract = {Compared to traditional single-turn ad-hoc retrieval, conversational retrieval needs to handle the multi-turn conversation and understand the user's real query intent. However, most existing methods simply fine-tune the pre-trained ad-hoc retriever on limited supervised data, making it challenging for the retriever to fully grasp the entirety of the conversation. In this paper, we find that large language models (LLMs) can accurately discover the user's query intent from the complex conversation context and provide the supervised signal to instruct the retriever in an unsupervised manner. Therefore, we propose a novel method termed InstructoR to Instruct unsupervised conversational dense Retrieval with LLMs. We design an unsupervised training framework that employs LLMs to estimate the session-passage relevance score as the soft label to guide the retriever's training. Specially, we devise three instructing strategies from context, query and response perspectives to calculate the relevance score more precisely, including conversational retrieval as conversation generation, question rewrite as latent variable and question response as posterior guide. Experimental results show InstructoR can bring significant improvements across various ad-hoc retrievers, even surpassing the current supervised state-of-the-art method. We also demonstrate the effectiveness of our method under low-resource and zero-shot settings. Our code is publicly available at https://github.com/jinzhuoran/InstructoR/.},
	urldate = {2025-06-27},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {EMNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Jin, Zhuoran and Cao, Pengfei and Chen, Yubo and Liu, Kang and Zhao, Jun},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	month = dec,
	year = {2023},
	pages = {6649--6675},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/2S52ZJND/Jin et al. - 2023 - InstructoR Instructing Unsupervised Conversational Dense Retrieval with Large Language Models.pdf:application/pdf},
}

@misc{mo_survey_2024,
	title = {A {Survey} of {Conversational} {Search}},
	url = {http://arxiv.org/abs/2410.15576},
	doi = {10.48550/arXiv.2410.15576},
	abstract = {As a cornerstone of modern information access, search engines have become indispensable in everyday life. With the rapid advancements in AI and natural language processing (NLP) technologies, particularly large language models (LLMs), search engines have evolved to support more intuitive and intelligent interactions between users and systems. Conversational search, an emerging paradigm for next-generation search engines, leverages natural language dialogue to facilitate complex and precise information retrieval, thus attracting significant attention. Unlike traditional keyword-based search engines, conversational search systems enhance user experience by supporting intricate queries, maintaining context over multi-turn interactions, and providing robust information integration and processing capabilities. Key components such as query reformulation, search clarification, conversational retrieval, and response generation work in unison to enable these sophisticated interactions. In this survey, we explore the recent advancements and potential future directions in conversational search, examining the critical modules that constitute a conversational search system. We highlight the integration of LLMs in enhancing these systems and discuss the challenges and opportunities that lie ahead in this dynamic field. Additionally, we provide insights into real-world applications and robust evaluations of current conversational search systems, aiming to guide future research and development in conversational search.},
	urldate = {2025-06-27},
	publisher = {arXiv},
	author = {Mo, Fengran and Mao, Kelong and Zhao, Ziliang and Qian, Hongjin and Chen, Haonan and Cheng, Yiruo and Li, Xiaoxi and Zhu, Yutao and Dou, Zhicheng and Nie, Jian-Yun},
	month = oct,
	year = {2024},
	note = {arXiv:2410.15576 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GMFXHRCD/Mo et al. - 2024 - A Survey of Conversational Search.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/JG7SW2R7/2410.html:text/html},
}

@misc{zhang_agentic_2025,
	title = {Agentic {Information} {Retrieval}},
	url = {http://arxiv.org/abs/2410.09713},
	doi = {10.48550/arXiv.2410.09713},
	abstract = {Since the 1970s, information retrieval (IR) has long been defined as the process of acquiring relevant information items from a pre-defined corpus to satisfy user information needs. Traditional IR systems, while effective in domains like web search, are constrained by their reliance on static, pre-defined information items. To this end, this paper introduces agentic information retrieval (Agentic IR), a transformative next-generation paradigm for IR driven by large language models (LLMs) and AI agents. The central shift in agentic IR is the evolving definition of ``information'' from static, pre-defined information items to dynamic, context-dependent information states. Information state refers to a particular information context that the user is right in within a dynamic environment, encompassing not only the acquired information items but also real-time user preferences, contextual factors, and decision-making processes. In such a way, traditional information retrieval, focused on acquiring relevant information items based on user queries, can be naturally extended to achieving the target information state given the user instruction, which thereby defines the agentic information retrieval. We systematically discuss agentic IR from various aspects, i.e., task formulation, architecture, evaluation, case studies, as well as challenges and future prospects. We believe that the concept of agentic IR introduced in this paper not only broadens the scope of information retrieval research but also lays the foundation for a more adaptive, interactive, and intelligent next-generation IR paradigm.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Zhang, Weinan and Liao, Junwei and Li, Ning and Du, Kounianhua and Lin, Jianghao},
	month = feb,
	year = {2025},
	note = {arXiv:2410.09713 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, important},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EGK436ZH/Zhang et al. - 2025 - Agentic Information Retrieval.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/K7DL49B8/2410.html:text/html},
}

@misc{wang_survey_2025,
	title = {A {Survey} of {LLM}-based {Agents} in {Medicine}: {How} far are we from {Baymax}?},
	shorttitle = {A {Survey} of {LLM}-based {Agents} in {Medicine}},
	url = {http://arxiv.org/abs/2502.11211},
	doi = {10.48550/arXiv.2502.11211},
	abstract = {Large Language Models (LLMs) are transforming healthcare through the development of LLM-based agents that can understand, reason about, and assist with medical tasks. This survey provides a comprehensive review of LLM-based agents in medicine, examining their architectures, applications, and challenges. We analyze the key components of medical agent systems, including system profiles, clinical planning mechanisms, medical reasoning frameworks, and external capacity enhancement. The survey covers major application scenarios such as clinical decision support, medical documentation, training simulations, and healthcare service optimization. We discuss evaluation frameworks and metrics used to assess these agents' performance in healthcare settings. While LLM-based agents show promise in enhancing healthcare delivery, several challenges remain, including hallucination management, multimodal integration, implementation barriers, and ethical considerations. The survey concludes by highlighting future research directions, including advances in medical reasoning inspired by recent developments in LLM architectures, integration with physical systems, and improvements in training simulations. This work provides researchers and practitioners with a structured overview of the current state and future prospects of LLM-based agents in medicine.},
	urldate = {2025-06-24},
	publisher = {arXiv},
	author = {Wang, Wenxuan and Ma, Zizhan and Wang, Zheng and Wu, Chenghan and Ji, Jiaming and Chen, Wenting and Li, Xiang and Yuan, Yixuan},
	month = may,
	year = {2025},
	note = {arXiv:2502.11211 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PUGCNMNX/Wang et al. - 2025 - A Survey of LLM-based Agents in Medicine How far are we from Baymax.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/BLSGR3FK/2502.html:text/html},
}

@misc{gan_clarq-llm_2024,
	title = {{ClarQ}-{LLM}: {A} {Benchmark} for {Models} {Clarifying} and {Requesting} {Information} in {Task}-{Oriented} {Dialog}},
	shorttitle = {{ClarQ}-{LLM}},
	url = {http://arxiv.org/abs/2409.06097},
	doi = {10.48550/arXiv.2409.06097},
	abstract = {We introduce ClarQ-LLM, an evaluation framework consisting of bilingual English-Chinese conversation tasks, conversational agents and evaluation metrics, designed to serve as a strong benchmark for assessing agents' ability to ask clarification questions in task-oriented dialogues. The benchmark includes 31 different task types, each with 10 unique dialogue scenarios between information seeker and provider agents. The scenarios require the seeker to ask questions to resolve uncertainty and gather necessary information to complete tasks. Unlike traditional benchmarks that evaluate agents based on fixed dialogue content, ClarQ-LLM includes a provider conversational agent to replicate the original human provider in the benchmark. This allows both current and future seeker agents to test their ability to complete information gathering tasks through dialogue by directly interacting with our provider agent. In tests, LLAMA3.1 405B seeker agent managed a maximum success rate of only 60.05{\textbackslash}\%, showing that ClarQ-LLM presents a strong challenge for future research.},
	urldate = {2025-07-08},
	publisher = {arXiv},
	author = {Gan, Yujian and Li, Changling and Xie, Jinxia and Wen, Luou and Purver, Matthew and Poesio, Massimo},
	month = sep,
	year = {2024},
	note = {arXiv:2409.06097 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/J3SHPML7/Gan et al. - 2024 - ClarQ-LLM A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/6CU2KLDN/2409.html:text/html},
}

@article{yao_reac_2023,
	title = {{REAC} {T}: {SYNERGIZING} {REASONING} {AND} {ACTING} {IN} {LANGUAGE} {MODELS}},
	abstract = {While large language models (LLMs) have demonstrated impressive performance across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-speciﬁc actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with and gather additional information from external sources such as knowledge bases or environments. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines in addition to improved human interpretability and trustworthiness. Concretely, on question answering (HotpotQA) and fact veriﬁcation (Fever), ReAct overcomes prevalent issues of hallucination and error propagation in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generating human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. Furthermore, on two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples.},
	language = {en},
	author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
	year = {2023},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/T4CSAUEP/Yao et al. - 2023 - REAC T SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS.pdf:application/pdf},
}

@article{bajwah_effectiveness_2020,
	title = {The effectiveness and cost-effectiveness of hospital-based specialist palliative care for adults with advanced illness and their caregivers},
	volume = {2020},
	issn = {1465-1858},
	url = {http://doi.wiley.com/10.1002/14651858.CD012780.pub2},
	doi = {10.1002/14651858.cd012780.pub2},
	language = {en},
	number = {9},
	urldate = {2025-07-18},
	journal = {Cochrane Database of Systematic Reviews},
	author = {Bajwah, Sabrina and Oluyase, Adejoke O and Yi, Deokhee and Gao, Wei and Evans, Catherine J and Grande, Gunn and Todd, Chris and Costantini, Massimo and Murtagh, Fliss E and Higginson, Irene J},
	editor = {{Cochrane Pain, Palliative and Supportive Care Group}},
	month = sep,
	year = {2020},
	note = {Publisher: Wiley},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/HUN6Z4FW/Bajwah et al. - 2020 - The effectiveness and cost-effectiveness of hospital-based specialist palliative care for adults wit.pdf:application/pdf},
}

@article{chochinov_intensive_2023,
	title = {Intensive {Caring}: {Reminding} {Patients} {They} {Matter}},
	volume = {41},
	issn = {0732-183X, 1527-7755},
	shorttitle = {Intensive {Caring}},
	url = {https://ascopubs.org/doi/10.1200/JCO.23.00042},
	doi = {10.1200/jco.23.00042},
	language = {en},
	number = {16},
	urldate = {2025-07-18},
	journal = {Journal of Clinical Oncology},
	author = {Chochinov, Harvey Max},
	month = jun,
	year = {2023},
	note = {Publisher: American Society of Clinical Oncology (ASCO)},
	pages = {2884--2887},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/8PETN56M/Chochinov - 2023 - Intensive Caring Reminding Patients They Matter.pdf:application/pdf},
}

@article{nafilyan_risk_2023,
	title = {Risk of suicide after diagnosis of severe physical health conditions: a retrospective cohort study of 47 million people},
	volume = {25},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {2666-7762},
	shorttitle = {Risk of suicide after diagnosis of severe physical health conditions},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666776222002587},
	doi = {10.1016/j.lanepe.2022.100562},
	language = {en},
	urldate = {2025-07-18},
	journal = {The Lancet Regional Health - Europe},
	author = {Nafilyan, Vahé and Morgan, Jasper and Mais, David and Sleeman, Katherine E. and Butt, Asim and Ward, Isobel and Tucker, James and Appleby, Louis and Glickman, Myer},
	month = feb,
	year = {2023},
	note = {Publisher: Elsevier BV},
	pages = {100562},
}

@article{yan_grief_2023,
	title = {Grief and bereavement of family and friends around medical assistance in dying: scoping review},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by-nc/4.0/},
	issn = {2045-435X, 2045-4368},
	shorttitle = {Grief and bereavement of family and friends around medical assistance in dying},
	url = {https://spcare.bmj.com/lookup/doi/10.1136/spcare-2022-003715},
	doi = {10.1136/spcare-2022-003715},
	abstract = {ObjectivesThe increase in the number of jurisdictions legalising medical assistance in dying (MAiD) has contributed to a growth in the number of family and friends who may face unique elements of grief and bereavement. The aim of this study was to review the literature of grief and bereavement of family and friends following MAiD, and to summarise findings for the development of community resources and programming.MethodsWe performed a scoping review with workshop consultation of stakeholders. Six electronic databases and the grey literature were searched for qualitative, quantitative and review articles. Content-analytical techniques and multidisciplinary discussions led to the development of concepts and a conceptual framework.ResultsTwenty-eight articles met the inclusion criteria. We identified five concepts that impact the grief and bereavement of family/friends: relationships between family/friends and the patient as well as healthcare providers; aspects of MAiD grief which can include secrecy and/or anticipatory grief; preparations which may include family/friends and should be centralised and harmonised; end of life as an opportunity for ceremony; and the aftereffects during which mental health outcomes are studied.ConclusionThis multidisciplinary scoping review incorporates stakeholder consultation to find that support is needed to address the complicated and changing emotions of family/friends before, during and after a MAiD death. Furthermore, additional societal normalisation of MAiD is necessary to reduce secrecy and stigma and improve the accessibility of resources for family/friends.},
	language = {en},
	number = {4},
	urldate = {2025-07-18},
	journal = {BMJ Supportive \& Palliative Care},
	author = {Yan, Han and Bytautas, Jessica and Isenberg, Sarina Roslyn and Kaplan, Ari and Hashemi, Narges and Kornberg, Mona and Hendrickson, Tekla},
	month = dec,
	year = {2023},
	note = {Publisher: BMJ},
	pages = {414--428},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/QQDW73U5/Yan et al. - 2023 - Grief and bereavement of family and friends around medical assistance in dying scoping review.pdf:application/pdf},
}

@article{falis_addressing_nodate,
	title = {Addressing {Concept} {Sparsity} in {Medical} {Text} with {Medical} {Ontologies}},
	language = {en},
	author = {Falis, Matusˇ},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/WD8YEIAH/Falis - Addressing Concept Sparsity in Medical Text with Medical Ontologies.pdf:application/pdf},
}

@article{falis_addressing_nodate-1,
	title = {Addressing {Concept} {Sparsity} in {Medical} {Text} with {Medical} {Ontologies}},
	language = {en},
	author = {Falis, Matusˇ},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/GTMN4EQZ/Falis - Addressing Concept Sparsity in Medical Text with Medical Ontologies.pdf:application/pdf},
}

@inproceedings{wen_network-based_2017,
	address = {Valencia, Spain},
	title = {A {Network}-based {End}-to-{End} {Trainable} {Task}-oriented {Dialogue} {System}},
	url = {https://aclanthology.org/E17-1042/},
	abstract = {Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.},
	urldate = {2025-08-18},
	booktitle = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Volume} 1, {Long} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Wen, Tsung-Hsien and Vandyke, David and Mrkšić, Nikola and Gašić, Milica and Rojas-Barahona, Lina M. and Su, Pei-Hao and Ultes, Stefan and Young, Steve},
	editor = {Lapata, Mirella and Blunsom, Phil and Koller, Alexander},
	month = apr,
	year = {2017},
	pages = {438--449},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KSB3D2PJ/Wen et al. - 2017 - A Network-based End-to-End Trainable Task-oriented Dialogue System.pdf:application/pdf},
}

@misc{jiang_medagentbench_2025,
	title = {{MedAgentBench}: {A} {Realistic} {Virtual} {EHR} {Environment} to {Benchmark} {Medical} {LLM} {Agents}},
	shorttitle = {{MedAgentBench}},
	url = {http://arxiv.org/abs/2501.14654},
	doi = {10.48550/arXiv.2501.14654},
	abstract = {Recent large language models (LLMs) have demonstrated significant advancements, particularly in their ability to serve as agents thereby surpassing their traditional role as chatbots. These agents can leverage their planning and tool utilization capabilities to address tasks specified at a high level. However, a standardized dataset to benchmark the agent capabilities of LLMs in medical applications is currently lacking, making the evaluation of LLMs on complex tasks in interactive healthcare environments challenging. To address this gap, we introduce MedAgentBench, a broad evaluation suite designed to assess the agent capabilities of large language models within medical records contexts. MedAgentBench encompasses 300 patient-specific clinically-derived tasks from 10 categories written by human physicians, realistic profiles of 100 patients with over 700,000 data elements, a FHIR-compliant interactive environment, and an accompanying codebase. The environment uses the standard APIs and communication infrastructure used in modern EMR systems, so it can be easily migrated into live EMR systems. MedAgentBench presents an unsaturated agent-oriented benchmark that current state-of-the-art LLMs exhibit some ability to succeed at. The best model (Claude 3.5 Sonnet v2) achieves a success rate of 69.67\%. However, there is still substantial space for improvement which gives the community a next direction to optimize. Furthermore, there is significant variation in performance across task categories. MedAgentBench establishes this and is publicly available at https://github.com/stanfordmlgroup/MedAgentBench , offering a valuable framework for model developers to track progress and drive continuous improvements in the agent capabilities of large language models within the medical domain.},
	urldate = {2025-07-29},
	publisher = {arXiv},
	author = {Jiang, Yixing and Black, Kameron C. and Geng, Gloria and Park, Danny and Zou, James and Ng, Andrew Y. and Chen, Jonathan H.},
	month = feb,
	year = {2025},
	note = {arXiv:2501.14654 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/T7FKI7CI/Jiang et al. - 2025 - MedAgentBench A Realistic Virtual EHR Environment.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/XQFBC53J/2501.html:text/html},
}

@inproceedings{xu_rethinking_2024,
	address = {Bangkok, Thailand},
	title = {Rethinking {Task}-{Oriented} {Dialogue} {Systems}: {From} {Complex} {Modularity} to {Zero}-{Shot} {Autonomous} {Agent}},
	shorttitle = {Rethinking {Task}-{Oriented} {Dialogue} {Systems}},
	url = {https://aclanthology.org/2024.acl-long.152/},
	doi = {10.18653/v1/2024.acl-long.152},
	abstract = {Task-oriented dialogue (TOD) systems are predominantly designed to be composed of several functional modules (e.g. dialogue state tracker, dialogue policy, natural language generation) whether they are pipeline or end-to-end architectures. However, this modular design not only heavily relies on massive fully-annotated data, but also suffers from many intrinsic drawbacks, such as serious error accumulation, poor generalization ability, high customization cost, and low fault tolerance rate. In this paper, we rethink the architecture of the task-oriented dialogue systems and propose a novel fully zero-shot autonomous TOD agent, named AutoTOD, where all the delicate modules in traditional TOD systems are deprecated and all it needs is a general-purpose instruction-following language model (e.g. GPT-4). AutoTOD only leverages a simple instruction schema consisting of the description of tasks and external APIs, and can autonomously decide what to do at each dialogue turn, including asking for information, calling APIs, summarizing API results, and correcting previous mistakes. Moreover, we propose a simulation-based evaluation framework to better validate the abilities of TOD models in real-life scenarios. Extensive experiments conducted on the MultiWOZ and SGD datasets show the superior task completion ability and flexible language skills of AutoTOD.},
	urldate = {2025-08-20},
	booktitle = {Proceedings of the 62nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Xu, Heng-Da and Mao, Xian-Ling and Yang, Puhai and Sun, Fanshu and Huang, Heyan},
	editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
	month = aug,
	year = {2024},
	pages = {2748--2763},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/PGT7X8Y5/Xu et al. - 2024 - Rethinking Task-Oriented Dialogue Systems From Complex Modularity to Zero-Shot Autonomous Agent.pdf:application/pdf},
}

@misc{noauthor_total_nodate,
	title = {Total healthcare spending as a share of {GDP}},
	url = {https://ourworldindata.org/grapher/total-healthcare-expenditure-gdp},
	abstract = {Total healthcare expenditure as the share of national gross domestic product (GDP).},
	language = {en},
	urldate = {2025-08-21},
	journal = {Our World in Data},
	file = {Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/RVKXX9AD/total-healthcare-expenditure-gdp.html:text/html},
}

@book{snow_mode_1855,
	title = {On the mode of communication of cholera},
	copyright = {{\textless}a href="http://creativecommons.org/publicdomain/mark/1.0/" rel="ugc nofollow"{\textgreater}This work is available under the Creative Commons, Public Domain Mark{\textless}/a{\textgreater}},
	url = {http://archive.org/details/b28985266},
	abstract = {Includes bibliographical footnotes},
	language = {eng},
	urldate = {2025-08-21},
	publisher = {London : John Churchill},
	author = {Snow, John},
	collaborator = {{Wellcome Library}},
	year = {1855},
	keywords = {Cholera},
}

@misc{kwa_measuring_2025,
	title = {Measuring {AI} {Ability} to {Complete} {Long} {Tasks}},
	url = {http://arxiv.org/abs/2503.14499},
	doi = {10.48550/arXiv.2503.14499},
	abstract = {Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human capabilities, we propose a new metric: 50\%-task-completion time horizon. This is the time humans typically take to complete tasks that AI models can complete with 50\% success rate. We first timed humans with relevant domain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter tasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet have a 50\% time horizon of around 50 minutes. Furthermore, frontier AI time horizon has been doubling approximately every seven months since 2019, though the trend may have accelerated in 2024. The increase in AI models' time horizons seems to be primarily driven by greater reliability and ability to adapt to mistakes, combined with better logical reasoning and tool use capabilities. We discuss the limitations of our results -- including their degree of external validity -- and the implications of increased autonomy for dangerous capabilities. If these results generalize to real-world software tasks, extrapolation of this trend predicts that within 5 years, AI systems will be capable of automating many software tasks that currently take humans a month.},
	urldate = {2025-08-26},
	publisher = {arXiv},
	author = {Kwa, Thomas and West, Ben and Becker, Joel and Deng, Amy and Garcia, Katharyn and Hasin, Max and Jawhar, Sami and Kinniment, Megan and Rush, Nate and Arx, Sydney Von and Bloom, Ryan and Broadley, Thomas and Du, Haoxing and Goodrich, Brian and Jurkovic, Nikola and Miles, Luke Harold and Nix, Seraphina and Lin, Tao and Parikh, Neev and Rein, David and Sato, Lucas Jun Koba and Wijk, Hjalmar and Ziegler, Daniel M. and Barnes, Elizabeth and Chan, Lawrence},
	month = mar,
	year = {2025},
	note = {arXiv:2503.14499 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/JI5MX763/Kwa et al. - 2025 - Measuring AI Ability to Complete Long Tasks.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/DPFHRCDJ/2503.html:text/html},
}

@misc{yi_survey_2025,
	title = {A {Survey} on {Recent} {Advances} in {LLM}-{Based} {Multi}-turn {Dialogue} {Systems}},
	url = {http://arxiv.org/abs/2402.18013},
	doi = {10.48550/arXiv.2402.18013},
	abstract = {This survey provides a comprehensive review of research on multi-turn dialogue systems, with a particular focus on multi-turn dialogue systems based on large language models (LLMs). This paper aims to (a) give a summary of existing LLMs and approaches for adapting LLMs to downstream tasks; (b) elaborate recent advances in multi-turn dialogue systems, covering both LLM-based open-domain dialogue (ODD) and task-oriented dialogue (TOD) systems, along with datasets and evaluation metrics; (c) discuss some future emphasis and recent research problems arising from the development of LLMs and the increasing demands on multi-turn dialogue systems.},
	urldate = {2025-08-26},
	publisher = {arXiv},
	author = {Yi, Zihao and Ouyang, Jiarui and Xu, Zhe and Liu, Yuwen and Liao, Tianhao and Luo, Haohao and Shen, Ying},
	month = aug,
	year = {2025},
	note = {arXiv:2402.18013 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/EVNXI53D/Yi et al. - 2025 - A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/LMCU98U8/2402.html:text/html},
}

@article{andreas_task-oriented_2020,
	title = {Task-{Oriented} {Dialogue} as {Dataflow} {Synthesis}},
	volume = {8},
	issn = {2307-387X},
	url = {https://doi.org/10.1162/tacl_a_00333},
	doi = {10.1162/tacl_a_00333},
	abstract = {We describe an approach to task-oriented dialogue in which dialogue state is represented as a dataflow graph. A dialogue agent maps each user utterance to a program that extends this graph. Programs include metacomputation operators for reference and revision that reuse dataflow fragments from previous turns. Our graph-based state enables the expression and manipulation of complex user intents, and explicit metacomputation makes these intents easier for learned models to predict. We introduce a new dataset, SMCalFlow, featuring complex dialogues about events, weather, places, and people. Experiments show that dataflow graphs and metacomputation substantially improve representability and predictability in these natural dialogues. Additional experiments on the MultiWOZ dataset show that our dataflow representation enables an otherwise off-the-shelf sequence-to-sequence model to match the best existing task-specific state tracking model. The SMCalFlow dataset, code for replicating experiments, and a public leaderboard are available at https://www.microsoft.com/en-us/research/project/dataflow-based-dialogue-semantic-machines.},
	urldate = {2025-08-27},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Andreas, Jacob and Bufe, John and Burkett, David and Chen, Charles and Clausman, Josh and Crawford, Jean and Crim, Kate and DeLoach, Jordan and Dorner, Leah and Eisner, Jason and Fang, Hao and Guo, Alan and Hall, David and Hayes, Kristin and Hill, Kellie and Ho, Diana and Iwaszuk, Wendy and Jha, Smriti and Klein, Dan and Krishnamurthy, Jayant and Lanman, Theo and Liang, Percy and Lin, Christopher H. and Lintsbakh, Ilya and McGovern, Andy and Nisnevich, Aleksandr and Pauls, Adam and Petters, Dmitrij and Read, Brent and Roth, Dan and Roy, Subhro and Rusak, Jesse and Short, Beth and Slomin, Div and Snyder, Ben and Striplin, Stephon and Su, Yu and Tellman, Zachary and Thomson, Sam and Vorobev, Andrei and Witoszko, Izabela and Wolfe, Jason and Wray, Abby and Zhang, Yuchen and Zotov, Alexander},
	month = sep,
	year = {2020},
	pages = {556--571},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/V4WT5DH3/Andreas et al. - 2020 - Task-Oriented Dialogue as Dataflow Synthesis.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/ES7UDFA2/tacl_a_00333.html:text/html},
}

@article{berwick_triple_2008,
	title = {The {Triple} {Aim}: {Care}, {Health}, {And} {Cost}},
	volume = {27},
	issn = {0278-2715, 1544-5208},
	shorttitle = {The {Triple} {Aim}},
	url = {http://www.healthaffairs.org/doi/10.1377/hlthaff.27.3.759},
	doi = {10.1377/hlthaff.27.3.759},
	language = {en},
	number = {3},
	urldate = {2025-08-28},
	journal = {Health Affairs},
	author = {Berwick, Donald M. and Nolan, Thomas W. and Whittington, John},
	month = may,
	year = {2008},
	pages = {759--769},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/I9ZI7JR3/Berwick et al. - 2008 - The Triple Aim Care, Health, And Cost.pdf:application/pdf},
}

@article{yasnoff_public_2000,
	title = {Public health informatics: improving and transforming public health in the information age},
	volume = {6},
	issn = {1078-4659},
	shorttitle = {Public health informatics},
	doi = {10.1097/00124784-200006060-00010},
	abstract = {Development of effective public health information systems requires understanding public health informatics (PHI), the systematic application of information and computer science and technology to public health practice, research, and learning. PHI is distinguished from other informatics specialties by its focus on prevention in populations, use of a wide range of interventions to achieve its goals, and the constraints of operating in a governmental context. The current need for PHI arises from dramatic improvements in information technology, new pressures on the public health system, and changes in medical care delivery. Application of PHI principles provides unprecedented opportunities to build healthier communities.},
	language = {eng},
	number = {6},
	journal = {Journal of public health management and practice: JPHMP},
	author = {Yasnoff, W. A. and O'Carroll, P. W. and Koo, D. and Linkins, R. W. and Kilbourne, E. M.},
	month = nov,
	year = {2000},
	pmid = {18019962},
	keywords = {Health Care Reform, Humans, Public Health, Public Health Informatics, United States},
	pages = {67--75},
	file = {PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/CNC83IYE/Yasnoff et al. - 2000 - Public health informatics improving and transforming public health in the information age.pdf:application/pdf},
}

@article{hripcsak_observational_2015,
	title = {Observational {Health} {Data} {Sciences} and {Informatics} ({OHDSI}): {Opportunities} for {Observational} {Researchers}},
	volume = {216},
	issn = {0926-9630},
	shorttitle = {Observational {Health} {Data} {Sciences} and {Informatics} ({OHDSI})},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4815923/},
	abstract = {The vision of creating accessible, reliable clinical evidence by accessing the clinical experience of hundreds of millions of patients across the globe is a reality. The Observational Health Data Sciences and Informatics (OHDSI) has built on learnings from the Observational Medical Outcomes Partnership to turn methods research and insights into a suite of applications and exploration tools that move the field closer to the ultimate goal of generating evidence about all aspects of healthcare to serve the needs of patients, clinicians and all other decision-makers around the world.},
	urldate = {2025-08-28},
	journal = {Studies in health technology and informatics},
	author = {Hripcsak, George and Duke, Jon D and Shah, Nigam H and Reich, Christian G and Huser, Vojtech and Schuemie, Martijn J and Suchard, Marc A and Park, Rae Woong and Wong, Ian Chi Kei and Rijnbeek, Peter R and van der Lei, Johan and Pratt, Nicole and Norén, G Niklas and Li, Yu-Chuan and Stang, Paul E and Madigan, David and Ryan, Patrick B},
	year = {2015},
	pmid = {26262116},
	pmcid = {PMC4815923},
	pages = {574--578},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/V4VAWQFU/Hripcsak et al. - 2015 - Observational Health Data Sciences and Informatics (OHDSI) Opportunities for Observational Research.pdf:application/pdf},
}

@article{swerdel_developing_2020,
	title = {Developing {Predictive} {Models} to {Determine} {Patients} in {End}-of-{Life} {Care} in {Administrative} {Datasets}},
	volume = {43},
	issn = {1179-1942},
	url = {https://doi.org/10.1007/s40264-020-00906-7},
	doi = {10.1007/s40264-020-00906-7},
	abstract = {In observational studies with mortality endpoints, one needs to consider how to account for subjects whose interventions appear to be part of ‘end-of-life’ care.},
	language = {en},
	number = {5},
	urldate = {2025-08-28},
	journal = {Drug Safety},
	author = {Swerdel, Joel N. and Reps, Jenna M. and Fife, Daniel and Ryan, Patrick B.},
	month = may,
	year = {2020},
	pages = {447--455},
	file = {Full Text:/home/extasia/snap/zotero-snap/common/Zotero/storage/4NQF62S3/Swerdel et al. - 2020 - Developing Predictive Models to Determine Patients in End-of-Life Care in Administrative Datasets.pdf:application/pdf},
}

@article{reich_ohdsi_2024,
	title = {{OHDSI} {Standardized} {Vocabularies}—a large-scale centralized reference ontology for international data harmonization},
	volume = {31},
	issn = {1067-5027},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10873827/},
	doi = {10.1093/jamia/ocad247},
	abstract = {Importance
The Observational Health Data Sciences and Informatics (OHDSI) is the largest distributed data network in the world encompassing more than 331 data sources with 2.1 billion patient records across 34 countries. It enables large-scale observational research through standardizing the data into a common data model (CDM) (Observational Medical Outcomes Partnership [OMOP] CDM) and requires a comprehensive, efficient, and reliable ontology system to support data harmonization.

Materials and methods
We created the OHDSI Standardized Vocabularies—a common reference ontology mandatory to all data sites in the network. It comprises imported and de novo-generated ontologies containing concepts and relationships between them, and the praxis of converting the source data to the OMOP CDM based on these. It enables harmonization through assigned domains according to clinical categories, comprehensive coverage of entities within each domain, support for commonly used international coding schemes, and standardization of semantically equivalent concepts.

Results
The OHDSI Standardized Vocabularies comprise over 10 million concepts from 136 vocabularies. They are used by hundreds of groups and several large data networks. More than 8600 users have performed 50 000 downloads of the system. This open-source resource has proven to address an impediment of large-scale observational research—the dependence on the context of source data representation. With that, it has enabled efficient phenotyping, covariate construction, patient-level prediction, population-level estimation, and standard reporting.

Discussion and conclusion
OHDSI has made available a comprehensive, open vocabulary system that is unmatched in its ability to support global observational research. We encourage researchers to exploit it and contribute their use cases to this dynamic resource.},
	number = {3},
	urldate = {2025-08-28},
	journal = {Journal of the American Medical Informatics Association : JAMIA},
	author = {Reich, Christian and Ostropolets, Anna and Ryan, Patrick and Rijnbeek, Peter and Schuemie, Martijn and Davydov, Alexander and Dymshyts, Dmitry and Hripcsak, George},
	month = jan,
	year = {2024},
	pmid = {38175665},
	pmcid = {PMC10873827},
	pages = {583--590},
	file = {PubMed Central Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/AJQDSGFV/Reich et al. - 2024 - OHDSI Standardized Vocabularies—a large-scale centralized reference ontology for international data.pdf:application/pdf},
}

@article{reps_design_2018,
	title = {Design and implementation of a standardized framework to generate and evaluate patient-level prediction models using observational healthcare data},
	volume = {25},
	issn = {1527-974X},
	url = {https://doi.org/10.1093/jamia/ocy032},
	doi = {10.1093/jamia/ocy032},
	abstract = {To develop a conceptual prediction model framework containing standardized steps and describe the corresponding open-source software developed to consistently implement the framework across computational environments and observational healthcare databases to enable model sharing and reproducibility.Based on existing best practices we propose a 5 step standardized framework for: (1) transparently defining the problem; (2) selecting suitable datasets; (3) constructing variables from the observational data; (4) learning the predictive model; and (5) validating the model performance. We implemented this framework as open-source software utilizing the Observational Medical Outcomes Partnership Common Data Model to enable convenient sharing of models and reproduction of model evaluation across multiple observational datasets. The software implementation contains default covariates and classifiers but the framework enables customization and extension.As a proof-of-concept, demonstrating the transparency and ease of model dissemination using the software, we developed prediction models for 21 different outcomes within a target population of people suffering from depression across 4 observational databases. All 84 models are available in an accessible online repository to be implemented by anyone with access to an observational database in the Common Data Model format.The proof-of-concept study illustrates the framework’s ability to develop reproducible models that can be readily shared and offers the potential to perform extensive external validation of models, and improve their likelihood of clinical uptake. In future work the framework will be applied to perform an “all-by-all” prediction analysis to assess the observational data prediction domain across numerous target populations, outcomes and time, and risk settings.},
	number = {8},
	urldate = {2025-08-28},
	journal = {Journal of the American Medical Informatics Association},
	author = {Reps, Jenna M and Schuemie, Martijn J and Suchard, Marc A and Ryan, Patrick B and Rijnbeek, Peter R},
	month = aug,
	year = {2018},
	pages = {969--975},
	file = {Full Text PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/KKV62Y7G/Reps et al. - 2018 - Design and implementation of a standardized framework to generate and evaluate patient-level predict.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/3S2JUX7M/ocy032.html:text/html},
}

@misc{hosseini-asl_simple_2022,
	title = {A {Simple} {Language} {Model} for {Task}-{Oriented} {Dialogue}},
	url = {http://arxiv.org/abs/2005.00796},
	doi = {10.48550/arXiv.2005.00796},
	abstract = {Task-oriented dialogue is often decomposed into three tasks: understanding user input, deciding actions, and generating a response. While such decomposition might suggest a dedicated model for each sub-task, we find a simple, unified approach leads to state-of-the-art performance on the MultiWOZ dataset. SimpleTOD is a simple approach to task-oriented dialogue that uses a single, causal language model trained on all sub-tasks recast as a single sequence prediction problem. This allows SimpleTOD to fully leverage transfer learning from pre-trained, open domain, causal language models such as GPT-2. SimpleTOD improves over the prior state-of-the-art in joint goal accuracy for dialogue state tracking, and our analysis reveals robustness to noisy annotations in this setting. SimpleTOD also improves the main metrics used to evaluate action decisions and response generation in an end-to-end setting: inform rate by 8.1 points, success rate by 9.7 points, and combined score by 7.2 points.},
	urldate = {2025-08-29},
	publisher = {arXiv},
	author = {Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
	month = apr,
	year = {2022},
	note = {arXiv:2005.00796 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:/home/extasia/snap/zotero-snap/common/Zotero/storage/MPDWRCBT/Hosseini-Asl et al. - 2022 - A Simple Language Model for Task-Oriented Dialogue.pdf:application/pdf;Snapshot:/home/extasia/snap/zotero-snap/common/Zotero/storage/296ANQ6R/2005.html:text/html},
}
